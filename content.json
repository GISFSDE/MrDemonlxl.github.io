{"pages":[{"title":"","text":"🎈🎈摄影-平面设计-绘画欣赏🎈🎈 每天看一点，审美高一点 😊薇薇安·迈尔😊 ​ 薇薇安·迈尔（Vivian Maier），1926年2月1日出生于美国纽约，美国业余街头摄影师、家庭保姆。薇薇安是法国人后裔，出生在纽约，但在法国长大，后回到美国先后生活在纽约和芝加哥，她一生拍摄了超过10万张照片。2007年，芝加哥当地历史学家约翰·马鲁夫发现了她的大量底片并开始整理，此后她的作品登上美国以至意大利、阿根廷和英国等地的报纸。2009年4月21日病逝于芝加哥。2010年，薇薇安的作品开始在芝加哥进行展出，成为摄影圈中热议的人物，并被认可为美国当代最重要的街头摄影师之一。 图片部分搜集于互联网，侵权请留言，马上处理😊。","link":"/album/index.html"},{"title":"","text":"【个人简介】 分享不知出处的一段话： &quot;你所有的烦恼都在于你想得太多，而做得太少。&quot; 无论多么精美浩瀚的绝世计划，都应该点点滴滴赋予行动。 在这里你可以得到什么? 😎 效率的种种利器！ 😎 Java全栈技术学习！ 😎 代码之外的丰富生活！ 【总内容导图】 【关于魑魅先生】 【动漫人物介绍】 魑魅魍魉（chī mèi wǎng liǎng），形形色色妖魔鬼怪，现通指坏人。而魑魅先生乃妖中之首，掌控妖魔万物，专克魑魅魍魉，其面容清秀，千变万化，善学好思矣。其间见霸戈【BUG】，祸害人世间，便习编程术，从此不归路。 绘画作者: @YYu 【联系方式】 如有任何交流需求，请添加个人微信或个人公众号 添加前请备注来由。(๑‾ ꇴ ‾๑) 微信扫码或点击链接关注我哦︿(￣︶￣)︿ 凡事预则立，不预则废。 计划 2021-PLANS DAY 读书 每日算法 每日英语 理财，记账 WEEK 绘画 吉他 运动两次 练字 MONTH 总结 YEAR 熟练一个以上技能 目标 2021-GOALS 读书 《社会心理学》 《大问题：简明哲学导论》 《局外人》 《三体》 《我是猫》 专业 设计模式代码Demo 网络 JVM VUE项目 Linux 音乐 吉他谱扒谱学习 运动 画画 时间轴记录 本站推荐索引 技术知识点 Java并发知识点 法律法规 法律法规数据库 中华人民共和国国旗法 中华人民共和国宪法 中华人民共和国消费者权益保护法 中华人民共和国刑事诉讼法 中华人民共和国婚姻法 中华人名共和国网络安全法 中华人民共和国劳动法 其他 网易云音乐歌单分享","link":"/about/index.html"},{"title":"","text":"申请友链须知 原则上只和技术类博客交换，但不包括含有和色情、暴力、政治敏感的网站。 不和剽窃、侵权、无诚信的网站交换，优先和具有原创作品的网站交换。 申请请提供：站点名称、站点链接、站点描述、logo或头像（不要设置防盗链）。 排名不分先后，刷新后重排，更新信息后请留言告知。 会定期清理很久很久不更新的、不符合要求的友链，不再另行通知。 本站不存储友链图片，如果友链图片换了无法更新。图片裂了的会替换成默认图，需要更换的请留言告知。 本站友链信息如下，申请友链前请先添加本站信息： 网站图标：https://mrdemonlxl.github.io/images/avatar.jpg 网站名称：魑魅先生 网站地址：https://mrdemonlxl.github.io/ 网站简介：Java全栈开发，技术分享，程序员的生活分享 加载中，稍等几秒...","link":"/friend/index.html"},{"title":"","text":"好问则裕，自用则小。——《尚书·仲虺之诰》","link":"/message/index.html"},{"title":"","text":"&nbsp;&nbsp;听听音乐 音乐播放器由mePlayer提供，布局参照网友博客所作，感谢作者的辛勤付出。更多音乐分享请查看歌单。 &nbsp;&nbsp;看看视频 ->点击以下条目开始播放视频,向下滑动查看更多","link":"/media/index.html"},{"title":"音乐歌单收藏","text":"个人学习食用，如有推荐请留言歌单或歌曲链接。点击左下角箭头可全局播放哦 - 🤲😎 温馨提示：选择喜欢的音乐双击播放，由于版权原因部分不能播放。如果喜欢歌单收藏一下，去网易云都能播放哟！","link":"/music/index.html"},{"title":"","text":"碎碎念树洞 tips：github登录后按时间正序查看、可点赞加❤️「+99次查看」 碎碎念加载中，请稍等... $.getScript(\"/js/gitalk_self.min.js\", function () { var gitalk = new Gitalk({ clientID: '20ef8321698ab8c0c37b', clientSecret: '237515b7faa3e1097f2980762f772c6f02dbcbbb', id: '666666', repo: 'MrDemonlxl.github.io', owner: 'MrDemonlxl', admin: \"MrDemonlxl\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"}],"posts":[{"title":"BUG","text":"一次相见，绝不再见 BUG分类解决记录，常见排查方法，常见避免方法总结。 cannot open git-upload-pack IDEA 设置 请求有参数有特殊字符 post参数写body里面 tomcat connecter加relaxedPathChars=&quot;|{}[]^&quot; relaxedQueryChars=&quot;|{}[]^&quot; 123456789101112131415161718192021222324252627package com.jeethink.framework.config;import org.apache.catalina.connector.Connector;import org.springframework.boot.web.embedded.tomcat.TomcatConnectorCustomizer;import org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory;import org.springframework.boot.web.servlet.server.ConfigurableServletWebServerFactory;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 解决高版本Tomcat不支持在URL中传入特殊字符（比如|）的问题 */@Configurationpublic class TomcatServerConfig { @Bean public ConfigurableServletWebServerFactory webServerFactory() { TomcatServletWebServerFactory factory = new TomcatServletWebServerFactory(); factory.addConnectorCustomizers(new TomcatConnectorCustomizer() { @Override public void customize(Connector connector) { //允许特殊字符 connector.setProperty(&quot;relaxedQueryChars&quot;, &quot;|{}[]&quot;); } }); return factory; }}","link":"/2021/02/24/Draft/2021/BUG/"},{"title":"博客模板","text":"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 嗨，请准确无误地输入密码查看哟！","link":"/2021/01/19/Draft/2021/Hexo%E4%BD%BF%E7%94%A8%E8%8C%83%E4%BE%8B/"},{"title":"魑魅先生 | 业务技术","text":"所有的技术都是为了更好的解决业务 JAVA应用（菜鸟一站），栏目下有： 文件上传下载解析到数据库 CURD（所有框架） 网络通信 单元测试 实际业务 加密解密 缓存 hutool（JAVA工具类包） 扫码登录 图片处理 jeekins与部署实施 动态表单设计与实现 验证码 外部接口应用 工作流 代码生成 数据库设计 文件格式转换（word--》pdf） 数据格式转换 工具类合集 分页 跨域 单点登录 外发接口规范token验证 支付 短信 后台创建数据【创建时间，id，初始数据】 目录可参考kuangstudy 数据格式 权限管理 JDK高版本 进行中 单元测试 数据库设计 http===https 定时任务 已完成 CRUD 所有知识从CRUD开始 SSM SpringBoot SpringCloud 文件上传下载 相关对象： 12MultipartFile 文件路径： 1HttpServletRequest req Servlet获取当前项目的上下文路径（web文件下的路径）： 1req.getContextPath() Servlet获取当前项目的上下文的绝对路径（web文件下的路径）： 1req.getServletContext().getRealPath(); 获取Java程序中的resources文件路径： 1Resources.getResourceAsStream() 前后端交互： 跨域 解决根本原理 什么情况会跨域 同一协议， 如http或https 同一IP地址, 如127.0.0.1 同一端口, 如8080 以上三个条件中有一个条件不同就会产生跨域问题。 解决方案 前端解决方案 使用JSONP方式实现跨域调用； 使用NodeJS服务器做为服务代理，前端发起请求到NodeJS服务器， NodeJS服务器代理转发请求到后端服务器； 后端解决方案 nginx反向代理解决跨域 服务端设置Response Header(响应头部)的Access-Control-Allow-Origin 在需要跨域访问的类和方法中设置允许跨域访问（如Spring中使用@CrossOrigin注解）； 继承使用Spring Web的CorsFilter（适用于Spring MVC、Spring Boot） 实现WebMvcConfigurer接口（适用于Spring Boot） WebService 简介 跨编程语言和跨操作系统平台的远程调用技术 原理 XML,SOAP和WSDL就是构成WebService平台的三大技术 。 WebService采用Http协议来在客户端和服务端之间传输数据。WebService使用XML来封装数据，XML主要的优点在于它是跨平台的。 WebService通过HTTP协议发送请求和接收结果时，发送的请求内容和结果内容都采用XML格式封装，并增加了一些特定的HTTP消息头，以说明HTTP消息的内容格式，这些特定的HTTP消息头和XML内容格式就是SOAP协议规定的。 WebService服务器端首先要通过一个WSDL文件来说明自己有什么服务可以对外调用。简单的说，WSDL就像是一个说明书，用于描述WebService及其方法、参数和返回值。 WSDL文件保存在Web服务器上，通过一个url地址就可以访问到它。客户端要调用一个WebService服务之前，要知道该服务的WSDL文件的地址。WebService服务提供商可以通过两种方式来暴露它的WSDL文件地址：1.注册到UDDI服务器，以便被人查找；2.直接告诉给客户端调用者。 RESTful 简介 数据格式 JSON 数据示例 1234567{ &quot;sites&quot;: [ { &quot;name&quot;:&quot;a&quot; , &quot;url&quot;:&quot;www.runoob.com&quot; }, { &quot;name&quot;:&quot;b&quot; , &quot;url&quot;:&quot;www.google.com&quot; }, { &quot;name&quot;:&quot;c&quot; , &quot;url&quot;:&quot;www.weibo.com&quot; } ]} 不同数据相互转换方式 字符串，Map，对象，JSONObject（无序），JSONArray（有序），Java数组 字符串2Json 123456789101112131415161718192021222324252627```# 单元测试## 基础知识### Springboot引入**spring-boot-starter-test**JUnit — The de-facto standard for unit testing Java applications. Spring Test &amp; Spring Boot Test — Utilities and integration test support for Spring Boot applications. AssertJ — A fluent assertion library. Hamcrest — A library of matcher objects (also known as constraints or predicates). Mockito — A Java mocking framework. JSONassert — An assertion library for JSON. JsonPath — XPath for JSON.## assertThat#### 基础语法assertThat( [value], [matcher statement] );- value 是接下来想要测试的变量值；- matcher statement 是使用 Hamcrest 匹配符来表达的对前面变量所期望的值的声明，如果 value 值与 matcher statement 所表达的期望值相符，则测试成功，否则测试失败。 字符相关匹配符 /**equalTo匹配符断言被测的testedValue等于expectedValue， equalTo可以断言数值之间，字符串之间和对象之间是否相等，相当于Object的equals方法 */ assertThat(testedValue, equalTo(expectedValue)); /**equalToIgnoringCase匹配符断言被测的字符串testedString *在忽略大小写的情况下等于expectedString */ assertThat(testedString, equalToIgnoringCase(expectedString)); /*equalToIgnoringWhiteSpace匹配符断言被测的字符串testedString 在忽略头尾的任意个空格的情况下等于expectedString， 注意：字符串中的空格不能被忽略 / assertThat(testedString, equalToIgnoringWhiteSpace(expectedString); /containsString匹配符断言被测的字符串testedString包含子字符串subString/ assertThat(testedString, containsString(subString) ); /*endsWith匹配符断言被测的字符串testedString以子字符串suffix结尾/ assertThat(testedString, endsWith(suffix)); /startsWith匹配符断言被测的字符串testedString以子字符串prefix开始/ assertThat(testedString, startsWith(prefix)); 一般匹配符 /nullValue()匹配符断言被测object的值为null/ assertThat(object,nullValue()); /notNullValue()匹配符断言被测object的值不为null/ assertThat(object,notNullValue()); /is匹配符断言被测的object等于后面给出匹配表达式/ assertThat(testedString, is(equalTo(expectedValue))); /is匹配符简写应用之一，is(equalTo(x))的简写，断言testedValue等于expectedValue/ assertThat(testedValue, is(expectedValue)); /is匹配符简写应用之二，is(instanceOf(SomeClass.class))的简写， 断言testedObject为Cheddar的实例 / assertThat(testedObject, is(Cheddar.class)); /*not匹配符和is匹配符正好相反，断言被测的object不等于后面给出的object/ assertThat(testedString, not(expectedString)); /**allOf匹配符断言符合所有条件，相当于“与”（&amp;&amp;）/ assertThat(testedNumber, allOf( greaterThan(8), lessThan(16) ) ); /**anyOf匹配符断言符合条件之一，相当于“或”（||）/ assertThat(testedNumber, anyOf( greaterThan(16), lessThan(8) ) ); 数值相关匹配符 /closeTo匹配符断言被测的浮点型数testedDouble在20.0¡À0.5范围之内/ assertThat(testedDouble, closeTo( 20.0, 0.5 )); /greaterThan匹配符断言被测的数值testedNumber大于16.0/ assertThat(testedNumber, greaterThan(16.0)); / lessThan匹配符断言被测的数值testedNumber小于16.0/ assertThat(testedNumber, lessThan (16.0)); / greaterThanOrEqualTo匹配符断言被测的数值testedNumber大于等于16.0/ assertThat(testedNumber, greaterThanOrEqualTo (16.0)); / lessThanOrEqualTo匹配符断言被测的testedNumber小于等于16.0/ assertThat(testedNumber, lessThanOrEqualTo (16.0)); 集合相关匹配符 /hasEntry匹配符断言被测的Map对象mapObject含有一个键值为&quot;key&quot;对应元素值为&quot;value&quot;的Entry项/ assertThat(mapObject, hasEntry(&quot;key&quot;, &quot;value&quot; ) ); /hasItem匹配符表明被测的迭代对象iterableObject含有元素element项则测试通过/ assertThat(iterableObject, hasItem (element)); / hasKey匹配符断言被测的Map对象mapObject含有键值“key”/ assertThat(mapObject, hasKey (&quot;key&quot;)); / hasValue匹配符断言被测的Map对象mapObject含有元素值value/ assertThat(mapObject, hasValue(value)); 123456789 可表达全部的测试思想。Springboot 可自动生成测试代码 IDEA Ctrl + Shift +T 生成测试类## Service import org.junit.Assert; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import static org.hamcrest.CoreMatchers.*; @RunWith(SpringRunner.class) @SpringBootTest public class LearnServiceTest { @Autowired private LearnService learnService; @Test public void getLearn(){ LearnResource learnResource=learnService.selectByKey(1001L); Assert.assertThat(learnResource.getAuthor(),is(&quot;嘟嘟MD独立博客&quot;)); } } 123456789101112131415161718192021222324252627282930313233343536373839404142## ControllerMockMvc：可以不启动工程测试接口，MockMvc 实现了对 Http 请求的模拟，能够直接使用网络的形式，转换到 Controller 的调用，这样可以使得测试速度快、不依赖网络环境，而且提供了一套验证的工具，这样可以使得请求的验证统一而且很方便。1. `mockMvc.perform`执行一个请求2. `MockMvcRequestBuilders.get(“/user/1”)`构造一个请求，Post请求就用.post方法3. `contentType(MediaType.APPLICATION_JSON_UTF8)`代表发送端发送的数据格式是`application/json;charset=UTF-8`4. `accept(MediaType.APPLICATION_JSON_UTF8)`代表客户端希望接受的数据类型为`application/json;charset=UTF-8`5. `session(session)`注入一个session，这样拦截器才可以通过6. `ResultActions.andExpect`添加执行完成后的断言7. `ResultActions.andExpect(MockMvcResultMatchers.status().isOk())`方法看请求的状态响应码是否为200如果不是则抛异常，测试不通过8. `andExpect(MockMvcResultMatchers.jsonPath(“$.author”).value(“嘟嘟MD独立博客”))`这里jsonPath用来获取author字段比对是否为嘟嘟MD独立博客,不是就测试不通过9. `ResultActions.andDo`添加一个结果处理器，表示要对结果做点什么事情，比如此处使用`MockMvcResultHandlers.print()`输出整个响应结果信息## 单元测试回滚测试的垃圾数据清理，添加注解@Transactional 默认引擎是InnoDB有效，MyISAM（MySQL5.5之前默认引擎）不支持事务、也不支持外键想关闭回滚，只要加上`@Rollback(false)`注解即可。`@Rollback`表示事务执行完回滚，支持传入一个参数value，默认true即回滚，false不回滚。### 修改默认引擎的步骤- MyISAM适合：(1)做很多count 的计算；(2)插入不频繁，查询非常频繁；(3)没有事务。- InnoDB适合：(1)可靠性要求比较高，或者要求事务；(2)表更新和查询都相当的频繁，并且表锁定的机会比较大的情况。(4)性能较好的服务器，比如单独的数据库服务器，像阿里云的关系型数据库RDS就推荐使用InnoDB引擎。show variables like '%storage_engine%';show create table user;ALTER TABLE user ENGINE=INNODB;# Swagger UI接口文档，接口测试 @Api：用在请求的类上，表示对类的说明 tags=&quot;说明该类的作用，可以在UI界面上看到的注解&quot; value=&quot;该参数没什么意义，在UI界面上也看到，所以不需要配置&quot; @ApiOperation：用在请求的方法上，说明方法的用途、作用 value=&quot;说明方法的用途、作用&quot; notes=&quot;方法的备注说明&quot; @ApiImplicitParams：用在请求的方法上，表示一组参数说明 @ApiImplicitParam：用在@ApiImplicitParams注解中，指定一个请求参数的各个方面 name：参数名 value：参数的汉字说明、解释 required：参数是否必须传 paramType：参数放在哪个地方 · header --&gt; 请求参数的获取：@RequestHeader · query --&gt; 请求参数的获取：@RequestParam · path（用于restful接口）--&gt; 请求参数的获取：@PathVariable · body（不常用） · form（不常用） dataType：参数类型，默认String，其它值dataType=&quot;Integer&quot; defaultValue：参数的默认值 @ApiResponses：用在请求的方法上，表示一组响应 @ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息 code：数字，例如400 message：信息，例如&quot;请求参数没填好&quot; response：抛出异常的类 @ApiModel：用于响应类上，表示一个返回响应数据的信息 （这种一般用在post创建的时候，使用@RequestBody这样的场景， 请求参数无法使用@ApiImplicitParam注解进行描述的时候） @ApiModelProperty：用在属性上，描述响应类的属性 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# http==》https## 两者区别：### https：优：1.**数据加密**2.**SSL安全机制**【客户端访问服务器-&gt;服务器把数字证书+公用密匙 发给客户端-&gt;客户端验证服务器，确保访问的是正确的服务器（不是钓鱼网站）-&gt;客户端生产会话密匙并用公用密匙进行加密再次发给服务器-&gt;服务器用私人密匙进行解密（也就相当于验证客户端），验证成功建立起一条安全的数据传递通道-&gt;服务器把客户端请求的数据打包加密发送给客户端-&gt;客户端浏览器接收数据并解析3.**安全标识**，提高用户信任感## 步骤：1. 申请SSL证书2. 安装证书。3. 整改网站链接4. 全站做301转向，减少网站权重的流失### nginx 【win】购买ssl证书获得key和pem文件```nginxserver { listen 8080 ssl; server_name aaa.bbb.com; ssl on; ssl_certificate E:/tys/nginx-1.12.2/key_pem//hzsgis.pem; ssl_certificate_key E:/tys/nginx-1.12.2/key_pem/hzsgis.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 20m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; #charset koi8-r; #access_log logs/host.access.log main; location /main/map3d/rest { #add_header 'Access-Control-Allow-Headers' '*'; proxy_pass http://111.111.11.11:1111/main/map3d/rest; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; }} 定时任务 SpringBoot @Scheduled注解，接口SchedulingConfigurer,Quartz","link":"/2021/03/01/Draft/2021/JAVA%E5%BA%94%E7%94%A8/"},{"title":"Java基础深入","text":"新学四问 WHY【与前代优化了什么，弥补了什么空白】筑基，越深越稳 WHAT【框架，思维导图，主题框架】容器、并发、IO、NET、JVM、其他 HOW【如何记忆，学习资源】:搜搜 LEVEL【不是每个都学精】精通 容器 总关系图 表格总结 集合名称 结构 是否可重复 是否线程安全 是否可为空 是否有序 增删改查 List Vector ArrayList LinkedList Set TreeSet HashSet Map HashMap TreeMap LinkedHashMap Queue PriorityQueue Collection 集合根接口，定义子类基础操作 遍历方式 foreach Iterator 12345Collection&lt;Person&gt; persons = new ArrayList&lt;Person&gt;();Iterator iterator = persons.iterator();while (iterator.hasNext) { System.out.println(iterator.next); } aggregate operations 123456789Collection&lt;Person&gt; persons = new ArrayList&lt;Person&gt;();persons .stream() .forEach(new Consumer&lt;Person&gt;() { @Override public void accept(Person person) { System.out.println(person.name); } }); 1234567891011121314//在 JDK 8 以后，推荐使用聚合操作对一个集合进行操作。聚合操作通常和 lambda 表达式结合使用，让代码看起来更简洁（因此可能更难理解）。下面举几个简单的栗子：//1.使用流来遍历一个 ShapesCollection，然后输出红色的元素：myShapesCollection.stream() .filter(e -&gt; e.getColor() == Color.RED) .forEach(e -&gt; System.out.println(e.getName()));//你还可以获取一个并行流（parallelStream），当集合元素很多时使用并发可以提高效率：myShapesCollection.parallelStream() .filter(e -&gt; e.getColor() == Color.RED) .forEach(e -&gt; System.out.println(e.getName())); //聚合操作还有很多操作集合的方法，比如说你想把 Collection 中的元素都转成 String 对象，然后把它们 连起来：String joined = elements.stream() .map(Object::toString) .collect(Collectors.joining(&quot;, &quot;));//Thanks:https://blog.csdn.net/u011240877/article/details/52773577 List 插入有序可重可多空 Vector 底层数组，同步，同步让其比AL慢，内存不够默认扩100% ArrayList 底层数组，查优，内存不够默认扩50%，不同步，随机访问优 不指定初始容量，可能会在过多的扩容操作浪费效率。 LinkedList 底层双向链表，插删优，可操作头尾，用作栈、（双向）队列、无随访、不同步 Stack 后进先出的堆栈 Set 无序不重单空 TreeSet 底层TreeMap，可排序【自然排序，定制排序】，线程不安全 HashSet 底层TreeMap，无序，不同步，善存取，单空 LinkedHashSet 底层链表【LinkedHashMap】，不重，不同步，插入有序 Map 键值对，键不重 HashMap 底层哈希表，无序，默认长度16，扩容2的幂 LinkedHashMap 底层哈希表+链表，HashMap子类，有序，可空键值， TreeMap 底层二叉树【红黑树】，可排序，非同步，比较通过key HashTable 线程安全，内部的方法基本都经过 synchronized，保留类不建议使用 ConcurrentHashMap JDK1.7 : 【数组（Segment） + 数组（HashEntry） + 链表（HashEntry节点）】 ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。 JDK1.8 : Node数组+链表 / 红黑树 利用CAS+Synchronized来保证并发更新的安全，底层依然采用数组+链表+红黑树的存储结构。 Queue 先进先出 PriorityQueue 底层二叉小顶堆，保证每次取出的元素是队列中权值最小的。非null， 并发 [JVM与上层技术](JVM 与上层技术) 反射 I/O NET 其他 hashcode与equals CAP、BASE理论 AQS lambda 基础类库（从上到下简化了解） 【java.io java.lang java.util】 【java.lang.reflect java.net javax.net.* java.nio.* java.util.concurrent.】 【java.lang.annotation javax.annotation.* java.lang.refjava.math java.rmi.*javax.rmi. java.security. javax.security. java.sqljavax.sql. javax.transaction. *java.text javax.xml.org.w3c.dom.org.xml.sax. javax.crypto. * javax.imageio. javax.jws. * java.util.jar java.util.logging java.util.prefs java.util.regex java.util.zip】","link":"/2022/02/24/Draft/2021/Java%E5%9F%BA%E7%A1%80%E6%B7%B1%E5%85%A5/"},{"title":"NO GAME NO LIFE","text":"游戏人生 🎈🎈🎈😎 吉他扒谱--数绘--英语--摄影 😎🎈🎈🎈 目前学习路线内容 优先等级 吉他乐理，扒谱 😎😎😎😎😎 数绘 😎😎😎😎😎 英语 😎😎😎😎 摄影 😎😎😎😎 运动 😎😎😎😎 自媒体 😎😎😎😎 平面设计 😎😎😎😎 目前学习路线内容 优先等级 音乐 吉他，钢琴，尤克里里，拇指琴，箫，口琴，演唱，词曲 绘画 数绘 设计 平面 运动 篮球，网球 语言 英语，日语 摄影 人像，景色 自媒体 剪辑，特效 修图 办公效率工具高端操作 OFFICE","link":"/2021/02/25/Draft/2021/NO%20GAME%20NO%20LIFE/"},{"title":"Markdown 学习","text":"改变颜色，内嵌 HTML 标签 Markdown 学习 Markdown作为自媒体人非常方便的一个工具，可以再各大自媒体网站通用，实现一篇多发的效果。其语法简单，几乎可以抛弃鼠标，生成一切样式。 Markdown 学习 符号 分割线 LaTeX符号 语法：$\\clubsuit$ $\\triangleright$ 格式 123&amp;emsp;首行缩进~~删除线~~~缩小~ 导图 图 状态转移图 stateDiagram %% 单程生命周期起点是实心圆，终点是同心圆，内圆为实心。 %%这个例子包含是3个状态Still, Moving 和 Crash. 从Still状态可以转移到Moving，从Moving可以转移到Still 或者 Crash。不能从Still转移到Crash [*] --> Still Still --> [*] Still --> Moving: A transition note right of Moving Moving可以转移到Still或者Crash end note Moving --> Still Moving --> Crash Crash --> [*] 类图 classDiagram class Duck{ -String beakColor - double weight +swim() +quack() #count() +getPrice(count) double +someAbstractMethod() * -someStaticMethod() $ } class Shape{ %% This whole line is a comment classDiagram class Shape noOfVertices draw() } class Color{ RED BLUE GREEN WHITE BLACK } class Relation{ } classK ..> classL : 依赖关系 classA --|> classB : 继承关系（泛化） classM ..|> classN : 实现关系 classG --> classH : 关联关系 classE --o classF : 聚合关系 classC --* classD : 组合关系 Customer \"1\" --> \"*\" Ticket Student \"1\" --> \"1..*\" Course Galaxy --> \"many\" Star : Contains Sky \"1\"--> \"1\" Sun Parent \"1\" -- \"0..2\" Children Person \"1\" -- \"2\" Eyes 饼图 pie title Pie Chart \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 150 \"Cows\" : 150 渲染效果 graph LR id1(Start)-->id2(Stop) style id1 fill:#f9f,stroke:#333,stroke-width:4px; style id2 fill:#f00,stroke:#000,stroke-width:2px,stroke-dasharray:5,5; 基础fontawesome支持 graph TD B[\"fa:fa-twitter for peace\"] B-->C[fa:fa-ban forbidden] B-->D(fa:fa-spinner); B-->E(A fa:fa-camerra-retro perhaps?); 连线 graph TD A1==TEXT===B1 A2-->|text|B2 A3..-B3 节点形状 graph TD B[bname] C(cname) D((dname)) E>ename] F{fname} 甘特图 关键词说明： title—标题 dateFormat—日期格式 section—模块 Completed—已经完成 Active—当前正在进行 Future—后续待处理 crit—关键阶段 gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d future task : des3, after des2, 5d future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and json :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to ,mermaid :1d 流程图 graph TD A[方形] -->B(圆角) B --> C{条件a} C -->|a=1| D[结果1] C -->|a=2| E[结果2] F[竖向流程图] 时序图示例 123456789Title:时序图示例客户端-&gt;服务端: 我想找你拿下数据 SYN服务端--&gt;客户端: 我收到你的请求啦 ACK+SYN客户端-&gt;&gt;服务端: 我收到你的确认啦，我们开始通信吧 ACKNote right of 服务端: 我是一个服务端Note left of 客户端: 我是一个客户端Note over 服务端,客户端: TCP 三次握手participant 观察者 公式 $$ \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} &amp; \\mathbf{j} &amp; \\mathbf{k} \\ \\frac{\\partial X}{\\partial u} &amp; \\frac{\\partial Y}{\\partial u} &amp; 0 \\ \\frac{\\partial X}{\\partial v} &amp; \\frac{\\partial Y}{\\partial v} &amp; 0 \\ \\end{vmatrix} ${$tep1}{\\style{visibility:hidden}{(x+1)(x+1)}} $$ 表格 左对齐 右对齐 居中对齐 单元格 单元格 单元格 单元格 单元格 单元格 代码 123456hello!--- 分割线+ [ ] 勾选框[内容文字](#标题) 页内跳转[内容文字](跳转目标文件的相对路径) 脚注 文字内容 [1] todo列表 读书 《》 专业 （设计模式代码Demo， 网络， JVM， VUE项目， Linux） 音乐 吉他谱扒谱学习 运动 画画 其他 emoji【外可访】，Typora 快捷键WIN+。 🎈🎈 🤲 😎 inserted =&gt; inserted 29th =&gt; 29th H20 =&gt; H2O basic footnote[1:1] here is an inline footnote[^2](inline footnote) and another one[2] and another one[3] footnote content The HTML specification is maintained by the W3C. flowchat st=>start: Start|past:>http://www.google.com[blank] e=>end: End:>http://www.google.com op1=>operation: My Operation|past op2=>operation: Stuff|current sub1=>subroutine: My Subroutine|invalid cond=>condition: Yes or No?|approved:>http://www.google.com c2=>condition: Good idea|rejected io=>inputoutput: catch something…|request st->op1(right)->cond cond(yes, right)->c2 cond(no)->sub1(left)->op1 c2(yes)->io->e c2(no)->op2->e{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options); basic footnote content ↩︎ ↩︎ paragraph ↩︎ footnote content with some markdown ↩︎","link":"/2021/07/23/Draft/2021/Markdown%20%E5%AD%A6%E4%B9%A0/"},{"title":"Nginx","text":"Nginx(&quot;engine x&quot;)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。 在高连接并发的情况下，Nginx是Apache服务器不错的替代品。 下载 安装部署 ​ 解压后不要直接点击exe，会导致修改配置后重启、停止nginx无效，需要手动关闭任务管理器内的所有nginx进程，再启动才可以。 12345start nginx//启动服务nginx -s reload//重新加载配置并启动nginx -s stop// 快速停止nginx -s quit//完整有序的关闭nginx -t // 检查配置是否正确 配置自定义nginx.conf 指令必须以分号结束 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136#user nobody;#==工作进程数，一般设置为cpu核心数worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events { #==最大连接数，一般设置为cpu*2048 worker_connections 1024;}http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' # '$status $body_bytes_sent &quot;$http_referer&quot; ' # '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; #==客户端链接超时时间 keepalive_timeout 65; #gzip on; #当配置多个server节点时，默认server names的缓存区大小就不够了，需要手动设置大一点 server_names_hash_bucket_size 512; #server表示虚拟主机可以理解为一个站点，可以配置多个server节点搭建多个站点 #每一个请求进来确定使用哪个server由server_name确定 server { #站点监听端口 listen 8800; #站点访问域名 server_name localhost; #编码格式，避免url参数乱码 charset utf-8; #access_log logs/host.access.log main; #location用来匹配同一域名下多个URI的访问规则 #比如动态资源如何跳转，静态资源如何跳转等 #location后面跟着的/代表匹配规则 location / { #站点根目录，可以是相对路径，也可以使绝对路径 root html; #默认主页 index index.html index.htm; #转发后端站点地址，一般用于做软负载，轮询后端服务器 #proxy_pass http://10.11.12.237:8080; #拒绝请求，返回403，一般用于某些目录禁止访问 #deny all; #允许请求 #allow all; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS'; add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type'; #重新定义或者添加发往后端服务器的请求头 #给请求头中添加客户请求主机名 proxy_set_header Host $host; #给请求头中添加客户端IP proxy_set_header X-Real-IP $remote_addr; #将$remote_addr变量值添加在客户端“X-Forwarded-For”请求头的后面，并以逗号分隔。 如果客户端请求未携带“X-Forwarded-For”请求头，$proxy_add_x_forwarded_for变量值将与$remote_addr变量相同 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #给请求头中添加客户端的Cookie proxy_set_header Cookie $http_cookie; #将使用代理服务器的主域名和端口号来替换。如果端口是80，可以不加。 proxy_redirect off; #浏览器对 Cookie 有很多限制，如果 Cookie 的 Domain 部分与当前页面的 Domain 不匹配就无法写入。 #所以如果请求 A 域名，服务器 proxy_pass 到 B 域名，然后 B 服务器输出 Domian=B 的 Cookie， #前端的页面依然停留在 A 域名上，于是浏览器就无法将 Cookie 写入。 #不仅是域名，浏览器对 Path 也有限制。我们经常会 proxy_pass 到目标服务器的某个 Path 下， #不把这个 Path 暴露给浏览器。这时候如果目标服务器的 Cookie 写死了 Path 也会出现 Cookie 无法写入的问题。 #设置“Set-Cookie”响应头中的domain属性的替换文本，其值可以为一个字符串、正则表达式的模式或一个引用的变量 #转发后端服务器如果需要Cookie则需要将cookie domain也进行转换，否则前端域名与后端域名不一致cookie就会无法存取 #配置规则：proxy_cookie_domain serverDomain(后端服务器域) nginxDomain(nginx服务器域) proxy_cookie_domain localhost .testcaigou800.com; #取消当前配置级别的所有proxy_cookie_domain指令 #proxy_cookie_domain off; #与后端服务器建立连接的超时时间。一般不可能大于75秒； proxy_connect_timeout 30; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } #当需要对同一端口监听多个域名时，使用如下配置，端口相同域名不同，server_name也可以使用正则进行配置 #但要注意server过多需要手动扩大server_names_hash_bucket_size缓存区大小 server { listen 80; server_name www.abc.com; charset utf-8; location / { proxy_pass http://localhost:10001; } } server { listen 80; server_name aaa.abc.com; charset utf-8; location / { proxy_pass http://localhost:20002; } } 功能 1）反向代理 正向代理：特定情况下，代理用户访问服务器，需要用户手动的设置代理服务器的ip和端口号。 反向代理：是用来代理服务器，代理用户要访问的目标服务器。代理服务器接受请求，然后将请求转发给内部网络的服务器(服务集群模式)，并将从服务器上得到的结果返回给客户端，此时代理服务器对外就表现为一个服务器。 Nginx在反向代理上，提供灵活的功能，可以根据不同的正则采用不同的转发策略，如图设置好后不同的请求就可以走不同的服务器。 2）负载均衡 负载均衡：多在高并发情况下需要使用。其原理就是将数据流量分摊到多个服务器执行，减轻每台服务器的压力，多台服务器(集群)共同完成工作任务，从而提高了数据的吞吐量。 Nginx可使用的负载均衡策略有：轮询（默认）、权重、ip_hash、url_hash(第三方)、fair(第三方)。 3）动静分离 常用于前后端分离，Nginx提供的动静分离是指把动态请求和静态请求分离开，合适的服务器处理相应的请求，使整个服务器系统的性能、效率更高。 Nginx可以根据配置对不同的请求做不同转发，这是动态分离的基础。静态请求对应的静态资源可以直接放在Nginx上做缓冲，更好的做法是放在相应的缓冲服务器上。动态请求由相应的后端服务器处理。","link":"/2021/02/24/Draft/2021/Nginx/"},{"title":"Software Engineer","text":"高级全栈软件工程师养成记 GIS研发工程师，全栈Java开发工程师 🎈🎈🎈😎 TODO 😎🎈🎈🎈 设计模式 Redis 算法 目题(Java基础深入，其他面试题) Springcloud 目前学习路线内容 优先等级 设计模式 😎😎😎😎😎 Redis 😎😎😎😎😎 RabbitMQ 😎😎😎😎 数据库优化 😎😎😎😎 网络 😎😎😎😎 算法 😎😎😎😎 SpringCloud 😎😎😎😎 GIS 😎😎😎😎 Linux 😎😎😎 JVM 😎😎 Dubbo 😎😎 ElasticSearch 😎😎 Node.js 😎😎 ES6 😎😎 Docker 😎😎 分布式 😎😎 高并发 😎😎 Python 😎😎 学习内容 项目名称 详细内容 进度记录 软件工程 （微服务，分布式，高并发，多线程，性能调优，缓存，消息，搜索）其他应用服务器了解。 项目 个人博客 个人博客完成 前端 VUE，Bootstrap，JS，Html，JQuery，Ajax，Thymeleaf,Axios 后端 基础深入，代码多写 框架 框架扎实深入，SpringCloud尝试了解 数据库 Oracle基础使用，MySQL,索引，触发器，存储过程，优化（文件化，从设计到e-r图到创建），Redis,MangoDB 算法 算法机试题 设计模式 Mybatis（ 1、Builder模式5、组合模式9、迭代器模式2、工厂模式3、单例模式4、代理6、模板方法模式7、适配器模式8、装饰者模式）Spring（1.简单工厂2.工厂方法3.单例模式4.适配器模式5.装饰器模式6.代理模式7.观察者模式8.策略模式9.模版方法模式） 网络 协议 系统 Linux常用命令，JVM 工具 Git，SVN高级操作，Pageoffice 实操 机试题 中间件 RabbitMQ ElasticSearch Docker Dubbo 测试 单元测试 部署 服务器Jboss 维护 其他 Python【熟悉基础】安卓【有时间了解】 公司 springboot+mybatis+gis+vue+redis+框架+基础前后端数据交互+springcloud【有时间了解】","link":"/2021/02/25/Draft/2021/Software%20Engineer/"},{"title":"魑魅先生 | 音乐","text":"乐理、吉他、尤克里里、钢琴、拇指琴","link":"/2021/02/25/Draft/2021/%E4%B9%90%E7%90%86%E7%9F%A5%E8%AF%86/"},{"title":"TODO","text":"FIXED 工具：时光序 资源：阿里云盘视频 流程：拟计划–》时光序—》简化记录 三大方面：艺术、技术、自媒体 优先顺序：技术、自媒体 艺术、生活 技术点： 基础深入【容器、并发、IO、Net、JVM】面向应用及题、 分布式中间件（MQ、Dubbo、Springcloud、ElasticSearch）、 前端（VUE、UI框架）、 数据库（Redis实战及理论深入、MySQL优化及复杂句、MongoDB基础可选）、 其他（工作流、Linux【部署、日志】、系统设计、地图开发、小程序、优化、设计模式、算法、网络、文件等框架、Jenkins测试部署）、 实战项目 自媒体： 引流、内容、 艺术： 乐理、唱技巧、钢琴基础、吉他深入、其他乐理深入后深入学习、摄影【风格化】、电子绘画【兴趣】 生活： 两周末出去一天（该关心的人）、一周至少运动一次不久坐、注意健康 语言： 英语口语（音乐电影）、日语未来再期。 时间：11.9-1.31（100天） 路线： 技术： JVM【零时看，网盘同步】+基础深入【书籍，自查结合题】 JVM 题（牛客） IO 并发 线程锁 数据库及优化（Redis【深入应用】+MySQL） Spring全家桶+中间件【熟练应用】 项目实战、Linux【基础命令，部署】 设计模式网络等深入 自媒体： 创建精美文章 艺术： 钢琴 生活： 首要计划 SQL优化 Redis 强制使用Redis 网络 设计模式 算法 JVM 乐理bili Java多线程并发、IO、NET 框架原理、分布式、中间件 MQ Dubbo MongoDB SpringCloud ElasticSearch 拟计划 拟计划，分于每个月的目标 考完后补充软考笔记，每周细化记忆，项目管理对应实践 设计模式 Java工作流 Python复习 DevOps VUE视频一遍 Jenkins Nginx 系统设计（数据库，软件流程） Linux环境开发部署，熟悉shell 小计划 小计划，有空就做 爬虫了解，Python复习 JAVA知识每日一题 Android 国外技术网站 严格执行奖惩制度 深度学习复习 一周一思考出篇公众号文章 文件上传下载清晰化 平台开发 编程思想重点查看 Pageoffice 健身开始肚肚 周期总结 微信小程序聊天提醒机器人 Postgresql学习准备 固定计划 固定计划，每天都做 算法 英语 面题 [ ] MONTH-----六 运动三次 数码绘画一次 摄影 剪辑 公众号运营 WEEK🤲 吉他练习 DAY-2021.5.28 固定计划 [ ] MONTH-----五 项管师 MONTH-----四 运动三次 数码绘画一次 摄影 剪辑 公众号运营【粉丝引导，自媒体矩阵搭建】 RabbitMQ基础第一轮 springcloud第一轮 VUE复习一遍 WEEK🤲🤲🤲 吉他练习 运动 DAY-2021.4.15 SpringCloud【】一节 项管师基础 四节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.4.14 SpringCloud【】一节 项管师基础 四节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.4.13 SpringCloud【】一节 项管师基础 四节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.4.12 SpringCloud【】一节 项管师基础 两节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 WEEK🤲🤲 吉他练习 ### DAY-2021.4.11 SpringCloud【】一节 项管师基础 两节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 ### DAY-2021.4.8 SpringCloud【】一节 项管师基础 两节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 ### DAY-2021.4.7 SpringCloud【】一节 项管师基础 两节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.4.6 SpringCloud【】一节 项管师基础 两节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 WEEK🤲 吉他练习 运动 DAY-2021.4.3 SpringCloud【】一节 项管师基础 两节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.4.2 SpringCloud【】一节 项管师基础 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.4.1 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.3.31 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.3.30 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 WEEK🤲🤲🤲🤲 吉他练习 运动 MONTH------三 运动三次 数码绘画一次 摄影 剪辑 公众号运营【粉丝引导，自媒体矩阵搭建】 RabbitMQ基础第一轮 springcloud第一轮 WEEK🤲 吉他练习 运动 WEEK🤲🤲 吉他练习 WEEK🤲🤲🤲 吉他练习 运动 WEEK🤲🤲🤲🤲 吉他练习 运动 DAY-2021.3.29 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.3.25 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.3.24 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 面题【】一题 Redis【】回忆 DAY-2021.3.23 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 虚拟机环境安装 面题【】一题 Redis【】回忆 DAY-2021.3.22 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 RabbitMQ 7节 面题【】一题 Redis【】回忆 DAY-2021.3.19 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 面题【】一题 Redis【】回忆 DAY-2021.3.18 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 面题【】一题 Redis【】回忆 DAY-2021.3.17 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 面题【】一题 Redis【】回忆 DAY-2021.3.16 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 面题【】一题 Redis【】回忆 DAY-2021.3.15 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 面题【】一题 Redis【】回忆 DAY-2021.3.12 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 面题【】一题 Redis【】回忆 DAY-2021.3.11 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 面题【】一题 Redis【】回忆 DAY-2021.3.10 SpringCloud【】一节 设计模式【】一个 英语【中午】强制外语网站-新闻-书，100单词刷 算法【中午】一题，一知识 面题【】一题 Redis【】回忆 DAY-2021.3.9 SpringCloud 设计模式 英语【中午】强制外语网站，100单词刷 算法【中午】 面题 Redis DAY-2021.3.8 SpringCloud 设计模式 英语【中午】强制外语网站，100单词刷 算法【中午】 面题 Redis 模板 MONTH-----四 运动三次 数码绘画一次 摄影 剪辑 公众号运营 WEEK🤲🤲🤲🤲 吉他练习 运动 DAY-2021.3.9 SpringCloud【】一节 固定计划 DAY-2021.3.9 SpringCloud【】一节 固定计划 WEEK🤲🤲🤲 吉他练习 DAY-2021.3.9 SpringCloud【】一节 固定计划 WEEK🤲🤲 吉他练习 运动 DAY-2021.3.9 SpringCloud【】一节 固定计划 WEEK🤲 吉他练习 运动 DAY-2021.3.9 SpringCloud【】一节 固定计划 FIXED RECORDS 健身记录 BUG排查总结 项管师总结，周末五节课 图书馆借阅信管师书籍，周六 软考高级备考 11.10 交费成功的报考人员于5月24日10:00至28日16:00通过浙江软件考试网下载并打印考试准考证，逾期未打印准考证视为放弃考试。报考人员按准考证规定的时间、地点和要求参加考试。","link":"/2022/02/24/Draft/2021/TODO/"},{"title":"五分钟搭建在线博客","text":"博客已成为程序员学习与输出重要一环，当你时间宝贵或者没有必要从零构建个人博客的话，一个可以进行快速搭建的静态博客就显得比较重要了。不但丰富的主题可以任你选择，各个组件还可以任你搭配。有的甚至无需服务器和域名注册，分分钟实现自己分享的小基地。 目前比较流行的开源框架有 Hexo、WordPress、VuePress、Hugo、Solo、Halo 、Jekyll 白嫖党【无需服务器，免费域名】喜欢的无个人域名无法被百度搜索 Jekyll、Hugo、Hexo 本博客使用 Hexo 接下来开始Hexo博客快速搭建 环境准备 Github账号，新库名:用户名.github.io node.js、npm、JS、Git 安装与基础学习 图床 Gitee+PicGo 初步搭建 创建博客文件夹，shift+右键进入目录cmd 安装hexo npm install -g hexo-cli 初始化文件夹 hexo init hexo_blog 进入博客文件夹 cd E:\\my\\hexo_blog 安装博客需要的依赖文件 npm install Hexo命令 hexo cl #清理 hexo g #生成 hexo s #本地服务 hexo d #发布 测试http://locakhost:4000 或127.0.0.1:4000 初步搭建完成 Hexo相关配置 项目目录说明 _config.yml配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117title: 博客名subtitle: 副标题description: 博客描述keywords: SEO搜索关键词author: 文章作者language: zh-CN #语言timezone: ''#时区# URL## If your site is put in a subdirectory, set url as 'http://example.com/child' and root as '/child/'url: http://MrDemonlxl.github.io #网址root: /permalink: :year/:month/:day/:title/permalink_defaults:pretty_urls: trailing_index: true # Set to false to remove trailing 'index.html' from permalinks trailing_html: true # Set to false to remove trailing '.html' from permalinks# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: enable: true # Open external links in new tab field: site # Apply to the whole site exclude: ''filename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: '' wrap: true hljs: falseprismjs: enable: false preprocess: true line_number: true tab_replace: ''# Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 10 order_by: -date# Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Metadata elements## https://developer.mozilla.org/en-US/docs/Web/HTML/Element/metameta_generator: true# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss## updated_option supports 'mtime', 'date', 'empty'updated_option: 'mtime'# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Include / Exclude file(s)## include:/exclude: options only apply to the 'source/' folderinclude:exclude:ignore:# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: amazing#landscape# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy: type: git repo: https://github.com/MrDemonlxl/MrDemonlxl.github.io.git branch: maincomment: #评论 type: gitalk language: zh-CN #zh-CN #Localization language key, en, zh-CN and zh-TW are currently available. owner: MrDemonlxl # (required) GitHub user name repo: MrDemonlxl.github.io # (required) GitHub repository name client_id: # (required) OAuth application client id client_secret: # (required) OAuth application client secret admin: [''] create_issue_manually: true distraction_free_mode: false has_hot_recommend: true # 是否有热门推荐 has_latest_comment: true #是否有最新评论 # 主题选择 https://hexo.io/themes/ 选择喜欢主题，下载相应主题包放入主题文件夹，进行对应主题说明配置。 # 继续学习完善 https://hexo.io/zh-cn/docs/index.html # 效果预览 https://mrdemonlxl.github.io/","link":"/2021/02/18/Draft/2021/%E4%BA%94%E5%88%86%E9%92%9F%E6%90%AD%E5%BB%BA%E5%9C%A8%E7%BA%BF%E5%8D%9A%E5%AE%A2/"},{"title":"书影音","text":"记录与回忆才能让那些美好的不美好的存留脑中，阵阵回荡与发酵。 单月更新 BOOKS--OTHER 《白夜行》（东野奎吾） 《解忧杂货铺》（东野奎吾） 《许三观卖血记》（余华） 《我们仨》（杨绛） 《我的家》（巴金） 《局外人》 《小王子》 《恶意》（东野奎吾） 《摆渡人》克莱尔麦克福尔 《偷影子的人》（马克李维） 《岛上书店》（东野奎吾） 《嫌疑人X的献身》 《活着》（余华） 《穆斯林的葬礼》（霍达） 《乖，摸摸头》（大冰） 《水彩从入门到精通》（飞乐鸟） 《人，诗意的栖居》（海德格尔） 《明朝那些事》当年明月，石锐 《看见》柴静 《混血豹王》沈石溪 《狼王梦》沈石溪 《第七天》余华 《地心游记》 《目送》龙应台 《人间失格》 《别上了摄影的当》 《拍出明星范》 《人像摄影教程》 唐东平 《安徒生童话》 BOOKS--MAJOR 《深入理解Java虚拟机3》 《计算机网络自顶下下方法》 《程序员的自我修养》 1.实践出真知，通用最宝贵，最新乐于求，沟通不可无，环境影响大，切保身体好，薪酬等量级，单项求发展，声誉建品牌，不断学进步 2.英语很重要，阅读优秀项目， 《阿里巴巴开发手册泰山版》 1.所有数据库都要配置gmy_create(创建时间)、gmt_modified(更新时间)且需要自动化 MUSIC MOVIES 《银河护卫队2》 《新木乃伊》 《加勒比海盗1234》 《这个杀手不太冷》 《肖申克的救赎》 《泰坦尼克号》 《怦判心动》 《星际穿越》 《源代码》 《黑客帝国》 《曾经》 《爱丽丝的梦游仙境》 《冈仁波次》 《天空之城》 《变形金刚5》 《机器管家》 《独立日》 《幽灵行动阿尔法队》 《太空旅客》 《太空一号》 《地心引力》 《暮光之城》 《异形》 《火星救援》 《美丽人生》 《深夜食堂》 《战狼1/2》 《摆渡人》 《安德得游戏》 《十二只猴子》 《小森林》 《逆世界》 《金刚骷髅岛》 《夏洛特烦恼》 《左耳》 《钢铁骑士》 《捉妖记》 《重返20岁》 《机械师》 《攻壳机动队》 《一万公里的约定》 《生化危机全》 《谋杀似水年华》 《第九区》 《与君相恋100次》 《悟空传》 《刺客信条》 《绣春刀，修罗场》 《权利的游戏1234567》 嫌疑人X的献身 寻梦环游记 缝纫机乐队 敦刻尔克 洛丽塔 魁拔123 解忧杂货店 前任3 神奇女侠 芳华 被偷走的那五年 从你的全世界路过 分手合约 夏洛特烦恼 匆匆那年 失恋33天 海上钢琴师 公牛历险记 179小时 月球 记忆大师 黑天鹅 银翼杀手 血战钢锯岭 自杀小队 看不见的客人 二代妖精之今生有幸 比得兔 天空之眼 小萝莉的猴神大叔 弱点 阿甘正传 当幸福来敲门 硅谷123 国王的演讲 我是江小白 影 绿皮书 盗梦空间 调音师 少年派的奇幻漂流 怦然心动 霸王别姬 复仇者联盟四 蜘蛛侠平行宇宙 头号玩家 明日边缘 小时光 疯狂动物城 驯龙高手12","link":"/2021/02/24/Draft/2021/%E4%B9%A6%E5%BD%B1%E9%9F%B3/"},{"title":"BUG","text":"身体是革命的本钱 软件：小红书，记录心得，读书电影笔记，摄影，旅游 第一个小目标：减掉小肚肚 健身计划： 至少每天 80 个仰卧起坐 代替方案：篮球，跑步 记录： 2021.3.25 100仰卧起坐","link":"/2021/02/24/Draft/2021/%E5%81%A5%E8%BA%AB%E5%A4%96%E5%9E%8B/"},{"title":"魑魅先生 | 前端","text":"VUE、HTML、JS、、、、 VUE HTML5 Javascript Bootstrap CSS Ajax JQuery 其他 var定义的变量，没有块的概念，可以跨块访问, 不能跨函数访问。 let定义的变量，只能在块作用域里访问，不能跨块访问，也不能跨函数访问。 const用来定义常量，使用时必须初始化(即必须赋值)，只能在块作用域里访问，而且不能修改指针。 this.$nextTick(()=&gt;{创建地图对象代码})顺序加载DOM","link":"/2021/03/01/Draft/2021/%E5%89%8D%E7%AB%AF/"},{"title":"自媒体计划","text":"自媒体规划，构建ing 2021-GOALS 前端栏目 Java栏目 Python栏目 每日算法栏目 设计模式栏目 网络知识栏目 音乐乐理栏目 职场经验栏目 艺术欣赏栏目 设计栏目 工具栏目 语言栏目 自媒体矩阵 抖音【艺术，生活，剪辑，Vlog】短视频 VUE【Vlog】长视频 bilibili【合集】长视频 头条【知识，新闻】 知乎【生活、知识】 CSDN【专业知识】 微博【宣传】 简书【文字】 小红书【时尚、生活】 豆瓣【记录艺术】 公众号【输出】","link":"/2021/02/09/Draft/2021/%E5%8D%9A%E5%AE%A2%E8%AE%A1%E5%88%92/"},{"title":"","text":"大纲目录以概览 博客计划 JAVA应用 乐理知识 TODO MYSQL优化 Linux Redis [Markdown 学习](Markdown 学习.md) 设计模式 快查 每日算法 Python3学习 计算机网络 每日面题 书影音 工具篇 Nginx GIS Hexo使用范例 BUG 如何学习一个新知识 健身外型 信息系统项目管理师 RabbitMQ SpringCloud 每日英语 [Software Engineer](Software Engineer.md) [NO GAME NO LIFE](NO GAME NO LIFE.md) jvm与上层技术 五分钟搭建在线博客 资源篇 ===","link":"/2021/06/30/Draft/2021/%E5%A4%A7%E7%BA%B2%E7%9B%AE%E5%BD%95/"},{"title":"如何学习一个新知识","text":"个人学习流程工具记录，如何将一个学习目标最高效率化 学习===》熟练》大师》创造 新学四问 WHY【与前代优化了什么，弥补了什么空白】 WHAT【框架，思维导图，主题框架】 HOW【如何记忆，学习资源】 LEVEL【不是每个都学精】 回顾四问【补充】 WHY【与前代优化了什么，弥补了什么空白】 WHAT【框架，思维导图，主题框架】 HOW【如何记忆，学习资源】 LEVEL【不是每个都学精】 工具 Xmaind MarginNote Typora Anki 印象笔记 专项工具 坚果（笔记在线同步） 百度在线脑图 流程 Google 为什么学【与前代优化了什么】，学什么【框架，思维导图】，如何学【重复运用，直接背诵】，学到哪【会用即可】 资源准备 Xmaind，MarginNote，Goodnotes【思维导图，笔记】，百度在线脑图 Typora，印象笔记 导入思维导图 Markdown 笔记细化，方便整理分享 Anki 艾宾浩斯记忆稳固 结构化====》细化====》固化====》更新 方法 分类学习 重复记忆 实操运用 最高标准 笔记方法 合理计划 督促验收 网络方法 费曼学习法","link":"/2021/02/09/Draft/2021/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9F%A5%E8%AF%86/"},{"title":"工具篇","text":"工具篇 工具篇 工欲善其事，必先利其器 编程 IDEA 电脑应用 学习 流程图 在线流程图 ProcessOn 离线流程图 XMaind 数码工具 Synergy键鼠共享工具 坚果云，文件同步工具 网站推荐 艺术 记录 时光序【备忘，提醒，TODO】","link":"/2021/08/17/Draft/2021/%E5%B7%A5%E5%85%B7%E7%AF%87/"},{"title":"快查","text":"Linux,Shell,软件等常用命令快捷键 CMD netstat -aon|findstr &quot;59207&quot;查找对应端口pid tasklist|findstr &quot;1396&quot;查看对应pid程序 taskkill /t /f /pid &quot;8888&quot;关闭对应端口 mstsc 启动远程桌面 gpedit.msc策略组 HEXO Hexo c 清理 Hexo g编译 Hexo s运行 Hexo d部署 hexo new draft（scaffolds中模板名字）“标题”新建草稿 在source/_drafts目录 hexo new “标题”新建文档 hexo publish “标题”草稿移动到source/_post目录 IDEA ctrl +R 替换 LINUX yum install net-tools 安装网络工具 linux可直接复制给别人，复制VMware工作目录然后直接打开 su 回车输入密码转换为超级管理员 ifconfig查询网络相关 clear清空显示 ifconfig eth0 192.16.。。。设置IP地址 命令多数为临时生效，写入配置文件为永久生效 ls [-选项][参数]：ls -la /etc 目录处理命令（list） ls -a/l/lh/ld/i 隐藏文件/文件详细信息/大小单位显示/查看目录信息/查看文件id d l 文件开头 文件、目录、软连接 权限 mkdir【make directories】 创建目录 -p递归创建 创建没有此目录下的目录，可同时创建多个mkdir /tmp/a/b /tmp/a/c cd 【change directory】切换目录 cd ..返回上一级目录 pwd【print working directory】 cd ./.. 当前目录/上级目录 remdir【remove empty dirctories】 删除空目录 cp【copy】复制 源文件 目录 -r复制目录 -p复制并保留文件属性（比如创建时间） 复制并改名 mv【move】 剪切 rm【remove】删除文件，目录 -r删除目录 -f强制删除 -rf直接删除 ctrl+c终止操作 touch 创建文件 可创建多个，创建空格文件名使用双引号但是不建议 cat 浏览文件内容 -n显示行号 tac 倒置浏览文件内容 more 分页显示长文件 空格翻页，回车换行，q退出， less 显示文件内容，可向上翻页pageup，可搜索：/关键词 n显示下一个搜索结果 head 只看文件前几行 -n 7 文件 显示前7行，默认前十行 tail 同上 -f动态显示变化 ctrl+c退出 ln【link】 -s创建软连接 不写-s创建硬链接【软连接相当于快捷方式rwxrwxrwx，权限跟源文件权限无关，硬链接相当于拷贝cp -p并且同步更新，硬链接通过i节点区分，不能跨分区（相当于不能c盘复制到d盘），不能针对目录使用】 yum -y install git sudo -s1获得管理员权限 命令：sudo -s回车 输入密码 编辑保存文件----------------------------------- 第一步：cd到该文件的目录下 第二步：vi 要编辑的文件名，进入普通模式，（可以查看文件内容） sudo gedit /etc/apt/sources.list 可视化编辑 第三步：输入 i 进入编辑模式，开始编辑文本 第四步：编辑之后，按ESC退出到普通模式。 第五步：在普通模式下，输入 : 进入命令模式 第六步：在命令模式下输入wq, 即可保存并退出 【#】代表 root权限 【$】代表普通用户 reboot重启 BUG————————————————————————————– centos7 cannot find a valid baseurl for repo············· https://blog.csdn.net/jiankunking/article/details/82770502 zlib.h: No such file or directory························ yum install zlib-devel CentOS Name or service not known·································· vi /etc/sysconfig/network-scripts/ifcfg-ens33命令来编辑配置文件 Job for network.service failed because the control process exited with error code········································································ 关闭 NetworkManger 服务就好了， service NetworkManager stop 禁止开机启动 chkconfig NetworkManager off su: Authentication failure····················································· sudo passwd root 网络————————————————————————————— 网络不行都用桥接 1systemctl restart network //重启网卡 ====ifup eth0（网卡名称） ip addr查询网络信息 postgresql——————————————————————————- sudo -u postgres psql 进入psql交互环境 alter user postgres with password'密码'; 修改postgres用户的密码 \\q 退出数据库 shp导入到postgresql——————————————————————— shp2pgsql -s 4544 -c -W &quot;UTF-8&quot; ADDRESS.shp public.rrrrr| psql -h 192.168.22.128 -d postgres -U postgres -W 转换格式——————————————————————— ogr2ogr -f &quot;GeoJSON&quot; ./natural.json PG:&quot;host=localhost dbname=postgres user=postgres password=724111&quot; -sql &quot;select * from natural&quot; 切片—————————————————————————————— tippecanoe -z 14 -Z 5 -ps -Bg -o buildings.mbtiles buildings.json tippecanoe -e lakepbf -pC -Z1 -z17 -f natural.json 各种常用软件环境安装 NPM npm install ---install dependencies npm run dev---serve with hot reload at localhost:8080 npm run build---build for production with minification npm run build --report----build for production and view the bundle analyzer report npm run unit---run unit tests npm run e2e---run e2e tests npm test----run all tests REDIDS ./redis-server redis.windows.conf 启动服务 VSCODE ctrl+~ ：打开终端 F1 或 Ctrl+Shift+P（俗称万能键） ：打开命令面板。在打开的输入框内，可以输入任何命令 代码格式化: Shift+Alt+F VUE 脚手架 npm config set registry https://registry.npm.taobao.org vue init webpack projectName cd projectName npm install npm run dev npm i element-ui -S npm install axios","link":"/2021/02/25/Draft/2021/%E5%BF%AB%E6%9F%A5/"},{"title":"数据库设计","text":"数据库如何设计实现，保证并发安全 阿里规范摘要 数据库字段设计及对应关系 数据库三原则 数据库设计工具 如何设计数据库","link":"/2022/02/24/Draft/2021/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/"},{"title":"魑魅先生 | 每日算法","text":"为什么学？编程的灵魂，不管什么语言都得需要。 如何学？多想多写多用 学到什么程度？实际运用 题源：Leetcode 一.基本数据结构 第一章 算法定义 在特定计算模型下，在信息处理过程中为了解决某一类问题而设计的一个指令序列。 要素： 输入：待处理的信息，即对具体问题的描述。 输出：经过处理之后得到的信息，即问题的答案。 确定性：任一算法都可以描述为由若干种基本操作组成的序列。 可行性：在相应的计算模型中，每一基本操作都可以实现，且能够在常数时间内完成。 有穷性：对于任何输入，按照算法，经过有穷次基本操作都可以得到正确的输出。 1.2性能分析预评价 三个层次：合法程序，确定尺度度量算法效率，通过对算法设计编写效率高，能处理大规模数据的程序， 时间复杂度 T(n) 度量算法执行速度并评价其效率，算法需要多少时间才能得到结果 ==》针对不同规模的输入，算法的执行时间各是多少 ==》统一规模算法处理时间也不相同 空间复杂度 算法所需存储空间 1.3 算法复杂度及其分析 1.3.1 O(1)⎯⎯取非极端元素 1.3.2 O(logn)⎯⎯进制转换 1.3.3 O(n)⎯⎯数组求和 1.3.4 O(n2)⎯⎯起泡排序 1.3.5 O(2r)⎯⎯幂函数 1.4 计算模型 1.4.1 可解性 1.4.2 有效可解 1.4.3 下界 1.5 递归 1.5.1 线性递归 1.5.2 递归算法的复杂度分析 1.5.3 二分递归 1.5.4 多分支递归 第二章 栈与队列 栈与队列最简单基本，但也是最重要的。JVM，CPU，Java提供对应内建类， 2.1 栈 后进先出（Last-in-first-out，LIFO），比如浏览器访问记录与回退，编辑回退。 元素： 栈容量，栈顶指针，初始化 进栈push()、出栈pop()，查栈顶peek() Java java.util.Stack ：push()、pop()、peek()（功能等价于top()）、getSize()以及empty()（功能等价于isEmpty()） 应用：数组倒置，括号匹配算法， 三种实现方式 数组 链表 LinkedList 2.2 队列 先进先出（First-In-First-Out, FIFO），羽毛球筒 2.2.1 队列ADT Queue 接口 元素 队头、队尾、队尾加元素add()，队头删除元素poll(),查队头元素peek() 2.2.2 基于数组的实现 顺序数组，整体移动 循环数组， 性能分析，O(1)。 2.2.3 队列应用实例 循环分配器，Josephus 环 2.3 链表 数组长度必须固定，在空间效率及适应性方面还存在不足。 2.3.1 单链表 元素 首节点，末节点 ​ 链表的第一个和最后一个节点，分别称作链表的首节点（Head）和末节点（Tail）。末节点的特征是，其next 引用为空。如此定义的链表，称作单链表（Singly linkedlist）。 ​ 与数组类似，单链表中的元素也具有一个线性次序⎯⎯若P 的next 引用指向S，则P 就是S的直接前驱，而S 是P 的直接后继。与数组不同的是，单链表的长度不再固定，而是可以根据实际需要不断变化。如此一来，包含n 个元素的单链表只需占用O(n)空间⎯⎯这要比定长数组更为灵活。 2.4 位置 2.5 双端队列 第三章 向量、列表与序列 ​ 序列（Sequence），就是依次排列的多个对象，就是一组对象之间的后继与前驱关系，是数据结构设计的基础。两种典型的序列：向量（Vector）和列表（List）。 3.1 向量与数组 3.1.1 向量ADT 第四章 树 ​ 前面所有的数据结构根据其实现方式，可以划分为基于数组实现和基于链表实现，其各有长短，数组善查找读取，修改耗时，链表反之。两者有点能结合?树或许可以回答这个问题。 术语及性质 节点的深度、树的深度与高度 ​ 树中的元素也称作节点（Node），每个节点的深度都是一个非负整数；深度为0 的节点有且仅有一个，称作树根（Root）；对于深度为k (k≥1)的每个节点u，都有且仅有一个深度为k-1 的节点v 与之对应，称作u 的父亲（Parent）或父节点。定义四.2 若节点v 是节点u 的父亲，则u 称作v 的孩子（Child），并在二者之间建立一条树边（Edge）。同一节点的孩子互称“兄弟”（Sibling）。树中所有节点的最大深度，称作树的深度或高度。树中节点的数目，总是等于边数加一。 度、内部节点与外部节点 ​ 任一节点的孩子数目，称作它的“度”（Degree）。至少拥有一个孩子的节点称作“内部节点”（Internal node）；没有任何孩子的节点则称作 “外部节点”（External node）或“叶子”（Leaf）。 路径 ​ 由树中k+1 节点通过树边首尾衔接而构成的序列{ (v0, v1), (v1, v2), …, (vk-1, vk) | k ≥ 0}，称作树中长度为k 的一条路径（Path）。由单个节点、零条边构成的路径也是合法的，其长度为0。树中任何两个节点之间都存在唯一的一条路径。若v 是u 的父亲，则depth(v) + 1 = depth(u)。从树根通往任一节点的路径长度，恰好等于该节点的深度。 祖先、后代、子树和节点的高度 每个节点都是自己的“祖先”（Ancestor），也是自己的“后代”（Descendent）； 若v 是u 的父节点的祖先，则v 也是u 的祖先； 若u 的父节点是v 的后代，则u 也是v 的后代。 除节点本身以外的祖先（后代），称作真祖先（后代）。任一节点v 的深度，等于其真祖先的数目。任一节点v 的祖先，在每一深度上最多只有一个。树T 中每一节点v 的所有后代也构成一棵树，称作T 的“以v 为根的子树（Subtree）”若子树v 的深度（高度）为h，则称v 的高度为h，记作height(v) = h。对于叶子节点u 的任何祖先v，必有depth(v) + height(v) ≥ depth(u)。 共同祖先及最低共同祖先 在树T 中，若节点u 和v 都是节点a 的后代，则称节点a 为节点u 和v 的共同祖先（Commonancestor）。每一对节点至少存在一个共同祖先。在一对节点u 和v 的所有共同祖先中，深度最大者称为它们的最低共同祖先（Lowerestcommon ancestor），记作lca(u, v)。每一对节点的最低共同祖先必存在且唯一。 有序树、m 叉树 在树T 中，若在每个节点的所有孩子之间都可以定义某一线性次序，则称T 为一棵“有序树（Ordered tree）”每个内部节点均为m 度的有序树，称作m 叉树。 二叉树 每个节点均不超过2 度的有序树，称作二叉树（Binary tree）。不含1 度节点的二叉树，称作真二叉树（Proper binary tree），否则称作非真二叉树 （Improper binary tree）。在二叉树中，深度为k 的节点不超过2k 个。高度为h 的二叉树最多包含2h+1-1 个节点。由n 个节点构成的二叉树，高度至少为⎣log2n⎦。在二叉树中，叶子总是比2 度节点多一个。 满二叉树与完全二叉树 若二叉树T 中所有叶子的深度完全相同，则称之为满二叉树（Full binary tree）高度为h 的二叉树是满的，当且仅当它拥有2h 匹叶子、2h+1-1 个节点。若在一棵满二叉树中，从最右侧起将相邻的若干匹叶子节点摘除掉，则得到的二叉树称作完全二叉树（Complete binary tree）。由n 个节点构成的完全二叉树，高度h = ⎣log2n⎦。在由固定数目的节点所组成的所有二叉树中，完全二叉树的高度最低。 第五章 优先队列 第六章 映射与词典 第七章 查找树 第八章 串 第九章 图 二、常用算法 排序 1、冒泡排序 2、选择排序 3、插入排序 4、希尔排序 5、归并排序 6、快速排序 然后基准两边分别快速排序 7、堆排序 8、计数排序 9、桶排序 10、基数排序 查找 1. 顺序查找 2. 二分查找 3. 插值查找 4. 斐波那契查找 5. 树表查找 6. 分块查找 7. 哈希查找 三、算法题 2.18题目：序号-题目 思路1： 123思路1优点：缺点： 代码1： 1代码1 思路2： 123思路2优点：缺点： 代码2： 1代码2 参考文献：数据结构预算法(Java描述)邓俊辉","link":"/2021/02/19/Draft/2021/%E6%AF%8F%E6%97%A5%E7%AE%97%E6%B3%95/"},{"title":"魑魅先生 | 程序员英语","text":"图解日常英语单词 通俗易懂的英语语法 针对计算机英语 口语练习记录","link":"/2021/02/25/Draft/2021/%E6%AF%8F%E6%97%A5%E8%8B%B1%E8%AF%AD/"},{"title":"魑魅先生 | 每日面题","text":"面试题不但是门槛，也是检测。 Java刷题 主要分类： JVM，网络，Java基础，算法数据结构，数据库高级知识，框架原理，设计模式，分布式 Java基础 查看JAVA基础项目并补充，包含java基础， JVM 网络 算法数据结构 数据库高级知识 框架原理 设计模式 分布式","link":"/2021/03/01/Draft/2021/%E6%AF%8F%E6%97%A5%E9%9D%A2%E9%A2%98/"},{"title":"魑魅先生 | 资源篇","text":"JVM 与上层技术 魑魅先生 | 资源篇 魑魅先生 | 资源篇 一.程序员书屋（编程相关，Kindle 相关 一共112个 G 资源） Java资源101个 G 囊括大部分 Java 开发小白到全栈大神所需阅读全部书籍，设计模式、网络、算法、框架、职场经验 ​ 关注公众号发送 小书屋 获取下载链接 不仅如此，还有 Kindle 各类电子书籍11个G 索引在此点击 搜索之后有需要的 关注公众号发送 Kindle获取下载链接！ 二.学习网站（持续更新中） 1.编程网站： Refactoring.Guru ​ 设计模式在线学习，程序员之间的沟通语言，学习必不可少的知识，有各种代码示范，UML图，动漫演示。 Visualgo ​ 算法在线可视化过程，理解更加容易，过程速度可调，步骤可控，代码可观。 Github ​ 将自己的学习代码进行版本化管理，将学习资源整理归纳，学习别人的优秀项目，获取全球最新资源，好处就不一一列举了，每个程序员都了解。 CSDN ​ 一个人的成就往往不在于得到多少，而在于输出多少，一个有贡献的程序员往往是会分享的。这个博客网站汇聚很多大牛，也有很多 demo，让你可以不重复造轮子。 2.设计网站： doyoudo ​ 学习 Ae、Ps、Pr、C4D、乐理等等。印象中小白老师的生动课堂是让我对设计感兴趣第一原因，也是第一个让我有想上付费课冲动的学习网站。 Colordrop ​ 配色网站，直观且复制方便，妈妈再也不用担心我的配色了。 创客贴 ​ 不会 PS 没关系，创客贴直接拉动修改元素，一切都直接设计好了，小白式拖动便可快速完成设计更改，还可以直接修改 GIF 动图！ 3.通用网站： Bilibili 不仅仅有鬼畜，你想有的教程都有，摄影、设计、编程、绘画等，是现代学习者不可缺少聚集地。 Coursera 国外学习网站，免费资源很多，可以接触更加及时的知识。 三.软件推荐（持续更新中） 电脑篇 英语语法书写纠正，毕竟语法纠正除了老师就只有他了。 自媒体必备，Markdown最佳利器。 字体中央管理，免费商用就够你用一辈子了，版权问题不用考虑了 Markdown图床管理优秀软件之一 有他还要啥百度云，配合chrome使用更香 你有个ipad放那盖泡面不如拿来用作你的第二屏幕 艾宾浩斯遗忘曲线最佳实践，记忆任何知识，自主卡片形式 目前使用过的最佳思维导图软件 三端互传文件，无缝同步，在鸿蒙系统出来之前它可能一直是我的主力 安卓可用，电脑操控手机，可无线控制，上班划水利器，免费开源 抓包，测试，网络模拟，新世界，一不小心从抓包到入狱 浏览器插件 ​ chrome有了它，啥会员都不用开。 ​ 有了它，任何复杂页面都可以变得小清新。 ipad篇 （待更新[如何抓包获取各种围哎皮，如何高效率利用学习软件]） 手机篇 （待更新[各种黑科技小工具]） ​ 魑魅先生，一只拼搏成为魑魅大能的小鬼(●—●) 四.设计资源（持续更新中） ​ 包括各大海报，字体，笔刷，素材，LOGO，全家桶等等，公众号回复设计资源获取下载链接 ​ ! 五.视频资源（持续更新中） Java，Python相关基础到架构课程，项目实战 ​ ​ 音乐相关 ​ 吉他，尤克里里，乐理，编曲，作词，相关软件，声源 ​ ​ 绘画 语言 摄影 ​ 包含美国摄影学院摄影教材，学习摄影不可缺少的书籍 最后想说，资源虽多，但如果只当一个收藏党那永远不会是你的。只有在这飞速发展的时代，卸去浮躁，一点点消化，才会让成为你茁壮成长的养分。 ​ 资源分享，部分资源请勿作商业用途，如有侵权，联系删除。如果有能力，请支持正版！","link":"/2021/07/22/Draft/2021/%E8%B5%84%E6%BA%90%E7%AF%87/"},{"title":"BUG","text":"项目管理，项目经验，开发之外【实施，测试，维护，部署】 项目总结，开发之外技能提升","link":"/2021/02/24/Draft/2021/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"title":"","text":"架构 一、项目背景(项目基本情况介绍、项目特点、要论述的论点) 二、提出论点(描述对××管理的重要性的认识) ​ 2020年6月，我参加了╳╳市资源局发起的“城市大脑”一地一码协同平台系统的建设工作，担任承建方项目经理，该信息综合管理平台系统的主要模块包括平台门户、“多规合一”业务协同系统优化、行政审批业务整合、土地码建设、数字驾驶舱规划和自然资源系统、驾驶舱指标库建设等9个业务管理模块，建设费用780万人民币，该项目于2021年6月通过了业主方的验收上线运行后,赢得了用户的一致好评，使项目获得了圆满成功。本文结合我的实际经验,以该项目为例,讨论了信息系统项目建设过程中的XX管理,主要从以下几个方面进行了阐述:XXXXX等过程内容，有效提高了XX管理水平，满足了项目干系人需求和期望。 ​ 2018年12月，“多规合一”业务协同系统中“多规共享”、“项目生成”等模块为各部门提供了非常便捷和快速的服务，取得了良好的效益。随着系统应用的不断深入，用户对“项目生成”等应用场景提出了更高的使用要求，如：项目类型、业务类型细化不足，导致在实际工作过程中存在盲区，影响了部分项目的推进等。另一方面，部门平台各自为政、系统间的数据存在壁垒，导致无法有效的进行数据共享，无法实现项目审批减材料、减时间、减环节，急需对原系统的各应用场景进行优化。杭州市XX资源局成立后，为尽快落实机构改革要求，释放改革红利，以自然资源“两统一”和业务需求为根本出发点，聚焦中心工作，立足已有基础，统筹整合现有资源，积极开展立足“一块土地一件事”全服务工作，由此一地一码协同平台应运而生。该项目采用了公开招标的方式，我公司参与了投标并顺利中标，于2020年6月签订了合同，随后成立了专门项目小组，任命我为项目经理。我公司的组织方式为项目型，项目成员直接归属项目经理领导，我组核心成员共15人。考虑到项目的复杂性、各区县地理位置不集中等原因，系统采用JAVA语言开发，项目组决定此项目采用SSM的三层b/s架构模式，地图基于leaflet的WebGIS可视化，数据库使用Postgres，这样的设计有利于后期的维护及扩展。项目共分为数字驾驶舱规划和自然资源系统、“一地一码”协同服务平台等子系统。经过全组成员的共同努力，项目于2021年6月顺利通过验收，目前运行情况良好。 ​ 由于该系统具有建设规模大（涵盖物价部门几乎所有业务），建设时间紧（建设期限为一年），涉及的干系人多（内部干系人包括项目组各类成员、公司领导和相关部门人员，外部干系人不仅包括市局各科室，也包括12个区县物价局的相关人员、运营商等），参与的项目成员多（高峰时达到60人，我将小组成员分为硬件集成部署组、数据中心组、软件开发组、平台测试组（四个小组），功能复杂等特点，为了保证项目圆满完成，我组建了强矩阵的项目组织结构，通过有效的项目管理，特别是出色的XX管理，带领项目团队全体成员经过奋战获得了良好的绩效，取得了项目的成功。本文将围绕该项目的XX管理进行重点讨论。 三、按照所涉及管理领域的过程分段进行论述(先给出每个过程的定义、输入、输出、工具与方法，再结合做过的项目描述项目中是如何做的) 一、 二、 三、 四、 五、 四、小结(对上面的论述进行一下小结) 五、分析项目存在的问题及改进的建议(写够三条就可以了) 六、总结(主要是写项目体会，比如通过项目实施，自己自觉应用项目管理知识、工具、技术，对成功实施项目所起的积极作用等)。 ​ 经过我们团队不懈的努力，历时1 年，本项目终于于2021年6月，通过了业主方组织的验收，实现从规划编制和实施、资源保护和利用、确权登记、地理资源等多方面进行业务和数据的融合，涵盖了规资局统一行使全民所有自然资源资产所有者职责，统一行使所有国土空间用途管制和生态保护修复职责。通过门户串联“多规合一”业务协同系统、行政审批系统、不动产登记系统等三大系统，以模块化形式，搭建多规共享、编制统筹、项目生成、实施监测、立项用地规划许可、工程许可、施工许可、竣工验收、确权登记等9个应用场景。本项目的成功在某些方面得益于我成功的xx 管理，在此我总结一下几条管理经验：（1）重视项目的调研，充分了解项目需求与范围；（2）树立正确的思想，采用适当的方法、遵循一定的流程，严格按照进度管理的要求做好活动定义、活动排序、活动的资源估算、活动的历时估算、编制进度计划、进度控制工作；（3）建立问题跟踪机制，对每个阶段的问题进行记录和跟踪，将每个问题落实到具体负责人。 ​ 当然，在本项目中，还有一些不足之处，比如：在项目的实施过程中，由于项目组2 名成员因为自身原因突然离职，导致项目的团队建设出现一些小问题，还有，曾经由于疫情原因导致一位技术人员居家隔离在家办公影响了些项目进度，不过，经过我后期的纠偏，并没有对项目产生什么影响。在后续的学习和工作中，我将不断的充电学习，和同行进行交流，提升自己的业务和管理水平，力争为我国信息化建设做出自己的努力。","link":"/2021/11/08/Draft/2021/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E8%AE%BA%E6%96%87%E6%A8%A1%E6%9D%BF/"},{"title":"Dubbo","text":"分布式RPC框架Apache Dubbo 1. 软件架构的演进过程 软件架构的发展经历了由单体架构、垂直架构、SOA架构到微服务架构的演进过程，下面我们分别了解一下这几个架构。 1.1 单体架构 架构说明： ​ 全部功能集中在一个项目内（All in one）。 架构优点： ​ 架构简单，前期开发成本低、开发周期短，适合小型项目。 架构缺点： ​ 全部功能集成在一个工程中，对于大型项目不易开发、扩展和维护。 ​ 技术栈受限，只能使用一种语言开发。 ​ 系统性能扩展只能通过扩展集群节点，成本高。 1.2 垂直架构 架构说明： ​ 按照业务进行切割，形成小的单体项目。 架构优点： ​ 技术栈可扩展（不同的系统可以用不同的编程语言编写）。 架构缺点： ​ 功能集中在一个项目中，不利于开发、扩展、维护。 ​ 系统扩张只能通过集群的方式。 ​ 项目之间功能冗余、数据冗余、耦合性强。 1.3 SOA架构 SOA全称为Service-Oriented Architecture，即面向服务的架构。它可以根据需求通过网络对松散耦合的粗粒度应用组件(服务)进行分布式部署、组合和使用。一个服务通常以独立的形式存在于操作系统进程中。 站在功能的角度，把业务逻辑抽象成可复用的服务，通过服务的编排实现业务的快速再生，目的：把原先固有的业务功能转变为通用的业务服务，实现业务逻辑的快速复用。 架构说明： ​ 将重复功能或模块抽取成组件的形式，对外提供服务，在项目与服务之间使用ESB（企业服务总线）的形式作为通信的桥梁。 架构优点： ​ 重复功能或模块抽取为服务，提高开发效率。 ​ 可重用性高。 ​ 可维护性高。 架构缺点： ​ 各系统之间业务不同，很难确认功能或模块是重复的。 ​ 抽取服务的粒度大。 ​ 系统和服务之间耦合度高。 1.4 微服务架构 架构说明： ​ 将系统服务层完全独立出来，抽取为一个一个的微服务。 ​ 抽取的粒度更细，遵循单一原则。 ​ 采用轻量级框架协议传输。 架构优点： ​ 服务拆分粒度更细，有利于提高开发效率。 ​ 可以针对不同服务制定对应的优化方案。 ​ 适用于互联网时代，产品迭代周期更短。 架构缺点： ​ 粒度太细导致服务太多，维护成本高。 ​ 分布式系统开发的技术成本高，对团队的挑战大。 2. Apache Dubbo概述 2.1 Dubbo简介 Apache Dubbo是一款高性能的Java RPC框架。其前身是阿里巴巴公司开源的一个高性能、轻量级的开源Java RPC框架，可以和Spring框架无缝集成。 什么是RPC？ RPC全称为remote procedure call，即远程过程调用。比如两台服务器A和B，A服务器上部署一个应用，B服务器上部署一个应用，A服务器上的应用想调用B服务器上的应用提供的方法，由于两个应用不在一个内存空间，不能直接调用，所以需要通过网络来表达调用的语义和传达调用的数据。 需要注意的是RPC并不是一个具体的技术，而是指整个网络远程调用过程。 RPC是一个泛化的概念，严格来说一切远程过程调用手段都属于RPC范畴。各种开发语言都有自己的RPC框架。Java中的RPC框架比较多，广泛使用的有RMI、Hessian、Dubbo等。 Dubbo官网地址：http://dubbo.apache.org Dubbo提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。 2.2 Dubbo架构 Dubbo架构图（Dubbo官方提供）如下： 节点角色说明： 节点 角色名称 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 虚线都是异步访问，实线都是同步访问 蓝色虚线:在启动时完成的功能 红色虚线(实线)都是程序运行过程中执行的功能 调用关系说明: 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 3. 服务注册中心Zookeeper 通过前面的Dubbo架构图可以看到，Registry（服务注册中心）在其中起着至关重要的作用。Dubbo官方推荐使用Zookeeper作为服务注册中心。 3.1 Zookeeper介绍 Zookeeper 是 Apache Hadoop 的子项目，是一个树型的目录服务，支持变更推送，适合作为 Dubbo 服务的注册中心，工业强度较高，可用于生产环境，并推荐使用 。 为了便于理解Zookeeper的树型目录服务，我们先来看一下我们电脑的文件系统(也是一个树型目录结构)： 我的电脑可以分为多个盘符（例如C、D、E等），每个盘符下可以创建多个目录，每个目录下面可以创建文件，也可以创建子目录，最终构成了一个树型结构。通过这种树型结构的目录，我们可以将文件分门别类的进行存放，方便我们后期查找。而且磁盘上的每个文件都有一个唯一的访问路径，例如：C:\\Windows\\itcast\\hello.txt。 Zookeeper树型目录服务： 流程说明： 服务提供者(Provider)启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址 服务消费者(Consumer)启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址 监控中心(Monitor)启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址 3.2 安装Zookeeper 下载地址：http://archive.apache.org/dist/zookeeper/ 本课程使用的Zookeeper版本为3.4.6，下载完成后可以获得名称为zookeeper-3.4.6.tar.gz的压缩文件。 安装步骤： 第一步：安装 jdk（略） 第二步：把 zookeeper 的压缩包（zookeeper-3.4.6.tar.gz）上传到 linux 系统 第三步：解压缩压缩包 ​ tar -zxvf zookeeper-3.4.6.tar.gz 第四步：进入zookeeper-3.4.6目录，创建data目录 ​ mkdir data 第五步：进入conf目录 ，把zoo_sample.cfg 改名为zoo.cfg ​ cd conf ​ mv zoo_sample.cfg zoo.cfg 第六步：打开zoo.cfg文件, 修改data属性：dataDir=/root/zookeeper-3.4.6/data 3.3 启动、停止Zookeeper 进入Zookeeper的bin目录，启动服务命令 ./zkServer.sh start 停止服务命令 ./zkServer.sh stop 查看服务状态： ./zkServer.sh status 4. Dubbo快速入门 Dubbo作为一个RPC框架，其最核心的功能就是要实现跨网络的远程调用。本小节就是要创建两个应用，一个作为服务的提供方，一个作为服务的消费方。通过Dubbo来实现服务消费方远程调用服务提供方的方法。 4.1 服务提供方开发 开发步骤： （1）创建maven工程（打包方式为war）dubbodemo_provider，在pom.xml文件中导入如下坐标 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.5.RELEASE&lt;/spring.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- dubbo相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.12.1.GA&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 指定端口 --&gt; &lt;port&gt;8081&lt;/port&gt; &lt;!-- 请求路径 --&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; （2）配置web.xml文件 1234567891011121314&lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot; &quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot; &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt;&lt;/web-app&gt; （3）创建服务接口 1234package com.itheima.service;public interface HelloService { public String sayHello(String name);} （4）创建服务实现类 12345678910package com.itheima.service.impl;import com.alibaba.dubbo.config.annotation.Service;import com.itheima.service.HelloService;@Servicepublic class HelloServiceImpl implements HelloService { public String sayHello(String name) { return &quot;hello &quot; + name; }} 注意：服务实现类上使用的Service注解是Dubbo提供的，用于对外发布服务 （5）在src/main/resources下创建applicationContext-service.xml 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 当前应用名称，用于注册中心计算应用间依赖关系，注意：消费者和提供者应用名不要一样 --&gt; &lt;dubbo:application name=&quot;dubbodemo_provider&quot; /&gt; &lt;!-- 连接服务注册中心zookeeper ip为zookeeper所在服务器的ip地址--&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.134.129:2181&quot;/&gt; &lt;!-- 注册 协议和port 端口默认是20880 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20881&quot;&gt;&lt;/dubbo:protocol&gt; &lt;!-- 扫描指定包，加入@Service注解的类会被发布为服务 --&gt; &lt;dubbo:annotation package=&quot;com.itheima.service.impl&quot; /&gt;&lt;/beans&gt; （6）启动服务 tomcat7:run 4.2 服务消费方开发 开发步骤： （1）创建maven工程（打包方式为war）dubbodemo_consumer，pom.xml配置和上面服务提供者相同，只需要将Tomcat插件的端口号改为8082即可 （2）配置web.xml文件 1234567891011121314151617181920&lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot; &quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot; &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 指定加载的配置文件 ，通过参数contextConfigLocation加载 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext-web.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; （3）将服务提供者工程中的HelloService接口复制到当前工程 （4）编写Controller 12345678910111213141516171819202122package com.itheima.controller;import com.alibaba.dubbo.config.annotation.Reference;import com.itheima.service.HelloService;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controller@RequestMapping(&quot;/demo&quot;)public class HelloController { @Reference private HelloService helloService; @RequestMapping(&quot;/hello&quot;) @ResponseBody public String getName(String name){ //远程调用 String result = helloService.sayHello(name); System.out.println(result); return result; }} 注意：Controller中注入HelloService使用的是Dubbo提供的@Reference注解 （5）在src/main/resources下创建applicationContext-web.xml 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 当前应用名称，用于注册中心计算应用间依赖关系，注意：消费者和提供者应用名不要一样 --&gt; &lt;dubbo:application name=&quot;dubbodemo-consumer&quot; /&gt; &lt;!-- 连接服务注册中心zookeeper ip为zookeeper所在服务器的ip地址--&gt; &lt;dubbo:registry address=&quot;zookeeper://192.168.134.129:2181&quot;/&gt; &lt;!-- 扫描的方式暴露接口 --&gt; &lt;dubbo:annotation package=&quot;com.itheima.controller&quot; /&gt;&lt;/beans&gt; （6）运行测试 tomcat7:run启动 在浏览器输入http://localhost:8082/demo/hello.do?name=Jack，查看浏览器输出结果 **思考一：**上面的Dubbo入门案例中我们是将HelloService接口从服务提供者工程(dubbodemo_provider)复制到服务消费者工程(dubbodemo_consumer)中，这种做法是否合适？还有没有更好的方式？ **答：**这种做法显然是不好的，同一个接口被复制了两份，不利于后期维护。更好的方式是单独创建一个maven工程，将此接口创建在这个maven工程中。需要依赖此接口的工程只需要在自己工程的pom.xml文件中引入maven坐标即可。 **思考二：**在服务消费者工程(dubbodemo_consumer)中只是引用了HelloService接口，并没有提供实现类，Dubbo是如何做到远程调用的？ **答：**Dubbo底层是基于代理技术为HelloService接口创建代理对象，远程调用是通过此代理对象完成的。可以通过开发工具的debug功能查看此代理对象的内部结构。另外，Dubbo实现网络传输底层是基于Netty框架完成的。 **思考三：**上面的Dubbo入门案例中我们使用Zookeeper作为服务注册中心，服务提供者需要将自己的服务信息注册到Zookeeper，服务消费者需要从Zookeeper订阅自己所需要的服务，此时Zookeeper服务就变得非常重要了，那如何防止Zookeeper单点故障呢？ **答：**Zookeeper其实是支持集群模式的，可以配置Zookeeper集群来达到Zookeeper服务的高可用，防止出现单点故障。 5. Dubbo管理控制台 我们在开发时，需要知道Zookeeper注册中心都注册了哪些服务，有哪些消费者来消费这些服务。我们可以通过部署一个管理中心来实现。其实管理中心就是一个web应用，部署到tomcat即可。 5.1 安装 安装步骤： （1）将资料中的dubbo-admin-2.6.0.war文件复制到tomcat的webapps目录下 （2）启动tomcat，此war文件会自动解压 （3）修改WEB-INF下的dubbo.properties文件，注意dubbo.registry.address对应的值需要对应当前使用的Zookeeper的ip地址和端口号 ​ dubbo.registry.address=zookeeper://192.168.134.129:2181 ​ dubbo.admin.root.password=root ​ dubbo.admin.guest.password=guest （4）重启tomcat 5.2 使用 操作步骤： （1）访问http://localhost:8080/dubbo-admin-2.6.0/，输入用户名(root)和密码(root) （2）启动服务提供者工程和服务消费者工程，可以在查看到对应的信息 6. Dubbo相关配置说明 6.1 包扫描 1&lt;dubbo:annotation package=&quot;com.itheima.service&quot; /&gt; 服务提供者和服务消费者都需要配置，表示包扫描，作用是扫描指定包(包括子包)下的类。 如果不使用包扫描，也可以通过如下配置的方式来发布服务： 12&lt;bean id=&quot;helloService&quot; class=&quot;com.itheima.service.impl.HelloServiceImpl&quot; /&gt;&lt;dubbo:service interface=&quot;com.itheima.api.HelloService&quot; ref=&quot;helloService&quot; /&gt; 作为服务消费者，可以通过如下配置来引用服务： 12&lt;!-- 生成远程服务代理，可以和本地bean一样使用helloService --&gt;&lt;dubbo:reference id=&quot;helloService&quot; interface=&quot;com.itheima.api.HelloService&quot; /&gt; 上面这种方式发布和引用服务，一个配置项(dubbo:service、dubbo:reference)只能发布或者引用一个服务，如果有多个服务，这种方式就比较繁琐了。推荐使用包扫描方式。 6.2 协议 1&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt; 一般在服务提供者一方配置，可以指定使用的协议名称和端口号。 其中Dubbo支持的协议有：dubbo、rmi、hessian、http、webservice、rest、redis等。 推荐使用的是dubbo协议。 dubbo 协议采用单一长连接和 NIO 异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。 也可以在同一个工程中配置多个协议，不同服务可以使用不同的协议，例如： 1234567&lt;!-- 多协议配置 --&gt;&lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;&lt;dubbo:protocol name=&quot;rmi&quot; port=&quot;1099&quot; /&gt;&lt;!-- 使用dubbo协议暴露服务 --&gt;&lt;dubbo:service interface=&quot;com.itheima.api.HelloService&quot; ref=&quot;helloService&quot; protocol=&quot;dubbo&quot; /&gt;&lt;!-- 使用rmi协议暴露服务 --&gt;&lt;dubbo:service interface=&quot;com.itheima.api.DemoService&quot; ref=&quot;demoService&quot; protocol=&quot;rmi&quot; /&gt; 6.3 启动时检查 1&lt;dubbo:consumer check=&quot;false&quot;/&gt; 上面这个配置需要配置在服务消费者一方，如果不配置默认check值为true。Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题。可以通过将check值改为false来关闭检查。 建议在开发阶段将check值设置为false，在生产环境下改为true。 6.4 负载均衡 负载均衡（Load Balance）：其实就是将请求分摊到多个操作单元上进行执行，从而共同完成工作任务。 在集群负载均衡时，Dubbo 提供了多种均衡策略（包括随机、轮询、最少活跃调用数、一致性Hash），缺省为random随机调用。 配置负载均衡策略，既可以在服务提供者一方配置，也可以在服务消费者一方配置，如下： 12345678910111213141516@Controller@RequestMapping(&quot;/demo&quot;)public class HelloController { //在服务消费者一方配置负载均衡策略 @Reference(check = false,loadbalance = &quot;random&quot;) private HelloService helloService; @RequestMapping(&quot;/hello&quot;) @ResponseBody public String getName(String name){ //远程调用 String result = helloService.sayHello(name); System.out.println(result); return result; }} 1234567//在服务提供者一方配置负载均衡@Service(loadbalance = &quot;random&quot;)public class HelloServiceImpl implements HelloService { public String sayHello(String name) { return &quot;hello &quot; + name; }} 可以通过启动多个服务提供者来观察Dubbo负载均衡效果。 注意：因为我们是在一台机器上启动多个服务提供者，所以需要修改tomcat的端口号和Dubbo服务的端口号来防止端口冲突。 在实际生产环境中，多个服务提供者是分别部署在不同的机器上，所以不存在端口冲突问题。 7. 解决Dubbo无法发布被事务代理的Service问题 前面我们已经完成了Dubbo的入门案例，通过入门案例我们可以看到通过Dubbo提供的标签配置就可以进行包扫描，扫描到@Service注解的类就可以被发布为服务。 但是我们如果在服务提供者类上加入@Transactional事务控制注解后，服务就发布不成功了。原因是事务控制的底层原理是为服务提供者类创建代理对象，而默认情况下Spring是基于JDK动态代理方式创建代理对象，而此代理对象的完整类名为com.sun.proxy.$Proxy42（最后两位数字不是固定的），导致Dubbo在发布服务前进行包匹配时无法完成匹配，进而没有进行服务的发布。 7.1 问题展示 在入门案例的服务提供者dubbodemo_provider工程基础上进行展示 操作步骤： （1）在pom.xml文件中增加maven坐标 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; （2）在applicationContext-service.xml配置文件中加入数据源、事务管理器、开启事务注解的相关配置 1234567891011121314&lt;!--数据源--&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test&quot; /&gt;&lt;/bean&gt;&lt;!-- 事务管理器 --&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;&lt;/bean&gt;&lt;!--开启事务控制的注解支持--&gt;&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt; 上面连接的数据库可以自行创建 （3）在HelloServiceImpl类上加入@Transactional注解 （4）启动服务提供者和服务消费者，并访问 上面的错误为没有可用的服务提供者 查看dubbo管理控制台发现服务并没有发布，如下： 可以通过断点调试的方式查看Dubbo执行过程，Dubbo通过AnnotationBean的postProcessAfterInitialization方法进行处理 7.2 解决方案 通过上面的断点调试可以看到，在HelloServiceImpl类上加入事务注解后，Spring会为此类基于JDK动态代理技术创建代理对象，创建的代理对象完整类名为com.sun.proxy.$Proxy35，导致Dubbo在进行包匹配时没有成功（因为我们在发布服务时扫描的包为com.itheima.service），所以后面真正发布服务的代码没有执行。 解决方式操作步骤： （1）修改applicationContext-service.xml配置文件，开启事务控制注解支持时指定proxy-target-class属性，值为true。其作用是使用cglib代理方式为Service类创建代理对象 12&lt;!--开启事务控制的注解支持--&gt;&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; proxy-target-class=&quot;true&quot;/&gt; （2）修改HelloServiceImpl类，在Service注解中加入interfaceClass属性，值为HelloService.class，作用是指定服务的接口类型 1234567@Service(interfaceClass = HelloService.class)@Transactionalpublic class HelloServiceImpl implements HelloService { public String sayHello(String name) { return &quot;hello &quot; + name; }} 此处也是必须要修改的，否则会导致发布的服务接口为SpringProxy，而不是HelloService接口，如下：","link":"/2021/02/24/Draft/2021/Dubbo/"},{"title":"GIS","text":"MAPBOX流程 准备：熟悉linux 安装、网络、文件等基本操作，JS、HTML等熟悉，Mapbox熟悉，SQL熟悉，，， Ubuntu环境准备===》其他格式数据===》shp数据===》Windows导入postgresql数据库===》通过ogr2ogr转换为geojson===》通过tippecanoe切片（参数自控）》~~数据打包（传输更快）~~windows共享文件夹=》准备mapbox2000 js css文件====》mapbox前端代码导入数据并显示====》准备图标数据===》filter分类图标显示=====》分层数据显示====》细节优化（颜色，光，字体大小，图片大小）》加入点击显示位置》其他点击功能====》wfts底图切换==》控件加载===》wfs，wms数据加载（不同数据源）==》其他模型加入 详细步骤 环境准备 Ubuntu虚拟机： 网络环境，数据共享，Postgresql，Tippecanoe，PROJ.4、GEOS和GDAL（ogr2ogr），gcc、g++、make windows： Postgresql,VMware,Ubuntu镜像（官方指定），Navicat（方便查看数据和建立空间数据库），VSCode 详细步骤： 安装Postgresql数据库，环境配置，导入shp Windows安装Postgresql 下载 环境变量添加 设置外网访问（pg_hba.conf） 1234567891011# TYPE DATABASE USER ADDRESS METHOD# IPv4 local connections:host all all 127.0.0.1/32 md5host all all 0.0.0.0/0 md5# IPv6 local connections:host all all ::1/128 md5# Allow replication connections from localhost, by a user with the# replication privilege.#host replication postgres 127.0.0.1/32 md5#host replication postgres ::1/128 md5 建立空间数据库,目标数据库执行以下语句 1234create extension postgis;create extension postgis_topology;create extension fuzzystrmatch;create extension postgis_tiger_geocoder; 在SHP文件夹新建txt文件，粘贴以下代码，导入数据到数据库，相关参数如下，改成bat后缀，双击运行后输入密码，显示类似 insert 1成功 123shp2pgsql -s 4544 -c -W “GBK” DJQ5120812018.shp public.DJQ5120812018 | psql -d shp2pgsqldemo -U postgres -W示例 ：shp2pgsql -s 4544 -c -W &quot;UTF-8&quot; ADDRESS.shp public.rrrrr| psql -h 192.168.22.128 -d postgres -U postgres -W 编码格式 SHP数据 public下的rrrrr表 导入数据库地址 数据库名 用户名 也可分为两个步骤，先转换为sql语句，再导入,步骤同上 12shp2pgsql -s 4544 -c -W “GBK” DJQ5120812018.shp&gt;DJQ5120812018.sqlpsql -d shp2pgsqldemo -U postgres -f DJQ5120812018.sql -W 可能出现的问题 解决办法 乱码 更改编码 导入中断，数据库无数据 数据过大 参数 含义 -s 空间参考标识符（SRID） -d 重新建立表，并插入数据 -a 在同一个表中增加数据 -c 建立新表，并插入数据(缺省) -p 只创建表 -g 指定要创建的表的空间字段名称(在追加数据时有用) -D 使用dump方式，比缺省生成sql的速度快 -G 使用类型geography -k 保持标识符（列名，模式，属性）大小写。 -i 将所有整型都转为标准的32-bit整数 -I 在几何列上建立GIST索引 -S 生成简单几何，而非MULTI几何 -t 指定几何的维度 -w 指定输出格式为WKT -W 输入的dbf文件编码方式 -N 指定几何为空时的操作 -n 只导入dbf文件 -T 指定表的表空间 -X 指定索引的表空间 -? 帮助 通过ogr2ogr转换为geojson 12ogr2ogr -f &quot;GeoJSON&quot; ./asstln.json PG:&quot;host=localhost dbname=postgres user=postgres password=111111&quot; -sql &quot;select * from asstln&quot; 目标文件名 导出数据库连接信息 导出表名 通过tippecanoe切片（参数自控） 单数据源 12tippecanoe -e tracenln -pC -Z0 -z20 -f tracenln.json 目标文件夹 切片等级空值 源文件名 单层多数据源合并 123#where确定级别ogr2ogr -f &quot;GeoJSON&quot; ./veg_py.json PG:&quot;host=126.10.9.16 dbname=postgres user=postgres password=724111&quot; -sql &quot;select * from veg_py fscale=10&quot; tippecanoe -e tracenln -pC -Z0 -z20 -f tracenln1.json tracenln2.json tracenln3.json 参数查看 数据打包 复制到编程端（传输更快） windows文件共享文件夹，或Tomcat，或在线服务器以便数据调用，注意解决触跨域资源访问 准备mapbox2000 js css文件 windows 安装 git Node.JS 安装说明 Yarn安装、配置、镜像源修改 12npm install --global yarnyarn --version Node.js安装本地插件构建工具node-gyp GitHub Mapbox源码地址：https://github.com/mapbox/mapbox-gl-js 2000坐标源码， 项目编译 yarn install 安装headless-gl，并将node_modules/headless-gl/deps/windows/dll/x64/*.dll 复制到c:\\windows\\system32 npm install gl yarn run start-debug yarn run build-dev 准备好js和css文件 mapbox 前端代码导入地图数据并显示 3D模型 针对对应的建筑数据，进行建筑物3D显示 123456789101112131415161718paint: { // 'fill-color': 'red', // 'fill-opacity': 1, 'fill-extrusion-color': '#f5f4ee', // use an 'interpolate' expression to add a smooth transition effect to the // buildings as the user zooms in 'fill-extrusion-height': [ &quot;interpolate&quot;, [&quot;linear&quot;], [&quot;zoom&quot;], 15, 0, 15.05, [&quot;get&quot;, &quot;height&quot;] ], 'fill-extrusion-base': [ &quot;interpolate&quot;, [&quot;linear&quot;], [&quot;zoom&quot;], 15, 0, 15.05, [&quot;get&quot;, &quot;min_height&quot;] ], 'fill-extrusion-opacity': 0.85 }, vscode 插件服务器 插件安装 Live Server 准备图标数据，PBF字体数据 https://github.com/mapbox/spritezero 从零生成图标资源工具，可网上下载 生成如图形式文件， filter 分类图标显示 123456789101112131415'filter': [ 'any', [ '==', 'fcode', '4206002500'//2 ] ,[ '==', 'fcode', '4305010500'//2 ] ], 分层数据显示 1&quot;layers&quot;: []//中越靠前的在底层 细节优化（颜色，光，字体大小，图片大小） 控件加载 Supermap查看 加入点击显示相关信息 123456789101112131415//弹出框​ map.on('click', function (e) {​ var features = map.queryRenderedFeatures(e.point, {​ layers: ['13'] // replace this with the id of the layer​ });​ if (!features.length) {​ return;​ }​ var feature = features[0];​ var popup = new mapboxgl.Popup({ offset: [0, -15] })​ .setLngLat(feature.geometry.coordinates)​ .setHTML('&lt;h3&gt;' + feature.properties.shortname + '&lt;/h3&gt;&lt;p&gt;' + feature.properties.name + '&lt;/p&gt;')​ .addTo(map);​ }); wfts 底图切换 wfs，wms 数据加载（不同数据源） 定位 数据查询 数据可视化 Supermap查看 优化 窗口样式优化，弹出框样式优化，字体等调节 一些小技巧 待更新 Mapbox源码编译 环境准备 GIT环境搭建： 详细点击：（一）windows 安装 git Node.JS环境搭建： 详细点击：（一）Node.JS 安装说明 Yarn环境搭建： 详细点击：（一）Yarn安装、配置、镜像源修改 12npm install --global yarnyarn --version Npm and node-gyp依赖安装 详细点击：（二）Node.js安装本地插件构建工具node-gyp 其他地址： GitHub Mapbox源码地址：https://github.com/mapbox/mapbox-gl-js 项目编译 yarn install 安装headless-gl，并将node_modules/headless-gl/deps/windows/dll/x64/*.dll 复制到c:\\windows\\system32 npm install gl yarn run start-debug yarn run build-dev debug/index.html中代码最上方增加token mapboxgl.accessToken='pk.eyJ1IjoibGltbiIsImEiOiJja2t1bG1na2IxZGU0MnZvNmlzY3FhZXM4In0.oQx4VguycOR4TK80Pyusmw'; var map = window.map = new mapboxgl.Map({ MAPBOX专业术语 矢量瓦片： 栅格瓦片： MAPBOX学习 中文文档：http://www.mapbox.cn/mapbox-gl-js/api/ Styles (8) 为地图添加生成的图标 为地图添加动画图标 为地图生成及添加缺失的图标 为地图添加图标 使用自定义样式展示地图 显示卫星地图 改变一个地图的样式 显示一个地图 Layers (30) 用3D形式呈现建筑物 拉伸多边形以绘制3D室内地图 添加3D模型 调整图层不透明度 为线添加动画效果 为一系列图像添加动画效果 为点添加动画效果 按照缩放级别改变建筑颜色 更改标注的大小写 显示具有自定义属性的HTML聚类 创建样式聚类 使用按钮更改图层颜色 添加自定义样式图层 给线添加数据驱动属性的样式。 给圆添加数据驱动属性的样式 显示多种文本格式并设置其样式 为多边形添加图案 在标签下添加新图层 添加 GeoJSON 线 绘制 GeoJSON 点 添加 GeoJSON 多边形 创建热力图图层 添加晕暄 使用表达式创建渐变色线条 设置海洋深度数据样式 显示和隐藏图层 改变行政边界世界观 根据缩放级别更新等值线图层 变量标签位置 可视化人口密度 Sources (9) 将本地JSON数据与矢量切片图形连接 添加影像 添加实时数据 更新实时要素 添加栅格切片数据源 添加一个第三方矢量切片来源 添加一个矢量图片数据源 添加一个视频 添加一个 WMS 源 User interaction (17) 基于周边声音给3D建筑添加动画效果 禁用地图旋转 创建可拖动的点 创建可拖动的标记（Marker） 通过文本输入筛选符号 在 map view 中筛选要素 通过切换列表筛选符号 创建悬停效果 显示非交互式地图 更改地图的语言 高亮包含相似数据的部分 从点击点周围选择特征 限制地图平移在某一区域 获取鼠标下点的特征 切换交互 创建时间滑动条 高亮一个选择框范围内的特征 Camera (11) 使地图相机环绕一点运动 为路线中的点添加动画效果 将地图居中于被单击的符号上 缓慢飞至某个位置 将地图缩放至边界框内 飞至某一位置 使用游戏式控件浏览地图 跳至一系列地点 以幻灯片形式播放地图位置。 根据滚动位置飞到某处 设置 pitch 和 bearing Controls and overlays (16) 为标记(marker)添加动画效果 改变注释的默认位置 使用 Markers 添加自定义图标 禁用滚轮缩放 全屏查看地图 定位用户 在不同地图之间滑动 显示驾驶方向 显示已绘制的多边形区域 添加地理编码器 利用地点名称添加标记 点击时显示多边形信息 悬浮时显示弹出窗 点击时显示一个弹出窗 显示一个弹出窗 将弹出窗口附加到 marker 实例 Geocoder (8) 从其他数据源中补充进一步的地理编码查询结果 接收输入坐标至地理编码器 使用地理编码器时采用自定义渲染功能 将地理编码的结果限制在指定地区范围内 在使用地理编码器的过程中结合使用自定义相机动画 在地图上添加位置搜索框 将地理编码器进行指定语言的本地化 在Geocoder产生结果后设置一个点 Browser support (1) 检查浏览器支持 Internationalization support (2) 使用本地生成的表意文字 为从右至左书写的脚本提供支持 SUPERMAP 一个mapbox华丽外衣与装备 Leaflet an open-source JavaScript library for mobile-friendly interactive maps Cygwin windows使用linux环境（部分机型失败） Tippecanoe Tippecanoe是Mapbox的一个开源切片工具，项目地址：https://github.com/mapbox/tippecanoe，Mapbox常规的切片方法tilelive-copy参见另一篇博客。Tippecanoe主要在处理大数据量时有很大的优势，具有很高的效率，并且有很多参数可以控制。Tippecanoe只能处理GeoJSON，因此在切片前需要将矢量数据转换为GeoJSON，推荐使用ogr2ogr工具转换。切片以后的格式为mbtiles，可自行导入mongodb等数据库。 目的：根据你的数据创造一个可自由缩放的视图 引用地址：https://my.oschina.net/u/1464512/blog/1631972 常用tippecanoe参数设置 GEOJSON GeoSever GeoServer是OGC Web服务器规范的J2EE实现，利用GeoServer可以方便地发布地图数据，允许用户对特征数据进行更新、删除、插入操作，通过GeoServer可以比较容易地在用户之间迅速共享空间地理信息。GeoServer是开源软件。 GeoServer主要包含如下一些特点： 兼容WMS和WFS特性 支持PostGIS、Shapefile、ArcSDE、Oracle、VPF、MySQL、MapInfo 支持上百种投影 能够将网络地图输出为JPEG、GIF、PNG、SVG、KML等格式 能够运行在任何基于J2EE/Servlet容器之上 嵌入MapBuilder支持AJAX的地图客户端OpenLayers 引用地址 WMS &amp;&amp; WFS WMS是由服务器将一地图图像发送给客户端，而WFS是服务器将矢量数据发送给客户端，也就是在使用WMS时地图由服务器绘制，在使用WFS时地图由客户端绘制。 WFTS","link":"/2021/02/22/Draft/2021/GIS/"},{"title":"JVM 与上层技术","text":"JVM 与上层技术 新学四问 **WHY【与前代优化了什么，弥补了什么空白】：**了解底层，优化，面试，解决底层BUG **WHAT【框架，思维导图，主题框架】：**结构， HOW【如何记忆，学习资源】：学习资源：尚硅谷JVM，ANKI记忆 **LEVEL【不是每个都学精】：**了解 进度：上篇 第二章【完】 上篇：内存与垃圾回收 一、JVM与JAVA体系结构 1.JAVA与JVM Java大事件 1990年，在sun公司中，由Patrick naughton、mikesheridan以及james Gosling领导的小组Green Team，开发出新的程序语言，命名为OAK，后期更名为Java 1995年，sun正式发布Java和hotJAVA产品，Java首次公开亮相。 1996年1月23日sun Microsystems发布了JDK1.0. 1998年，JDK1.2版本发布。同时，sun发布了JSP/Servlet、EJB规范，以及将Java分成了J2EE、J2SE和J2ME。这表明Java开始向企业、桌面应用和移动设备应用3大领域挺进。 2000年，JDK1.3发布，Java HotSpot Virtual Machine正式发布，成为Java默认的虚拟机。 2002年，JDK 1.4发布，古老的classic虚拟机退出历史舞台。 2003年底，Java平台的scala正式发布，同年Groovy也加入了Java阵营。 2004年，JDK1.5发布，同时JDK1.5改名为JavaSE5.0. 2006年，JDK 6发布，同年Java开源并建立了openJDK，顺理成章，Hotspot虚拟机成为了OpenJDK中默认的虚拟机。 2007年，Java平台迎来了新伙伴Clojure。 2008年，Oracle收购了BEA，得到了JRockit虚拟机。 2009年，Twitter宣布将后台大部分程序从ruby迁移到Scala，这是Java平台的有一次大规模应用。 2010年，Oracle收购了sun，获得Java商标和最具价值的hotspot虚拟机。此时Oracle拥有市场占用率最高的两款虚拟机hotspot和JRockit，并且计划未来进行整合：HotRockit。 2011年，JDK7发布，在JDK１.7ｕ4中，正式启用了新的垃圾回收器G1. 2017年，JDK9发布，将G1设置为默认GC，替代CMS。 2017同年，IBM的J9开源，形成了现在的open J9社区。 2018年，Android的Java侵权案判决，Google公司赔偿Oracle总计88亿美元。 2018同年，Oracle宣布JavaEE成为历史名词，JDBC、JMS、Servlet赠与Eclipse基金会。 2018同年，JDK11发布，LTS版本的JDK，发布革命性的ZGC，调整JDK授权许可。 2019年，JDK12发布，加入RedHat领导开发的shenandoah GC。 在JDK11之前，OracleJDK还会存在一些openJDK中没有的、闭源的功能。但在JDK11中，openJDK和OracleJDK代码实质上已经达到完全一致的程度。 JVM介绍 ​ 所谓虚拟机(Virtual Machine)，就是一台虚拟的计算机。它是一款软件，用来执行一系列虚拟计算机指令。大体上，虚拟机可以分为系统虚拟机和程序虚拟机。大名鼎鼎的Visual Box,VMware就属于系统虚拟机，它们完全是对物理计算机的仿真，提供了一个可运行完整操作系统的软件平台。程序虚拟机的典型代表就是Java虚拟机，它专门为执行单个计算机程序而设计，在Java虚拟机中执行的指令我们称为Java字节码指令。无论是系统虚拟机还是程序虚拟机，在上面运行的软件都被限制于虚拟机提供的资源中。 ​ Java虚拟机是一台执行Java字节码的虚拟计算机，它拥有独立的运行机制,其运行的Java字节码也未必由Java语言编译而成。JVM平台的各种语言可以共享Java虚拟机带来的跨平台性、优秀的垃圾回器，以及可靠的即时编译器。Java技术的核心就是Java虚拟机（JVM，Java Virtual Machine) ,因为所有的Java程序都运行在Java虚拟机内部。 **作用：**Java虚拟机就是二进制字节码的运行环境，负责装载字节码到其内部，解释/编译为对应平台上的机器指令执行。每一条Java指令，Java虚拟机规汜甲都有详细定义，如怎么取操作数，怎么处理操作数，处理结果放在哪里。 **特点：**一次编译，到处运行；自动内存管理；自动垃圾回收功能 位置： JVM整体结构 Java代码执行流程 ​ JVM架构模型 Java编译器输入的指令流基本上是一种基于栈的指令集架构，另外一种指令集架构则是基于寄存器的指令集架构。 区别: ·基于栈式架构的特点 设计和实现更简单，适用于资源受限的系统; 避开了寄存器的分配难题:使用零地址指令方式分配。 指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈。指令集更小，编译器容易实现。 不需要硬件支持，可移植性更好，更好实现跨平台 基于寄存器架构的特点 典型的应用是x86的二进制指令集:比如传统的pc以及Android的Davlik虚拟机。 指令集架构则完全依赖硬件,可移植性差 性能优秀和执行更高效; 花费更少的指令去完成一项操作。 在大部分情况下，基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主，而基于栈式架构的指令集却是以零地址指令为主。 总结: 由于跨平台性的设计，Java的指令都是根据栈来设计的。不同平台CPu架构不同，所以不能设计为基于寄存器的。优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令。 时至今日，尽管嵌入式平台已经不是Java程序的主流运行平台了（准确的来说HotSpotVM的宿主环境已经不局限于嵌入式平台了)，那么为什么不将 架构更换为基于寄存器的架构呢? 栈: 跨平台性、指令集小、指令多;执行性能比寄存器差 JVM生命周期 启动 Java虚拟机的启动是通过引导类加载器(bootstrap class loader)创建一个初始类(initial class)来完成的，这个类是由虚拟机的具体实现指定的 执行 一个运行中的Java虚拟机有着一个清晰的任务:执行Java程序。 程序开始执行时他才运行，程序结束时他就停止。 执行一个所谓的Java程序的时候，真真正正在执行的是一个叫做Java虚拟机的进程。 退出 有如下的几种情况:。程序正常执行结束 ·程序在执行过程中遇到了异常或错误而异常终止·由于操作系统出现错误而导致Java虚拟机进程终止 ·某线程调用Runtime类或system类的exit方法，或Runtime类的halt方法，并且Java安全管理器也允许这次exit或halt操作。 ·除此之外，JNI ( Java Native Interface)规范描述了用JNI Invocation API来加载或卸载Java虚拟机时，Java虚拟机的退出情况。 JVM发展历程 SUN Classic VM ·早在1996年Java1.0版本的时候，sun公司发布了一款名为Sun Classic VM的Java虚拟机，它同时也是世界上第一款商用Java虚拟机，JDK1.4时完全被淘汰。 ·这款虚拟机内部只提供解释器。 ·如果使用JIT编译器，就需要进行外挂。但是一旦使用了JIT编译器JIT就会接管虚拟机的执行系统。解释器就不再工作。解释器和编译器不能配合工作。 ·现在hotspot内置了此虚拟机。 Exact VM ·为了解决上一个虚拟机问题，jdk1.2时，sun提供了此虚拟机。 Exact Memory Management:准确式内存管理 ·也可以叫Non-conservative/Accurate Memory Management：虚拟机可以知道内存中某个位置的数据具体是什么类型。 具备现代高性能虚拟机的雏形 ·热点探测 ·编译器与解释器混合工作模式I 只在solaris平台短暂使用，其他平台上还是classic vm ·英雄气短，终被Hotspot虚拟机替换 SUN公司的 HotSpot VM HotSpot历史 ·最初由一家名为“Longview Technologies&quot;的小公司设计1997年，此公司被sun收购;2009年，sun公司被甲骨文收购。 ·JDK1.3时，HotSpot VM成为默认虚拟机 ·目前Hotspot占有绝对的市场地位，称霸武林。 不管是现在仍在广泛使用的JDK6，还是使用比例较多的JDK8中，默认的虚拟机都是HotSpot sun/ oracle JDK 和 OpenJDK的默认虚拟机 因此本课程中默认介绍的虚拟机都是HotSpot，相关机制也主要是指HotSpot的GC机制。(比如其他两个商用虚拟机都没有方法区的概念) ·从服务器、桌面到移动端、嵌入式都有应用。 ·名称中的HotSpot指的就是它的热点代码探测技术。 通过计数器找到最具编译价值代码，触发即时编译或栈上替换 通过编译器与解释器协同工作，在最优化的程序响应时间与最佳执行性能中取得平衡 BEA 的JRockit ·专注于服务器端应用 它可以不太关注程序启动速度，因此JRockit内部不包含解析器实现，全部代码都靠即时编译器编译后执行。 ·大量的行业基准测试显示，JRockit JVM是世界上最快的JVM。 使用JRockit产品，客户已经体验到了显著的性能提高（一些超过了70% ）和 硬件成本的减少(达50%）。 ·优势:全面的Java运行时解决方案组合 JRockit面向延迟敏感型应用的解决方案JRockit Real Time提供以毫秒或 微秒级的JVM响应时间，适合财务、军事指挥、电信网络的需要 MissionControl服务套件，它是一组以极低的开销来监控、管理和分析生产 环境中的应用程序的工具。 2008年，BEA被oracle收购。 oracle表达了整合两大优秀虚拟机的工作，大致在JDK 8中完成。整合的方式是在HotSpot的基础上，移植JRockit的优秀特性。 ·高斯林:目前就职于谷歌，研究人工智能和水下机器人 IBM 的J9 全称:IBM Technology for Java virtual Machine，简称IT4J，内部代号:J9 ·市场定位与HotSpot接近，服务器端、桌面应用、嵌入式等多用途VM。 ·广泛用于IBM的各种Java产品。 ·目前，有影响力的三大商用虚拟机之一，也号称是世界上最快的Java虚拟机。 ·2017年左右，IBM发布了开源J9 VM，命名为openJ9，交给Eclipse基金会管理，也称为Eclipse OpenJ9 KVM和cDC/CL.DC Hotspot oracle在Java ME产品线上的两款虚拟机为:CDC/CLDC HotSpot Implementation VM KVM (Kilobyte）是CLDC-HI早期产品 ·目前移动领域地位尴尬，智能手机被Android和ioS二分天下。 .KVM简单、轻量、高度可移植，面向更低端的设备上还维持自己的一片市场 智能控制器、传感器I 老人手机、经济欠发达地区的功能手机 .所有的虚拟机的原则:一次编译，到处运行。 Azul VM ·前面三大“高性能Java虚拟机”使用在通用硬件平台上 ·这里Azul VM和BEA Liquid VM是与特定硬件平台绑定、软硬件配合的专有虚拟机 高性能Java虚拟机中的战斗机。 Azul VM是Azul systems公司在HotSpot基础上进行大量改进，运行于Azul systems公司的专有硬件vega系统上的Java虚拟机。 ·每个Azul VM实例都可以管理至少数十个CPu和数百GB内存的硬件资源，并提供在巨大内存范围内实现可控的Gc时间的垃圾收集器、专有硬件优化的线程调度等优秀特性。 2010年，Azul systems公司开始从硬件转向软件，发布了自己的ZingJVM，可以在通用x86平台上提供接近于Vega系统的特性。T Liquid VM ·高性能Java虚拟机中的战斗机。 ·BEA公司开发的，直接运行在自家Hypervisor系统上 ·Liquid VM即是现在的JRockit VE(Virtual Edition） ,LiquidVM不需要操作系统的支持，或者说它自己本身实现了一个专用操作系统的必要功能，如线程调度、文件系统、网络支持等。 ·随着JRockit虚拟机终止开发，Liquid VM项目也停止了。 Apache Harmony Apache也曾经推出过与JDK 1.5和JDK 1.6兼容的Java运行平台Apache Harmony。 ·它是IBM和Intel联合开发的开源JVM，受到同样开源的openJDK的压制， sun坚决不让Harmony获得JCP认证，最终于2011年退役，IBM转而参与OpenJDK ·虽然目前并没有Apache Harmony被大规模商用的案例，但是它的Java 类库代码吸纳进了Android SDK。 Microsoft JVM ·微软为了在IE3浏览器中支持Java Applets，开发了Microsoft JVM。·只能在window平台下运行。但确是当时windows下性能最好的Java VM.. 1997年，sun以侵犯商标、不正当竞争罪名指控微软成功，赔了sun很多钱。微软在windowsXP SP3中抹掉了其VM。现在windows上安装的jdk都是HotSpot。l TaobaoJVM ·由AliJVM团队发布。阿里，国内使用Java最强大的公司，覆盖云计算、金雷生切一电商等众多领域，需要解决高并发、高可用、分布式的复合问题。有大重的开源广的。 ·基于openJDK开发了自己的定制版本AlibabaJDK，简称AJDK。是整个阿里Java体系的基石。 ·基于openJDK HotSpot VM 发布的国内第一个优化、深度定制且开源的高性能服务器版Java虚拟机。 创新的GCIH (Gc invisible heap ）技术实现了off-heap ，即将生命周期较长的Java对象从heap中移到heap之外，并且GC不能管理GCIH内部的Java 对象，以此达到降低GC的回收频率和提升GC 的回收效率的目的。 GCIH 中的对象还能够在多个Java虚拟机进程中实现共享 使用crc32指令实现JVM intrinsic降低JNI 的调用开销 PMU hardware 的Java profiling tool和诊断协助功能 针对大数据场景的ZenGC . taobao vm应用在阿里产品上性能高，硬件严重依赖intel的cpu，损失了兼容性，但提高了性能 目前已经在淘宝、天猫上线，把oracle 官方JVM版本全部替换了。 Dalvik VM : ·谷歌开发的，应用于Android系统，并在Android2.2中提供了JIT，发展迅猛。.Dalvik VM只能称作虚拟机，而不能称作“Java虚拟机”，它没有遵循 Java虚拟机规范 ·不能直接执行Java 的class 文件·基于寄存器架构，不是jvm的栈架构。 ·执行的是编译以后的dex(Dalvik Executable）文件。执行效率比较高 它执行的dex (Dalvik Executable）文件可以通过class文件转化而来，使用Java语法编写应用程序，可以直接使用大部分的Java API等。 ·Android 5.0使用支持提前编译(Ahead of Time Compilation，AOT）的ARTVM替换Dalvik VM。 Graal VM . 2018年4月，oracle Labs公开了Graal VM，号称&quot;Run Programs Faster Anywhere&quot;，勃勃野心。与1995年java的”write once，run anywhere&quot;遥相呼应。 Graal VM在HotSpot VM基础上增强而成的跨语言全栈虚拟机，可以作为“任何语言”的运行平台使用。语言包括: Java、Scala、Groovy、Kotlin;C、C++ Javascript、Ruby、Python、R等 ·支持不同语言中混用对方的接口和对象，支持这些语言使用已经编写好的本地库文件工作原理是将这些语言的源代码或源代码编译后的中间格式，通过解释器转换为能被Graal VM接受的中间表示。Graal VM提供Truffle工具集快速构建面向一种新语言的解释器。在运行时还能进行即时编译优化，获得比原生编译器更优秀的执行效率。 如果说HotSpot有一天真的被取代，Graal VM希望最大。但是Java的软件生态没有丝毫变化。 二、类加载子系统 1.内存简图 2.类加载器 ​ 类加载器子系统负责从文件系统或者网络中加载class文件，class文件在文件开头有特定的文件标识。 ClassLoader只负责class文件的加载，至于它是否可以运行，则由ExecutionEngine决定。 加载的类信息存放于一块称为方法区的内存空间。除了类的信息外，方法区中还会存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息是Class文件中常量池部分的内存映射) 3.类加载器ClassLoader角色 class file 存在于本地硬盘上，可以理解为设计师画在纸上的模板，而最终这个模板在执行的时候是要加载到JVM当中来根据这个文件实例化出n个一模一样的实例。 class file 加载到JVM中，被称为DNA元数据模板，放在方法区。 在.class文件-&gt; JVM -&gt;最终成为元数据模板，此过程就要一个运输工具(类装载器class Loader)，扮演一个快递员的角色。 获取ClassLoader途经 4.类加载过程 加载(Loading): 1．通过一个类的全限定名获取定义此类的二进制字节流 2．将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 3．在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口 补充:加载.class文件的方式 ·从本地系统中直接加载 ·通过网络获取，典型场景: web Applet ·从zip压缩包中读取，成为日后jar、 war格式的基础·运行时计算生成，使用最多的是:动态代理技术 ·由其他文件生成，典型场景:JSP应用 ·从专有数据库中提取.class文件,比较少见 ·从加密文件中获取，典型的防class文件被反编译的保护措施 链接 验证(Verify): ·目的在于确保class文件的字节流中包含信息符合当前虚拟机要求，保证被加载类的正确性，不会危害虚拟机自身安全。 ·主要包括四种验证，文件格式验证，元数据验证，字节码验证，符号引用验证。 准备(Prepare): ·为类变量分配内存并且设置该类变量的默认初始值，即零值。 这里不包含用final修饰的static，因为final在编译的时候就会分配了，准备阶段会显式链初始化; ·这里不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量是会随着对象一起分配到Java堆中。 解析(Resolve) : ·将常量池内的符号引用转换为直接引用的过程。 ·事实上，解析操作往往会伴随着JVM在执行完初始化之后再执行。 ·符号引用就是一组符号来描述所引用的目标。符号引用的字面量形式明确定义在《java虚拟机规范》的class文件格式中。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 ·解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的 CONSTANT Class info、CONSTANT Fieldref_info、CONSTANT _Methodref_info等.。 初始化: ·初始化阶段就是执行类构造器方法 ()的过程。 ·此方法不需定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来。 ·构造器方法中指令按语句在源文件中出现的顺序执行。 . ()不同于类的构造器。(关联:构造器是虚拟机视角下的( ))·若该类具有父类，JVM会保证子类的()执行前，父类的 ()已经执行完毕。 ·虚拟机必须保证一个类的 ()方法在多线程下被同步加锁。 5.类加载器分类 JVM支持两种类型的类加载器，分别为引导类加载器（Bootstrap ClassLoader）和自定义类加载器(User-Defined ClassLoader)。 ·从概念上来讲，自定义类加载器一般指的是程序中由开发人员自定义的一类类加载器，但是Java虚拟机规范却没有这么定义，而是将所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器。 ·无论类加载器的类型如何划分，在程序中我们最常见的类加载器始终只有3个，如下所示: 虚拟机自带的加载器 ·启动类加载器（引导类加载器，Bootstrap classLoader) 这个类加载使用C/C++语言实现的，嵌套在JVM内部。 它用来加载Java的核心库（JAVA HOME/jre/lib/rt.jar、resources.jar或sun.boot.class.path路径下的内容），用于提供JVM自身需要的类 并不继承自java.lang.classLoader，没有父加载器。加载扩展类和应用程序类加载器，并指定为他们的父类加载器。 出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类 ·扩展类加载器（Extension ClassLoader) Java语言编写，由sun.misc.Launcher$ExtClassLoader实现。派生于classLoader类 父类加载器为启动类加载器 从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre/lib/ext子目录（扩展目录)下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。 ·应用程序类加载器（系统类加载器，AppClassLoader) java语言编写，由sun.misc.Launcher$AppclassLoader实现&gt;派生于classLoader类 父类加载器为扩展类加载器 它负责加载环境变量classpath或系统属性java.class.path指定路径下的类库 该类加载是程序中默认的类加载器，一般来说，Java应用的类都是由它来完成加载 通过classLoader#getSystemClassLoader ()方法可以获取到该类加载器 用户自定义类加载器 ·在Java的日常应用程序开发中，类的加载几乎是由上述3种类加载器相互 配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式。 .为什么要自定义类加载器? 隔离加载类 修改类加载的方式 扩展加载源 防止源码泄漏 用户自定义类加载器实现步骤: 1.开发人员可以通过继承抽象类java.lang.classLoader类的方式，实现自己的类加载器，以满足一些特殊的需求 2.在JDK1.2之前，在自定义类加载器时，总会去继承classLoader类并重写loadClass ()方法，从而实现自定义的类加载类，但是在JDK1.2之后已不再建议用户去覆盖loadclass ()方法，而是建议把自定义的类加载逻辑写在findclass ()方法中 3．在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findclass ()方法及其获取字节码流的方式，使自定义类加载器编写更加简洁。 6.双亲委派机制 ​ Java虚拟机对class文件采用的是按需加载的方式，也就是说当需要使用该类时才会将它的class文件加载到内存生成class对象。而且加载某个类的class文件时，Java虚拟机采用的是双亲委派模式，即把请求交由父类处理,它是一种任务委派模式。 工作原理 1)如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行; 2)如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器; 3)如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式。 双亲委派优势 避免类的重复加载 保护程序安全，防止核心API被随意篡改 自定义类:java. lang. string 自定义类: java . lang. shkStart java.lang. securityException: Prohibited package name: java.lang 沙箱安全机制 ​ 自定义string类，但是在加载自定义String类的时候会率先使用引导类加载器加载，而引导类加载器在加载的过程中会先加载jdk自带的文件(rt.jar包中java\\lang\\String.class)，报错信息说没有main方法，就是因为加载的是rt.jar包中的String类。这样可以保证对java核心源代码的保护，这就是沙箱安全机制。 7.其他 ·在JVM中表示两个class对象是否为同一个类存在两个必要条件: 类的完整类名必须一致，包括包名。 加载这个类的classLoader(指classLoader实例对象)必须相同。 ·换句话说，在VM中，即使这两个类对象(class对象)来源同一个class文件，被同一个虚拟机所加载，但只要加载它们的ClassLoader实例对象不同，那么这两个类对象也是不相等的。 对类加载其的引用 JVM必须知道一个类型是由启动加载器加载的还是由用户类加载器加载的。如果一个类型是由用户类加载器加载的，那么JVM会将这个类加载器的一个引用作为类型信息的一部分保存在方法区中。当解析一个类型到另一个类型的引用的时候，JVM需要保证这两个类型的类加载器是相同的。 类的主动使用和被动使用 Java程序对类的使用方式分为:主动使用和被动使用。·主动使用，又分为七种情况: ·创建类的实例 ·访问某个类或接口的静态变量，或者对该静态变量赋值 ·调用类的静态方法 ·反射（比如: Class.forName ( &quot;com.atguigu . Test&quot;) )&gt; ·初始化一个类的子类 ·Java虚拟机启动时被标明为启动类的类 ·JDK 7开始提供的动态语言支持:java . lang.invoke.MethodHandle实例的解析结果REF getstatic、REF putstatic、REF_invokestatic句柄对应的类没有初始化，则初始化 除了以上七种情况，其他使用Java类的方式都被看作是对类的被动使用，都不会导致类的初始化。 三、运行时数据区概述及线!程 四、程序计数器 五、虚拟机栈 六、本地方法接口 七、本地方法栈. 八、堆 九、方法区 十、直接内存 十一、执行引擎 十二、StringTable 十三、垃圾回收概述 十四、垃圾回收相关算法 十五、垃圾回收相关概念 十六、垃圾回收器","link":"/2021/11/16/Draft/2021/JVM%20%E4%B8%8E%E4%B8%8A%E5%B1%82%E6%8A%80%E6%9C%AF/"},{"title":"SpringCloud","text":"新学四问 WHY【与前代优化了什么，弥补了什么空白】微服务，主流 WHAT【框架，思维导图，主题框架】eureka注册中心，Gateway网关，Ribbon负载均衡，Feign服务调用，Hystrix熔断器等，springcloudalibaba HOW【如何记忆，学习资源】:bilibili，官网 LEVEL【不是每个都学精】当前阶段熟练运用 Spring Cloud 【Hoxton】 简介 1. 系统架构演变 随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此也不断的演 进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google 带领下来势汹涌的Service Mesh。 1.1. 集中式架构 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。 优点： 系统开发速度快 维护成本低 适用于并发要求较低的系统 缺点： 代码耦合度高，后期维护困难 无法针对不同模块进行针对性优化 无法水平扩展 单点容错率低，并发能力差 1.2. 垂直拆分 ​ 当访问量逐渐增大，单一应用无法满足需求，此时为了应对更高的并发和业务需求，我们根据业务功能对系统进行拆 分： 优点： 系统拆分实现了流量分担，解决了并发问题 可以针对不同模块进行优化 方便水平扩展，负载均衡，容错率提高 缺点： 系统间相互独立，会有很多重复开发工作，影响开发效率 1.3. 分布式服务 ​ 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。 优点： 将基础服务进行了抽取，系统间相互调用，提高了代码复用和开发效率 缺点： 系统间耦合度变高，调用关系错综复杂，难以维护 1.4. 面向服务架构（SOA） ​ SOA（Service Oriented Architecture）面向服务的架构：它是一种设计方法，其中包含多个服务， 服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在与操作系统进程中。各个服务之间 通过网络调用。SOA结构图： ESB（企业服务总线），简单 来说 ESB 就是一根管道，用来连接各个服务节点。为了集 成不同系统，不同协议的服务，ESB 做了消息的转化解释和路由工作，让不同的服务互联互通。 SOA缺点：每个供应商提供的ESB产品有偏差，自身实现较为复杂；应用服务粒度较大，ESB集成整合所有服务和协 议、数据转换使得运维、测试部署困难。所有服务都通过一个通路通信，直接降低了通信速度。 1.5. 微服务架构 ​ 微服务架构是使用一套小服务来开发单个应用的方式或途径，每个服务基于单一业务能力构建，运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API，并能够通过自动化部署机制来独立部署。这些服务可以使用不同的编程语言实现，以及不同数据存储技术，并保持最低限度的集中式管理。微服务结构图： API Gateway网关是一个服务器，是系统的唯一入口。为每个客户端提供一个定制的API。API网关核心是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。如它还可以具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。通常，网关提供RESTful/HTTP的方式访问服务。而服务端通过服务注册中心进行服务注册和管理。 微服务的特点： 单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责 微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。 面向服务：面向服务是说每个服务都要对外暴露Rest风格服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。 自治：自治是说服务间互相独立，互不干扰 团队独立：每个服务都是一个独立的开发团队，人数不能过多。 技术独立：因为是面向服务，提供Rest接口，使用什么技术没有别人干涉 前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动端开 发不同接口 数据库分离：每个服务都使用自己的数据源 部署独立：服务间虽然有调用，但要做到服务重启不影响其它服务。有利于持续集成和 持续交付。每个服务都是独立的组件，可复用，可替换，降低耦合，易维护 微服务架构与SOA都是对系统进行拆分；微服务架构基于SOA思想，可以把微服务当做去除了ESB的SOA。ESB是SOA架构中的中心总线，设计图形应该是星形的，而微服务是去中心化的分布式软件架构。两者比较类似，但其实也有一些差别： 2. 服务调用方式 2.1. RPC和HTTP 无论是微服务还是SOA，都面临着服务间的远程调用。那么服务间的远程调用方式有哪些呢？ 常见的远程调用方式有以下2种： RPC：Remote Produce Call远程过程调用，RPC基于Socket，工作在会话层。自定义数据格式，速度快，效率高。早期的webservice，现在热门的dubbo，都是RPC的典型代表 Http：http其实是一种网络传输协议，基于TCP，工作在应用层，规定了数据传输的格式。现在客户端浏览器与服务端通信基本都是采用Http协议，也可以用来进行远程服务调用。缺点是消息封装臃肿，优势是对服务的提供和调用方没有任何技术限定，自由灵活，更符合微服务理念。 现在热门的Rest风格，就可以通过http协议来实现。 区别：RPC的机制是根据语言的API（language API）来定义的，而不是根据基于网络的应用来定义的。 如果你们公司全部采用Java技术栈，那么使用Dubbo作为微服务架构是一个不错的选择。 相反，如果公司的技术栈多样化，而且你更青睐Spring家族，那么Spring Cloud搭建微服务是不二之选。在我们的项目中，会选择Spring Cloud套件，因此会使用Http方式来实现服务间调用。 2.2. Http客户端工具 既然微服务选择了Http，那么我们就需要考虑自己来实现对请求和响应的处理。不过开源世界已经有很多的http客户端工具，能够帮助我们做这些事情，例如： HttpClient OKHttp URLConnection 不过这些不同的客户端，API各不相同。而Spring也有对http的客户端进行封装，提供了工具类叫RestTemplate。 2.3. Spring的RestTemplate Spring提供了一个RestTemplate模板工具类，对基于Http的客户端进行了封装，并且实现了对象与json的序列化和 反序列化，非常方便。RestTemplate并没有限定Http的客户端类型，而是进行了抽象，目前常用的3种都有支持： HttpClient OkHttp JDK原生的URLConnection（默认的） 3.Springcloud综述 版本命名：伦敦地铁站字母顺序 实验环境 停更、升级、替换 父工程创建 创建工程前准备 约定》配置》编码 编码UTF-8全套 作用 注解生效激活 作用 JAVA编译版本 文件过滤 作用，关闭对应文件idea可见 Eureka【大楼老板】 Spring Cloud [Finchley] ​ 一系列框架有序集合，封装后屏蔽了复杂的配置和实现原理。Spring Cloud为开发人员提供了工具，以快速构建分布式系统中的一些常见模式（例如，配置管理，服务发现，断路器，智能路由，微代理，控制总线，一次性令牌，全局锁，领导选举，分布式会话，群集状态）。分布式系统的协调导致样板式样，并且使用Spring Cloud开发人员可以快速站起来实现这些样板的服务和应用程序。它们将在任何分布式环境中都能很好地工作，包括开发人员自己的笔记本电脑，裸机数据中心以及诸如Cloud Foundry之类的托管平台。 1.系统架构演变 graph LR; 1[集中式架构] --> 2[垂直拆分] 2 --> 3[分布式服务] 3 --> 4[SOA面向服务架构] 4 --> 5[微服务架构] 微服务架构 一套使用小服务或者单一业务来开发单个应用的方式或途径。 微服务架构特点： 单一职责 服务粒度小 面向服务（对外暴露REST api） 服务之间相互独立 与使用ESB的SOA架构的区别： 微服务架构没有使用ESB，有服务治理注册中心；业务粒度小。 2.服务调用方式 RPC：基于socket，速度快，效率高；webservice、dubbo HTTP：基于TCP，封装比较臃肿；对服务和调用方没有任何技术、语言的限定，自由灵活；RESTful，Spring Cloud 一般情况下有如下三种http客户端工具类包都可以方便的进行http服务调用： httpClient okHttp JDK原生URLConnection spring 提供了RestTemplate的工具类对上述的3种http客户端工具类进行了封装，可在spring项目中使用RestTemplate进行服务调用。 小结： 12345678910111213141516@RunWith(SpringRunner.class)@SpringBootTestpublic class RestTemplateTest { @Autowired private RestTemplate restTemplate; @Test public void test(){ String url = &quot;http://localhost/user/8&quot;; //restTemplate可以对json格式字符串进行反序列化 User user = restTemplate.getForObject(url, User.class); System.out.println(user); }} 3.SpringCloud概述 整合的组件可以有很多组件；常见的组件有：eureka注册中心，Gateway网关，Ribbon负载均衡，Feign服务调用，Hystrix熔断器。在有需要的时候项目添加对于的启动器依赖即可。 版本特征：以英文单词命名（伦敦地铁站名） 4.创建微服务工程 父工程springcloud：添加spring boot父坐标和管理其它组件的依赖 用户服务工程user-service：整合mybatis查询数据库中用户数据；提供查询用户服务 服务消费工程consumer-demo：利用查询用户服务获取用户数据并输出到浏览器 5.搭建配置Service工程 添加启动器依赖（web、通用Mapper）； 创建启动引导类和配置文件； 修改配置文件中的参数； 编写测试代码（UserMapper，UserService，UserController）； 测试 6.搭建配置Client工程 添加启动器依赖； 创建启动引导类（注册RestTemplate）和配置文件； 编写测试代码（ConsumerController中使用restTemplate访问服务获取数据） 测试 7.问题 服务管理 如何自动注册和发现 如何实现状态监管 如何实现动态路由 服务如何实现负载均衡 服务如何解决容灾问题 服务如何实现统一配置 上述问题通过springcloud各种组件解决 8.Eureka Eureka的主要功能是进行服务管理，定期检查服务状态，返回服务地址列表。 8.1Eureka-server Eureka是服务注册中心，只做服务注册；自身并不提供服务也不消费服务。可以搭建web工程使用Eureka，可以使用Spring Boot方式搭建。 搭建步骤： 创建工程； 添加启动器依赖； 编写启动引导类（添加Eureka的服务注解）和配置文件； 修改配置文件（端口，应用名称...）； 启动测试 8.2服务注册与发现 服务注册：在服务提供工程user-service上添加Eureka客户端依赖；自动将服务注册到EurekaServer服务地址列表。 添加依赖； 改造启动引导类；添加开启Eureka客户端发现的注解； 修改配置文件；设置Eureka 服务地址 服务发现：在服务消费工程consumer-demo上添加Eureka客户端依赖；可以使用工具类根据服务名称获取对应的服务地址列表。 添加依赖； 改造启动引导类；添加开启Eureka客户端发现的注解； 修改配置文件；设置Eureka 服务地址； 改造处理器类Controller，可以使用工具类DiscoveryClient根据服务名称获取对应服务地址列表。 8.3高可用配置 ​ 将Eureka Server作为一个服务注册到其它Eureka Server，这样多个Eureka Server之间就能够互相发现对方，同步服务，实现Eureka Server集群。 9.负载均衡Ribbon Ribbon提供了轮询、随机两种负载均衡算法（默认是轮询）可以实现从地址列表中使用负载均衡算法获取地址进行服务调用。 9.1Ribbon应用 在实例化RestTemplate的时候使用@LoadBalanced，服务地址直接可以使用服务名。 10.熔断器Hystrix（豪猪） Hystrix是一个延迟和容错库，用于隔离访问远程服务，防止出现级联失败。 10.1线程隔离&amp;服务降级 Hystrix解决雪崩效应： 线程隔离：用户请求不直接访问服务，而是使用线程池中空闲的线程访问服务，加速失败判断时间。 服务降级：及时返回服务调用失败的结果，让线程不因为等待服务而阻塞。 小结： 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 开启熔断 降级逻辑 12345678910111213141516171819202122232425262728293031323334353637@RestController@RequestMapping(&quot;/consumer&quot;)@Slf4j@DefaultProperties(defaultFallback = &quot;defaultFallback&quot;)public class ConsumerController { @Autowired private RestTemplate restTemplate; @Autowired private DiscoveryClient discoveryClient; @GetMapping(&quot;/{id}&quot;) //@HystrixCommand(fallbackMethod = &quot;queryByIdFallback&quot;) @HystrixCommand public String queryById(@PathVariable Long id){ /*String url = &quot;http://localhost:9091/user/&quot;+id; //获取eureka中注册的user-service的实例 List&lt;ServiceInstance&gt; serviceInstances = discoveryClient.getInstances(&quot;user-service&quot;); ServiceInstance serviceInstance = serviceInstances.get(0); url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() + &quot;/user/&quot; + id;*/ String url = &quot;http://user-service/user/&quot; + id; return restTemplate.getForObject(url, String.class); } public String queryByIdFallback(Long id){ log.error(&quot;查询用户信息失败。id：{}&quot;, id); return &quot;对不起，网络太拥挤了！&quot;; } public String defaultFallback(){ return &quot;默认提示：对不起，网络太拥挤了！&quot;; }} 修改超时配置 1234567hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 2000 10.2服务熔断 ​ 在服务熔断中，使用的熔断器，也叫断路器，其英文单词为：Circuit Breaker ​ 熔断机制与家里使用的电路熔断原理类似；当如果电路发生短路的时候能立刻熔断电路，避免发生灾难。在分布式系 统中应用服务熔断后；服务调用方可以自己进行判断哪些服务反应慢或存在大量超时，可以针对这些服务进行主动熔 断，防止整个系统被拖垮。 ​ Hystrix的服务熔断机制，可以实现弹性容错；当服务请求情况好转之后，可以自动重连。通过断路的方式，将后续 请求直接拒绝，一段时间（默认5秒）之后允许部分请求通过，如果调用成功则回到断路器关闭状态，否则继续打 开，拒绝请求的服务。 Hystrix的熔断状态机模型： 状态机有3个状态： Closed：关闭状态（断路器关闭），所有请求都正常访问。 Open：打开状态（断路器打开），所有请求都会被降级。Hystrix会对请求情况计数，当一定时间内失败请求百 分比达到阈值，则触发熔断，断路器会完全打开。默认失败比例的阈值是50%，请求次数最少不低于20次。 Half Open：半开状态，不是永久的，断路器打开后会进入休眠时间（默认是5S）。随后断路器会自动进入半开 状态。此时会释放部分请求通过，若这些请求都是健康的，则会关闭断路器，否则继续保持打开，再次进行休 眠计时。 11.服务消费者（Feign） 11.1简介 ​ Feign是一个声明式的伪Http客户端，它使得写Http客户端变得更简单。使用Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用Feign 注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。Feign默认集成了Ribbon，并和Eureka结合，默认实现了负载均衡的效果。 简而言之： Feign 采用的是基于接口的注解 Feign 整合了ribbon，具有负载均衡的能力 整合了Hystrix，具有熔断的能力 12.断路器（Hystrix） ​ 在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以相互调用（RPC），在Spring Cloud可以用RestTemplate+Ribbon和Feign来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证100%可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的“雪崩”效应。 为了解决这个问题，业界提出了断路器模型。 12.1断路器简介 ​ Netflix has created a library called Hystrix that implements the circuit breaker pattern. In a microservice architecture it is common to have multiple layers of service calls.Netflix. 开源了Hystrix组件，实现了断路器模式，SpringCloud对这一组件进行了整合。 在微服务架构中，一个请求需要调用多个服务是非常常见的。较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值（Hystric 是5秒20次） 断路器将会被打开。断路打开后，可用避免连锁故障，fallback方法可以直接返回一个固定值。 13.路由网关(zuul) ​ Zuul的主要功能是路由转发和过滤器。路由功能是微服务的一部分，比如／api/user转发到到user服务，/api/shop转发到到shop服务。zuul默认和Ribbon结合实现了负载均衡的功能。 zuul有以下功能： Authentication Insights Stress Testing Canary Testing Dynamic Routing Service Migration Load Shedding Security Static Response handling Active/Active traffic management 服务过滤 filterType：返回一个字符串代表过滤器的类型，在zuul中定义了四种不同生命周期的过滤器类型，具体如下： pre：路由之前 routing：路由之时 post： 路由之后 error：发送错误调用 filterOrder：过滤的顺序 shouldFilter：这里可以写逻辑判断，是否要过滤，本文true,永远过滤。 run：过滤器的具体逻辑。可用很复杂，包括查sql，nosql去判断该请求到底有没有权限访问。 14.分布式配置中心(Spring Cloud Config) ​ 在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。 15. 高可用的分布式配置中心(Spring Cloud Config) ​ 当服务实例很多时，都从配置中心读取文件，这时可以考虑将配置中心做成一个微服务，将其集群化，从而达到高可用 16.消息总线(Spring Cloud Bus) ​ Spring Cloud Bus 将分布式的节点用轻量的消息代理连接起来。它可以用于广播配置文件的更改或者服务之间的通讯，也可以用于监控。本文要讲述的是用Spring Cloud Bus实现通知微服务架构的配置文件的更改。【修改配置文件，无需重启】 准备：安装rabbitMq 17.服务链路追踪(Spring Cloud Sleuth) ​ 微服务架构上通过业务来划分服务的，通过REST调用，对外暴露的一个接口，可能需要很多个服务协同才能完成这个接口功能，如果链路上任何一个服务出现问题或者网络超时，都会形成导致接口调用失败。随着业务的不断扩张，服务之间互相调用会越来越复杂。 术语 Span：基本工作单元，例如，在一个新建的span中发送一个RPC等同于发送一个回应请求给RPC，span通过一个64位ID唯一标识，trace以另一个64位ID表示，span还有其他数据信息，比如摘要、时间戳事件、关键值注释(tags)、span的ID、以及进度ID(通常是IP地址) span在不断的启动和停止，同时记录了时间信息，当你创建了一个span，你必须在未来的某个时刻停止它。 Trace：一系列spans组成的一个树状结构，例如，如果你正在跑一个分布式大数据工程，你可能需要创建一个trace。 Annotation：用来及时记录一个事件的存在，一些核心annotations用来定义一个请求的开始和结束 cs - Client Sent -客户端发起一个请求，这个annotion描述了这个span的开始 sr - Server Received -服务端获得请求并准备开始处理它，如果将其sr减去cs时间戳便可得到网络延迟 ss - Server Sent -注解表明请求处理的完成(当请求返回客户端)，如果ss减去sr时间戳便可得到服务端需要的处理请求时间 cr - Client Received -表明span的结束，客户端成功接收到服务端的回复，如果cr减去cs时间戳便可得到客户端从服务端获取回复的所有所需时间 将Span和Trace在一个系统中使用Zipkin注解的过程图形化： 18.高可用的服务注册中心 ​ 服务注册中心Eureka Server，是一个实例，当成千上万个服务向它注册的时候，它的负载是非常高的，这在生产环境上是不太合适的，这篇文章主要介绍怎么将Eureka Server集群化。Eureka通过运行多个实例，使其更具有高可用性。事实上，这是它默认的熟性，你需要做的就是给对等的实例一个合法的关联serviceurl。 参考文献：黑马课程笔记，方志朋的博客","link":"/2021/02/25/Draft/2021/SpringCloud/"},{"title":"魑魅先生 | 计算机网络","text":"1. 网络层次划分 OSI/RM模型（Open System Interconnection/Reference Model）开放系统互联参考模型 2. OSI七层网络模型 OSI七层网络模型 1）物理层（Physical Layer） · 激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性。该层为上层协议提供了一个传输数据的可靠的物理媒体。简单的说，物理层确保原始的数据可在各种物理媒体上传输。两个重要的设备名称，中继器（Repeater，放大器），集线器。 2）数据链路层（Data Link Layer） · 数据链路层在物理层提供的服务的基础上向网络层提供服务，其最基本的服务是将源自网络层来的数据可靠地传输到相邻节点的目标机网络层。为达到这一目的，数据链路必须具备一系列相应的功能，主要有：如何将数据组合成数据块，在数据链路层中称这种数据块为帧（frame），帧是数据链路层的传送单位；如何控制帧在物理信道上的传输，包括如何处理传输差错，如何调节发送速率以使与接收方相匹配；以及在两个网络实体之间提供数据链路通路的建立、维持和释放的管理。数据链路层在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。 · 有关数据链路层的重要知识点：1&gt; 数据链路层为网络层提供可靠的数据传输；2&gt; 基本数据单位为帧；3&gt; 主要的协议：以太网协议；4&gt; 两个重要设备名称：网桥和交换机。 3）网络层（Network Layer） · 实现两个端系统之间的数据透明传送，具体功能包括寻址和路由选择、连接的建立、保持和终止等。它提供的服务使传输层不需要了解网络中的数据传输和交换技术。如果您想用尽量少的词来记住网络层，那就是&quot;路径选择、路由及逻辑寻址&quot;。网络层中涉及众多的协议，其中包括最重要的协议，也是TCP/IP的核心协议——IP协议。IP协议非常简单，仅仅提供不可靠、无连接的传送服务。IP协议的主要功能有：无连接数据报传输、数据报路由选择和差错控制。与IP协议配套使用实现其功能的还有地址解析协议ARP、逆地址解析协议RARP、因特网报文协议ICMP、因特网组管理协议IGMP。 · 具体的协议我们会在接下来的部分进行总结，有关网络层的重点为： 1&gt; 网络层负责对子网间的数据包进行路由选择。此外，网络层还可以实现拥塞控制、网际互连等功能； 2&gt; 基本数据单位为IP数据报； 3&gt; 包含的主要协议： IP协议（Internet Protocol，因特网互联协议）; ICMP协议（Internet Control Message Protocol，因特网控制报文协议）; ARP协议（Address Resolution Protocol，地址解析协议）; RARP协议（Reverse Address Resolution Protocol，逆地址解析协议）。 4&gt; 重要的设备：路由器。 4）传输层（Transport Layer） · 第一个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。 传输层的任务是根据通信子网的特性，最佳的利用网络资源，为两个端系统的会话层之间，提供建立、维护和取消传输连接的功能，负责端到端的可靠数据传输。在这一层，信息传送的协议数据单元称为段或报文。 网络层只是根据网络地址将源结点发出的数据包传送到目的结点，而传输层则负责将数据可靠地传送到相应的端口。 · 重点：1&gt; 传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输以及端到端的差错控制和流量控制问题；2&gt; 包含的主要协议：TCP协议（Transmission Control Protocol，传输控制协议）、UDP协议（User Datagram Protocol，用户数据报协议）；3&gt; 重要设备：网关。 5）会话层 · 会话层管理主机之间的会话进程，即负责建立、管理、终止进程之间的会话。会话层还利用在数据中插入校验点来实现数据的同步。 6）表示层 · 表示层对上层数据或信息进行变换以保证一个主机应用层信息可以被另一个主机的应用程序理解。表示层的数据转换包括数据的加密、压缩、格式转换等。 7）应用层 · 为操作系统或网络应用程序提供访问网络服务的接口。 · 会话层、表示层和应用层重点： · 1&gt; 数据传输基本单位为报文； · 2&gt; 包含的主要协议：FTP（文件传送协议）、Telnet（远程登录协议）、DNS（域名解析协议）、SMTP（邮件传送协议），POP3协议（邮局协议），HTTP协议（Hyper Text Transfer Protocol）。 3. IP地址 1）网络地址 IP地址由网络号（包括子网号）和主机号组成，网络地址的主机号为全0，网络地址代表着整个网络。 2）广播地址 广播地址通常称为直接广播地址，是为了区分受限广播地址。 广播地址与网络地址的主机号正好相反，广播地址中，主机号为全1。当向某个网络的广播地址发送消息时，该网络内的所有主机都能收到该广播消息。 3）组播地址 D类地址就是组播地址。 先回忆下A，B，C，D类地址吧： A类地址以0开头，第一个字节作为网络号，地址范围为：0.0.0.0~127.255.255.255；(modified @2016.05.31) B类地址以10开头，前两个字节作为网络号，地址范围是：128.0.0.0~191.255.255.255; C类地址以110开头，前三个字节作为网络号，地址范围是：192.0.0.0~223.255.255.255。 D类地址以1110开头，地址范围是224.0.0.0~239.255.255.255，D类地址作为组播地址（一对多的通信）； E类地址以1111开头，地址范围是240.0.0.0~255.255.255.255，E类地址为保留地址，供以后使用。 注：只有A,B,C有网络号和主机号之分，D类地址和E类地址没有划分网络号和主机号。 4）255.255.255.255 该IP地址指的是受限的广播地址。受限广播地址与一般广播地址（直接广播地址）的区别在于，受限广播地址只能用于本地网络，路由器不会转发以受限广播地址为目的地址的分组；一般广播地址既可在本地广播，也可跨网段广播。例如：主机192.168.1.1/30上的直接广播数据包后，另外一个网段192.168.1.5/30也能收到该数据报；若发送受限广播数据报，则不能收到。 注：一般的广播地址（直接广播地址）能够通过某些路由器（当然不是所有的路由器），而受限的广播地址不能通过路由器。 5）0.0.0.0 常用于寻找自己的IP地址，例如在我们的RARP，BOOTP和DHCP协议中，若某个未知IP地址的无盘机想要知道自己的IP地址，它就以255.255.255.255为目的地址，向本地范围（具体而言是被各个路由器屏蔽的范围内）的服务器发送IP请求分组。 6）回环地址 127.0.0.0/8被用作回环地址，回环地址表示本机的地址，常用于对本机的测试，用的最多的是127.0.0.1。 7）A、B、C类私有地址 私有地址(private address)也叫专用地址，它们不会在全球使用，只具有本地意义。 A类私有地址：10.0.0.0/8，范围是：10.0.0.0~10.255.255.255 B类私有地址：172.16.0.0/12，范围是：172.16.0.0~172.31.255.255 C类私有地址：192.168.0.0/16，范围是：192.168.0.0~192.168.255.255 4. 子网掩码及网络划分 随着互连网应用的不断扩大，原先的IPv4的弊端也逐渐暴露出来，即网络号占位太多，而主机号位太少，所以其能提供的主机地址也越来越稀缺，目前除了使用NAT在企业内部利用保留地址自行分配以外，通常都对一个高类别的IP地址进行再划分，以形成多个子网，提供给不同规模的用户群使用。这里主要是为了在网络分段情况下有效地利用IP地址，通过对主机号的高位部分取作为子网号，从通常的网络位界限中扩展或压缩子网掩码，用来创建某类地址的更多子网。但创建更多的子网时，在每个子网上的可用主机地址数目会比原先减少。什么是子网掩码？子网掩码是标志两个IP地址是否同属于一个子网的，也是32位二进制地址，其每一个为1代表该位是网络位，为0代表主机位。它和IP地址一样也是使用点式十进制来表示的。如果两个IP地址在子网掩码的按位与的计算下所得结果相同，即表明它们共属于同一子网中。在计算子网掩码时，我们要注意IP地址中的保留地址，即&quot; 0&quot;地址和广播地址，它们是指主机地址或网络地址全为&quot; 0&quot;或&quot; 1&quot;时的IP地址，它们代表着本网络地址和广播地址，一般是不能被计算在内的。子网掩码的计算：对于无须再划分成子网的IP地址来说，其子网掩码非常简单，即按照其定义即可写出：如某B类IP地址为 10.12.3.0，无须再分割子网，则该IP地址的子网掩码255.255.0.0。如果它是一个C类地址，则其子网掩码为 255.255.255.0。其它类推，不再详述。下面我们关键要介绍的是一个IP地址，还需要将其高位主机位再作为划分出的子网网络号，剩下的是每个子网的主机号，这时该如何进行每个子网的掩码计算。 下面总结一下有关子网掩码和网络划分常见的面试考题： 1）利用子网数来计算 · 在求子网掩码之前必须先搞清楚要划分的子网数目，以及每个子网内的所需主机数目。(1) 将子网数目转化为二进制来表示;如欲将B类IP地址168.195.0.0划分成27个子网：27=11011；(2) 取得该二进制的位数，为N；该二进制为五位数，N = 5(3) 取得该IP地址的类子网掩码，将其主机地址部分的的前N位置1即得出该IP地址划分子网的子网掩码。将B类地址的子网掩码255.255.0.0的主机地址前5位置 1，得到 255.255.248.0 2）利用主机数来计算 · 如欲将B类IP地址168.195.0.0划分成若干子网，每个子网内有主机700台：(1) 将主机数目转化为二进制来表示；700=1010111100(2) 如果主机数小于或等于254（注意去掉保留的两个IP地址），则取得该主机的二进制位数，为N，这里肯定 N&lt;8。如果大于254，则 N&gt;8，这就是说主机地址将占据不止8位；该二进制为十位数，N=10；(3) 使用255.255.255.255来将该类IP地址的主机地址位数全部置1，然后从后向前的将N位全部置为 0，即为子网掩码值。将该B类地址的子网掩码255.255.0.0的主机地址全部置1，得到255.255.255.255，然后再从后向前将后 10位置0,即为：11111111.11111111.11111100.00000000，即255.255.252.0。这就是该欲划分成主机为700台的B类IP地址 168.195.0.0的子网掩码。 3）根据每个网络的主机数量进行子网地址的规划和计算子网掩码 · 这也可按上述原则进行计算。比如一个子网有10台主机，那么对于这个子网需要的IP地址是：10＋1＋1＋1＝13注意：加的第一个1是指这个网络连接时所需的网关地址，接着的两个1分别是指网络地址和广播地址。因为13小于16（16等于2的4次方），所以主机位为4位。而256－16＝240，所以该子网掩码为255.255.255.240。如果一个子网有14台主机，不少人常犯的错误是：依然分配具有16个地址空间的子网，而忘记了给网关分配地址。这样就错误了，因为14＋1＋1＋1＝17，17大于16，所以我们只能分配具有32个地址（32等于2的5次方）空间的子网。这时子网掩码为：255.255.255.224。 5. ARP/RARP协议 地址解析协议，即ARP（Address Resolution Protocol），是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。地址解析协议是建立在网络中各个主机互相信任的基础上的，网络上的主机可以自主发送ARP应答消息，其他主机收到应答报文时不会检测该报文的真实性就会将其记入本机ARP缓存；由此攻击者就可以向某一主机发送伪ARP应答报文，使其发送的信息无法到达预期的主机或到达错误的主机，这就构成了一个ARP欺骗。ARP命令可用于查询本机ARP缓存中IP地址和MAC地址的对应关系、添加或删除静态对应关系等。 ARP工作流程举例： 主机A的IP地址为192.168.1.1，MAC地址为0A-11-22-33-44-01； 主机B的IP地址为192.168.1.2，MAC地址为0A-11-22-33-44-02； 当主机A要与主机B通信时，地址解析协议可以将主机B的IP地址（192.168.1.2）解析成主机B的MAC地址，以下为工作流程： · （1）根据主机A上的路由表内容，IP确定用于访问主机B的转发IP地址是192.168.1.2。然后A主机在自己的本地ARP缓存中检查主机B的匹配MAC地址。 · （2）如果主机A在ARP缓存中没有找到映射，它将询问192.168.1.2的硬件地址，从而将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求。 · （3）主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存中。 · （4）主机B将包含其MAC地址的ARP回复消息直接发送回主机A。 · （5）当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。 逆地址解析协议，即RARP，功能和ARP协议相对，其将局域网中某个主机的物理地址转换为IP地址，比如局域网中有一台主机只知道物理地址而不知道IP地址，那么可以通过RARP协议发出征求自身IP地址的广播请求，然后由RARP服务器负责回答。 RARP协议工作流程： · （1）给主机发送一个本地的RARP广播，在此广播包中，声明自己的MAC地址并且请求任何收到此请求的RARP服务器分配一个IP地址； · （2）本地网段上的RARP服务器收到此请求后，检查其RARP列表，查找该MAC地址对应的IP地址； · （3）如果存在，RARP服务器就给源主机发送一个响应数据包并将此IP地址提供给对方主机使用； · （4）如果不存在，RARP服务器对此不做任何的响应； 6. 路由选择协议 常见的路由选择协议有：RIP协议、OSPF协议。RIP协议 ：底层是贝尔曼福特算法，它选择路由的度量标准（metric)是跳数，最大跳数是15跳，如果大于15跳，它就会丢弃数据包。OSPF协议 ：Open Shortest Path First开放式最短路径优先，底层是迪杰斯特拉算法，是链路状态路由选择协议，它选择路由的度量标准是带宽，延迟。 7. TCP/IP协议 TCP/IP协议是Internet最基本的协议、Internet国际互联网络的基础，由网络层的IP协议和传输层的TCP协议组成。通俗而言：TCP负责发现传输的问题，一有问题就发出信号，要求重新传输，直到所有数据安全正确地传输到目的地。而IP是给因特网的每一台联网设备规定一个地址。IP层接收由更低层（网络接口层例如以太网设备驱动程序）发来的数据包，并把该数据包发送到更高层---TCP或UDP层；相反，IP层也把从TCP或UDP层接收来的数据包传送到更低层。IP数据包是不可靠的，因为IP并没有做任何事情来确认数据包是否按顺序发送的或者有没有被破坏，IP数据包中含有发送它的主机的地址（源地址）和接收它的主机的地址（目的地址）。TCP是面向连接的通信协议，通过三次握手建立连接，通讯完成时要拆除连接，由于TCP是面向连接的所以只能用于端到端的通讯。TCP提供的是一种可靠的数据流服务，采用&quot;带重传的肯定确认&quot;技术来实现传输的可靠性。TCP还采用一种称为&quot;滑动窗口&quot;的方式进行流量控制，所谓窗口实际表示接收能力，用以限制发送方的发送速度。 TCP报文首部格式：件）、HTTP协议等。 TCP协议的三次握手和四次挥手： 注：seq:&quot;sequance&quot;序列号；ack:&quot;acknowledge&quot;确认号；SYN:&quot;synchronize&quot;请求同步标志；；ACK:&quot;acknowledge&quot;确认标志&quot;；FIN：&quot;Finally&quot;结束标志。 TCP连接建立过程：首先Client端发送连接请求报文，Server段接受连接后回复ACK报文，并为这次连接分配资源。Client端接收到ACK报文后也向Server段发生ACK报文，并分配资源，这样TCP连接就建立了。TCP连接断开过程：假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说&quot;我Client端没有数据要发给你了&quot;，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，&quot;告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息&quot;。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，&quot;告诉Client端，好了，我这边数据发完了，准备好关闭连接了&quot;。Client端收到FIN报文后，&quot;就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。&quot;，Server端收到ACK后，&quot;就知道可以断开连接了&quot;。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！为什么要三次握手？在只有两次&quot;握手&quot;的情形下，假设Client想跟Server建立连接，但是却因为中途连接请求的数据报丢失了，故Client端不得不重新发送一遍；这个时候Server端仅收到一个连接请求，因此可以正常的建立连接。但是，有时候Client端重新发送请求不是因为数据报丢失了，而是有可能数据传输过程因为网络并发量很大在某结点被阻塞了，这种情形下Server端将先后收到2次请求，并持续等待两个Client请求向他发送数据...问题就在这里，Cient端实际上只有一次请求，而Server端却有2个响应，极端的情况可能由于Client端多次重新发送请求数据而导致Server端最后建立了N多个响应在等待，因而造成极大的资源浪费！所以，&quot;三次握手&quot;很有必要！为什么要四次挥手？试想一下，假如现在你是客户端你想断开跟Server的所有连接该怎么做？第一步，你自己先停止向Server端发送数据，并等待Server的回复。但事情还没有完，虽然你自身不往Server发送数据了，但是因为你们之前已经建立好平等的连接了，所以此时他也有主动权向你发送数据；故Server端还得终止主动向你发送数据，并等待你的确认。其实，说白了就是保证双方的一个合约的完整执行！使用TCP的协议：FTP（文件传输协议）、Telnet（远程登录协议）、SMTP（简单邮件传输协议）、POP3（和SMTP相对，用于接收邮 8. UDP协议 UDP用户数据报协议，是面向无连接的通讯协议，UDP数据包括目的端口号和源端口号信息，由于通讯不需要连接，所以可以实现广播发送。UDP通讯时不需要接收方确认，属于不可靠的传输，可能会出现丢包现象，实际应用中要求程序员编程验证。UDP与TCP位于同一层，但它不管数据包的顺序、错误或重发。因此，UDP不被应用于那些使用虚电路的面向连接的服务，UDP主要用于那些面向查询---应答的服务，例如NFS。相对于FTP或Telnet，这些服务需要交换的信息量较小。每个UDP报文分UDP报头和UDP数据区两部分。报头由四个16位长（2字节）字段组成，分别说明该报文的源端口、目的端口、报文长度以及校验值。UDP报头由4个域组成，其中每个域各占用2个字节，具体如下：（1）源端口号；（2）目标端口号；（3）数据报长度；（4）校验值。使用UDP协议包括：TFTP（简单文件传输协议）、SNMP（简单网络管理协议）、DNS（域名解析协议）、NFS、BOOTP。TCP 与 UDP 的区别：TCP是面向连接的，可靠的字节流服务；UDP是面向无连接的，不可靠的数据报服务。 9. DNS协议 DNS是域名系统(DomainNameSystem)的缩写，该系统用于命名组织到域层次结构中的计算机和网络服务，可以简单地理解为将URL转换为IP地址。域名是由圆点分开一串单词或缩写组成的，每一个域名都对应一个惟一的IP地址，在Internet上域名与IP地址之间是一一对应的，DNS就是进行域名解析的服务器。DNS命名用于Internet等TCP/IP网络中，通过用户友好的名称查找计算机和服务。 10. NAT协议 NAT网络地址转换(Network Address Translation)属接入广域网(WAN)技术，是一种将私有（保留）地址转化为合法IP地址的转换技术，它被广泛应用于各种类型Internet接入方式和各种类型的网络中。原因很简单，NAT不仅完美地解决了lP地址不足的问题，而且还能够有效地避免来自网络外部的攻击，隐藏并保护网络内部的计算机。 11. DHCP协议 DHCP动态主机设置协议（Dynamic Host Configuration Protocol）是一个局域网的网络协议，使用UDP协议工作，主要有两个用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。 12. HTTP协议 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。 HTTP 协议包括哪些请求？GET：请求读取由URL所标志的信息。POST：给服务器添加信息（如注释）。PUT：在给定的URL下存储一个文档。DELETE：删除给定的URL所标志的资源。 HTTP 中， POST 与 GET 的区别1）Get是从服务器上获取数据，Post是向服务器传送数据。2）Get是把参数数据队列加到提交表单的Action属性所指向的URL中，值和表单内各个字段一一对应，在URL中可以看到。3）Get传送的数据量小，不能大于2KB；Post传送的数据量较大，一般被默认为不受限制。4）根据HTTP规范，GET用于信息获取，而且应该是安全的和幂等的。I. 所谓 安全的 意味着该操作用于获取信息而非修改信息。换句话说，GET请求一般不应产生副作用。就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。II. 幂等 的意味着对同一URL的多个请求应该返回同样的结果。 13. 一个举例 在浏览器中输入 http://www.baidu.com/ 后执行的全部过程。现在假设如果我们在客户端（客户端）浏览器中输入 http://www.baidu.com， 而 baidu.com 为要访问的服务器（服务器），下面详细分析客户端为了访问服务器而执行的一系列关于协议的操作：1）客户端浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。2）在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。3）客户端的网络层不用关系应用层或者传输层的东西，主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，不作过多的描述，无非就是通过查找路由表决定通过那个路径到达服务器。4）客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。 14.TCP三次握手/四次挥手","link":"/2021/02/25/Draft/2021/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"title":"信息系统项目管理师","text":"教材准备:视频一套，历年真题 工具：平板做真题，查阅记录陌生概念，电脑Markdown记下重要笔记， 项目示例：追肖小姐的工程 准备：江山老师（视频），十大管理（打印），历年真题答案（） 技巧：多口诀，&quot;不择手段记忆&quot;，论文字要练，错不涂，十大管理要滚瓜烂熟，速看视频，适当笔记记忆，做题对应细化，论文提前准备 考试计划： 时间段 8.17-11.06（82）周末两天【专业知识，软考】 工作日【中午一个半小时专业知识，下班7-9两个小时以上软考】 阶段 详细步骤 完成情况 用时 8.17-9.15 完成所有视频并笔记，背诵基础知识【选择，案例，计算，论文】专项研究 17【2】18【1】19【】20【1】21【】22【】23【1】24【1】25【2】26【2】27【】28【1】29【】30【3】31【】1【2】2【2】3【2】4【】5【】6【3】7【2基础十大管理完成，案例两节，计算两节】8【3】9【3】案例完成，计算四节10、13【4计算完】 完成 9.15-9.30 16-18年6套真题精做并分类总结 （一） 做真题套题平板或打印，对应基础速览，重点Anki记忆，错题归结，论文课开始。闲时软件刷题。构建知识框架。16年之前20套的直接看解析，陌生记录 三天一套，知识点Anki一遍并添加，狠补基础 16【2005上】26【2005下】 9.30-10.15 19年2套真题精做并分类总结 （二） 同上，完成（一）未完成的 真题外，论文框架准备并背诵 完成 10.15-10.30 20、21年三套真题定时并分类总结 （一） 总结，所有错题排查，查漏补缺 五天周末一次真实模拟，论文写后总结，练练字 完成 10.30-11.05 论文框架梳理，模拟练字速度 考前准备（工具，考场，是否留宿） 加油！ 倒计时：3 考试介绍，学习方法，重难点，10大知识域概述 考试介绍 通过考试相当于拿到高级职称，难度上午大于论文大于案例。 作用 方法 联想记忆，知识术语哪个板块，板块下那些过程，输入输出工具技术，计算相关，陌生词汇 重视基础（上午），考哪里学哪里，重视真题，费曼学习法，艾宾浩斯记忆，利用碎片时间，考上决心，2/8法则，PDCA循环，人机料法环，无事不项目，错题，知识点ANKI记录记忆 狗（沟通）子（质量）整（整体）范（范围）进（进度），成（成本）人（人力资源，干系人）风（风险）采（采购） 佂帆进城志，力够风采干。 掌管质检边界，鬼激钉娃缺恐，鬼火牌子痴恐，鬼故狱恐，鬼食恐，鬼祖见冠，鬼棺孔，鬼时醒两嘤孔，鬼识孔姐，识鬼棺孔 整 章 管 指 监变 结 范 规集定W 确控 进 规活排资持制 控 成 规估预 控 质 规 实 控 力 规 组建管 沟 规 管 控 风 规识性量应 控 采 规实 控 ···结 人 识 规 管 控 所有管理的综合性管理 考点题型，先做题再对应看书细化 重视周末大段时间 三从 从过程想结果，从结果知输入，从输入选工具 四得 一得文件计划；二得成果数据；三得变更请求；四的因素资产 共性总结 1、上一个过程的输出大部分是下一个过程的输入 2、计划和文件是不一样的（每个输入都有计划和文件） 3、被批准的变更请求约等于计划 4、在执行和监控过程产生新的变更请求（变更请求包括变什么和怎么变，这是变更请求和纠正、预防、缺陷修复的关系） 5、执行过程产生工作绩效数据---数据+背景在监控过程组成为了工作绩效信息然后输出工作绩效报告注意工作绩效数据是执行过程的输出→那么就是监控的输入→监控的输出就成了工作绩效信息 6、通过过程的含义记忆每个过程组最主要的成果（输出）！ 7、监控过程组每个过程都有计划+工作绩效报告要记住我说的监控的那些原理 跟踪进展→拿着计划的这把尺子测量实际的工作绩效报告→偏差计算→偏差评估、分析是否变更→预测→趋势分析 8、项目管理计划和其它子计划（范围管理计划、进度管理计划、质量管理计划等）区别和联系下面以项目管理计划和其中一个子计划为例子总结规律如下：了解后对其它过程帮助甚多 （1）当子计划或基准是主要的输入时→专门列出（如定义范围、收集需求等过程） （2）当子计划或基准是首次输出时→专门列出（如范围管理计划），以后的输出都以“项目管理计划更新”的形式出现 （3）子计划或基准是作为输出时候→项目管理计划将作为输入（如规划范围管理） （4）对控制过程组来说，输入和输出都是项目管理计划而不是具体的子计划 重点，十大管理 1.论文写作基本介绍 ​ 二选一，两小时，注意写字整洁。2500左右 摘要300 正文2000。 ​ 学好理论，写字速度整洁，多看范文，选定素材，别写具体项目名称。 2.信息化与信息系统【23】 网络 物数网传会表应 OSI/RM（Open System Interconnection/Reference Model，开放系统互连参考模型） 物理层：比特，串行传输。数据链路层：帧。网络层：分组，处理与寻址和传输有关的管理问题，提供点对点的连接。传输层：报文，建立、维护和撤销传输连接（端对端的连接），并进行流量控制和差错控制。 测试，软件需求，生命周期，面向对象，中间件，新网络技术 UML，测试 重点 新一代信息技术（英语单词），物联网，大数据，云计算，移动互联网，智慧城市，互联网+（互联网+各种传统行业），智能制造2025，AR，VR，AI，区块链，特别联网，5G，华为鸿蒙麒麟，一带一路，两化融合 信息安全技术 3.信息系统项目管理基础 项目特点：（1）临时性：有明确的开始和结束时间。 （2）独特性：世上没有两个完全相同的项目。 （3）渐进明细性：前期只能粗略定义，然后逐渐明朗、完善和精确，这也就意味着变更不可避免，所以要控制变更。 **项目的组织方式：**职能型、项目型、矩阵型 4.立项管理 2 （一个项目从提出申请到批准立项）招投标，合同，采购 项目建议书（立项申请)主要内容：项目的必要性、项目的市场预测、产品方案或服务的市场预测、项目建设必需的条件等 计算: 利率 利率有单利和复利，单利息=本金×利率×期限，F=P×（1+i）n F：复利终值 P：本金 i：利率 N：利率获取时间的整数倍 净现值（Net Present Value，NPV） 净现值大于零则方案可行，且净现值越大，方案越优，投资效益越好。 NPV 的计算步骤如下： （1）根据项目的资本结构设定项目的折现率。 （2）计算每年项目现金流量的净值。 （3）根据设定的折现率计算每年的净现值。 （4）将净现值累加起来。 净现值率 净现值率（NPVR）=项目的净现值（NPV）/原始投资的现值合计 投资回收期 招标 招标（招标公告，招标文件，） 中标通知书发出之日起三十日内应当签订合同，截止时间15日前进行必要的澄清或者修改，招标人应当确定投标人编制投标文件所需要的合理时间。但是，依法必须进行招标的项目，自招标文件开始发出之日起至投标人提交投标文件截止之日止，最短不得少于20日。 投标 投标人少于三个的，招标人应当重新招标。在招标文件要求提交投标文件的截止时间后送达的投标文件，招标人应当拒收。 开标 开标应当在招标文件确定的提交投标文件截止时间的同一时间公开进行。开标地点应当为招标文件中预先确定的地点。开标由招标人主持，邀请所有投标人参加。 评标 评标委员会由招标人的代表和有关技术、经济等方面的专家组成，成员人数为5人以上单数，其中技术、经济等方面的专家不得少于成员总数的三分之二。 中标 中标通知书发出后，招标人改变中标结果的，或者中标人放弃中标项目的，应当依法承担法律责任。 合同 分类： 范围：项目总承包合同、项目单项承包合同、项目分包合同。 付款方式：项目总价合同、项目单价合同、项目成本加酬金合同 合同的主要内容包括：项目名称；标的内容和范围；项目的质量要求：通常情况下采用技术指标限定等各种方式来描述信息系统工程的整体质量标准以及各部分质量标准，它是判断整个工程项目成败的重要依据；项目的计划、进度、地点、地域和方式；项目建设过程中的各种期限；技术情报和资料的保密；风险责任的承担；技术成果的归属；验收的标准和方法；价款、报酬（或使用费）及其支付方式；违约金或者损失赔偿的计算方法；解决争议的方法：该条款中应尽可能地明确在出现争议与纠纷时采取何种方式来协商解决；名词术语解释等 8.整体管理 ITO ITO 名称及定义 输入 工具技术 输出 项目章程 正式批准一个项目的文档，制定项目的头（项目经理） 项目工作说明书商业论证协议事业环境因素组织过程资产 专家判断引导技术 项目章程 制定项目管理计划 包括定义、准备和协调所有构成计划，形成项目管理计划所必要的行动 项目章程其他过程输入【项目初步范围说明书，管理过程，预测，工作绩效信息】事业环境因素组织过程资产 专家判断引导技术 项目管理计划 指导与管理项目工作 提意见，记考核，做东西 项目管理计划，批准的变更请求，事业环境因素，组织过程资产 专家判断项目管理信息系统会议 可交付成果工作绩效数据变更请求项目管理计划更新项目文件更新 监控项目工作 从项目开始到结束，收集，测量发布绩效信息，及评估会影响过程改进的度量项和趋势 项目管理计划事业环境因素组织过程资产进度预测成本预测确认的变更工作绩效信息 专家判断分析技术项目管理信息系统【PMIS】会议 变更请求工作绩效报告项目管理计划更新项目文件更新 实施整体变更控制 审批变更，项目经理付最终责任 变更请求，工作绩效报告，变更请求，项目管理计划，事业环境因素，组织过程资产 专家判断会议变更控制工具 批准的变更请求变更日志项目管理计划更新项目文件更新 项目收尾 打包交货 项目管理计划验收的可交付成果组织过程资产 专家判断分析技术会议 最终产品、服务或成果移交组织过程资产更新 9.范围管理 ITO ITO 名称及定义 输入 工具技术 输出 10.进度管理 ITO ITO 名称及定义 输入 工具技术 输出 11.成本管理 ITO ITO 名称及定义 输入 工具技术 输出 挣值分析计算 12.质量管理 ITO ITO 名称及定义 输入 工具技术 输出 13.人力资源管理 ITO ITO 名称及定义 输入 工具技术 输出 14.干系人管理 ITO ITO 名称及定义 输入 工具技术 输出 15.沟通管理 ITO ITO 名称及定义 输入 工具技术 输出 16.风险管理 ITO ITO 名称及定义 输入 工具技术 输出 17.采购管理 ITO ITO 名称及定义 输入 工具技术 输出 PPT加星看了就可以了 18.合同管理 上午一分 合同的分类 19.信息文档和配置管理 上午2分 文档分类（开发，产品，管理） 上午一般三分 20.20-28章 知识管理 显性知识，隐性知识,隐性知识分享途经，知识产权保护，软件著作权 战略管理 组织战略因素组成，战略实施，类型层次，平衡计分卡 组织级项目管理 流程管理 项目集，项目组合管理 信息安全管理 综合测试管理、量化项目管理，成熟度模型 CMMI（能力成熟度模型）、 法律法规 合同法 1 合同内容，要约，标的，格式（非格式【手写】）条款，违心合同， 招标法 1 必须进行招标的项目、标底（必须保密） 著作权法 政府采购法 2 常用技术标准 2-3 软件工程国家标准GB/T11457-2006（审计-代码审记-配置审计-认证-走查-鉴定-基线-配置控制委员会-配置状态报告-设计评审-桌面检查-评价-故障-功能配置审计） 软件生存周期的过程，软件生命周期各阶段与软件文档编制工作的关系，各类人员与软件文档的使用关系，软件产品质量，6个质量特性21个质量子特性 案例分析 五种题型 问答题，计算题，分析题，理论题，填空，选择，判断题 分析题 回答简练，文字工整清晰，答题有序，多写不扣分，专业化 万金油： 技术出身：开发和管理所需技能不同，需要培训 身兼数职：导致没时间去学习管理知识，工作负荷过载，身心疲惫，全局影响 新技术：风险，需培训，学习，监控技术风险，找到合适的人，实在不行外包 有人对项目不满意：简历有效沟通机制方式发法，缺乏有效的项目绩效管理机制，需加强沟通 变更：书面申请，审批确认，跟踪变更缺一不可 客户验收不通过：说明验收标准没有得到认可确认，没有验收测试规范和方法 愚人有关问题：沟通不到位 过一段时间才发现问题：监控不力 里程碑，时间紧促：没有冗余考虑风险的想法 外部因素导致延工：没有考虑外在因素影响，变更5个理由 争执：沟通问题，计划不够周明 多头汇报：项目章程，多头汇报导致信息沟通不畅通或产生冲突 知识点 如何缩短活动的工期，成本控制，质量新老7工具，提升项目质量， 答题关键词 新人：培训 并行工作：有风险 客户要求都答应： 口头：书面 备忘录：配置管理 部分人：全员参与 开会很久：效率低下 当场修改，能改就改：变更监控分析记录 文档配置管理 人员离职：AB思想，风险 总价合同：乙方风险太大 前期需求调研不充分： 计算 进度类 EV、AC、PV需验算确保后面不错。 管理储备不计入挣值和基准，但是总预算一部分。 注意审题，时间和单位。 总时差 是指在不延误项目完成日期或违反进度因素的前提下，某活动可以推迟的时间。 总时差=LS-ES=LF-EF 自由时差 是指在不影响紧后活动最早开始的情况下，当前活动可以推迟的时间。 自由时差=(后一活动)ES-(前一活动的)EF 所以总时差影响总工期，自由时差影响紧后活动。 （1）总时差（TF）：当一项活动的最早开始时间和最迟开始时间不相同时，它们之间的差值是该工作的总时差。计算公式是：TF=LS-ES。 （2）自由时差（FF）：在不影响紧后活动完成时间的条件下，一项活动可能被延迟的时间是该项活动的自由时差，它由该项活动的最早完成时间EF和它的紧后活动的最早开始时间决定的。计算公式是：FF=min{紧后活动的ES}-EF。 （3）关键路径。项目的关键路径是指能够决定项目最早完成时间的一系列活动。它是网络图中的最长路径，具有最少的时差。在实际求关键路径时，一般的方法是看哪些活动的总时差为0，总时差为0的活动称为关键活动，关键活动组成的路径称为关键路径。 尽管关键路径是最长的路径，但它代表了完成项目所需的最短时间。因此，关键路径上各活动持续时间（历时）的和就是项目的计算工期。 最早开始时间（ES）： 一项活动的最早开始时间取决于它的所有紧前活动的完成时间。通过计算到该活动路径上所有活动的完成时间的和，可得到指定活动的ES。如果有多条路径指向此活动，则计算需要时间最长的那条路径，即ES=max{紧前活动的EF}。 最早结束时间（EF）： 一项活动的最早完成时间取决于该工作的最早开始时间和它的持续时间（D），即EF=ES+D。 最晚结束时间（LF）： 在不影响项目完成时间的条件下，一项活动可能完成的最迟时间。计算公式是：LF=min{紧后活动的LS}。 最晚开始时间（LS）： 在不影响项目完成时间的条件下，一项活动可能开始的最晚时间。计算公式是：LS=LF-D。 前推法来计算最早时间 某一活动的最早开始时间（ES）=指向它的所有紧前活动的最早结束时间的最大值。 某一活动的最早结束时间（EF）=ES+T（作业时间） 逆推法来计算最迟时间 某一活动的最迟结束时间（LF）=指向它的所有紧后活动的最迟开始时间的最小值。 某一活动的最迟开始时间（LS）=LF-T（作业时间） 计算关键路径的步骤 **1. 用有方向的线段标出各结点的紧前活动和紧后活动的关系，使之成为一个有方向的网络图（PDM） \\2. 用正推和逆推法计算出各个活动的ES,LS, EF, LF，并计算出各个活动的自由时差。找出所有总时差为零或为负的活动，就是关键活动 \\3. 关键路径上的活动持续时间决定了项目的工期，总和就是项目工期。 **自由时差 ** 计算公式： 自由时差=所有紧后工作中最早开始时间最小值－ 最早结束时间 **总时差 ** 计算公式： 总时差=最迟开始时间-最早开始时间=最迟结束时间-最早结束时间 单代号网络图 双代号网络图 双代号时标网络图 全为实线的为关键路径， 成本类 挣值分析 PV [Planned Value]计划值：应该完成多少工作？ 要干的活 EV [Earned Value]挣值：完成了多少预算工作？ 干完的活 AC [Actual Cost]实际成本：完成工作的实际成本是多少？ 实际花费 BAC [Budget cost at completion] 基线预算成本：全部工作的预算是多少？不改变成本基准，BAC就不会发生变化 CV [Cost Variance] 成本偏差 CV＝EV－AC，CV&gt;0，成本节约，CV&lt;0，成本超支。 SV [Schedule Variance] 进度偏差 SV＝EV－PV，SV&gt;0，进度超前，SV&lt;0，进度落后。 CPI [Cost Performance Index] 成本执行指数CPI＝EV/AC，CPI＝1，资金使用效率一般；CPI&gt;1成本节约，资金使用效率高；CPI&lt;1，成本超支，资金使用效率低。 SPI [Schedule Performance Index] 进度执行指数 SPI＝EV/PV，SPI＝1，进度与计划相符，SPI&gt;1，进度超前，SPI&lt;1，进度落后。 ETC [Estimate (or Estimated) To Complete] 完工时尚需成本估算：到完成时，剩余工作量还需要多少成本,ETC也就是估计完成项目的剩余工作成本 BAC [Budget cost at completion] 完工预算：全部工作的预算是多少？不改变成本基准，BAC就不会发生变化 EAC [Estimate at completion] 完成预估：全部工作的成本是多少？是根据项目的绩效和风险量化对项目最可能的总成本所做的一种预测。 完工工期估算=预算工期/SPI 预测EAC 与 ETC： 由于存在成本偏差情况，所以在典型偏差与非典型偏差时，计算顺序不一样，如下: 典型偏差：未来项目的CPI、SPI会保持不变，此时预测项目完成时的总成本和预计完成时间，应该用典型偏差公式。 EAC= AC+(BAC-EV) =BAC/CPI ETC=EAC-AC 非典型偏差：非典型偏差的含义是项目未来的工作绩效与当前无关，和原计划保持一样，即项目未来的成本绩效指数和进度绩效指数都是“1”）需要纠偏 ETC=BAC-EV 基线总成本-已挣得部份 EAC=ETC+AC 上午小计算 盈亏平衡点 决策树计算 资源平衡问题 统计抽样问题 自制\\外购分析 沟通渠道数 [n(n-1)]/2 风险曝光度 现值 净现值，投资回收期 运筹学 计算量大 求最短和最长路径 线性规划问题 投资收益最大问题 更换设备问题 车床铣床问题 流量问题 人员分配问题【矩阵法（行列分别减一次最小值，根据行零个数从少到多分配）】 伏格尔方法解传输问题 论文 提前准备，摘要300内，正文不少于2000，字迹清晰，无需写题目 准备一个项目（投标书，方案书） 准备框架 自己写一个","link":"/2021/03/29/Draft/2021/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%B8%88/"},{"title":"魑魅先生 | 微信小程序","text":"微信小程序指南 常用函数 跳转 123wx.navigateTo({ url: '../component/L-component' }) 简介 前端，后端任意，上线需配置域名。 WeixinJSBridge对内---》 JS-SDK，前者包装，对内转对外---》 小程序，逻辑层和渲染层是分开的，逻辑层运行在 JSCore 中，并没有一个完整浏览器对象，因而缺少相关的DOM API和BOM API。导致无法运行常用前端库jQuery、 Zepto 等， JSCore 的环境同 NodeJS 环境也是不尽相同，所以一些 NPM 的包在小程序中也是无法运行的。 **初始过程：**申请小程序账号(管理小程序，获取AppID)，安装小程序开发工具、配置项目 结构 app.json 全局配置，包括了小程序的所有页面路径、界面表现、网络超时时间、底部 tab 1234567891011121314151617{ // 描述当前小程序所有页面路径，这是为了让微信客户端知道当前你的小程序页面定义在哪个目录。 &quot;pages&quot;:[ &quot;pages/index/index&quot;, &quot;pages/logs/logs&quot; ], // 定义小程序所有页面的顶部背景颜色，文字颜色定义等。 &quot;window&quot;:{ &quot;backgroundTextStyle&quot;:&quot;light&quot;, &quot;navigationBarBackgroundColor&quot;: &quot;#fff&quot;, &quot;navigationBarTitleText&quot;: &quot;Weixin&quot;, &quot;navigationBarTextStyle&quot;:&quot;black&quot; }, &quot;style&quot;: &quot;v2&quot;, &quot;sitemapLocation&quot;: &quot;sitemap.json&quot;} project.config.json 小程序开发者工具个性化配置，界面颜色、编译配置等等 page.json 表示 pages/logs 目录下的 logs.json 这类和小程序页面相关的配置。独立定义每个页面的一些属性 页面中配置项会覆盖 app.json 的 window 中相同的配置项 index.wxml WXML（WeiXin Markup Language）， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748数据绑定&lt;!--wxml--&gt;&lt;view&gt; {{message}} &lt;/view&gt;// page.jsPage({ data: { message: 'Hello MINA!' }})列表渲染&lt;!--wxml--&gt;&lt;view wx:for=&quot;{{array}}&quot;&gt; {{item}} &lt;/view&gt;// page.jsPage({ data: { array: [1, 2, 3, 4, 5] }})条件渲染&lt;!--wxml--&gt;&lt;view wx:if=&quot;{{view == 'WEBVIEW'}}&quot;&gt; WEBVIEW &lt;/view&gt;&lt;view wx:elif=&quot;{{view == 'APP'}}&quot;&gt; APP &lt;/view&gt;&lt;view wx:else=&quot;{{view == 'MINA'}}&quot;&gt; MINA &lt;/view&gt;// page.jsPage({ data: { view: 'MINA' }})模板&lt;!--wxml--&gt;&lt;template name=&quot;staffName&quot;&gt; &lt;view&gt; FirstName: {{firstName}}, LastName: {{lastName}} &lt;/view&gt;&lt;/template&gt;&lt;template is=&quot;staffName&quot; data=&quot;{{...staffA}}&quot;&gt;&lt;/template&gt;&lt;template is=&quot;staffName&quot; data=&quot;{{...staffB}}&quot;&gt;&lt;/template&gt;&lt;template is=&quot;staffName&quot; data=&quot;{{...staffC}}&quot;&gt;&lt;/template&gt;// page.jsPage({ data: { staffA: {firstName: 'Hulk', lastName: 'Hu'}, staffB: {firstName: 'Shang', lastName: 'You'}, staffC: {firstName: 'Gideon', lastName: 'Lin'} }}) index.wxss CSS,仅支持部分 CSS 选择器,新增了尺寸单位,提供了全局的样式[app.wxss]和局部样式 .js 逻辑层 除此之外，只有后缀名在白名单内的文件可以被上传，不在白名单列表内文件在开发工具能被访问到，但无法被上传。具体白名单列表如下： wxs png jpg jpeg gif svg json cer mp3 aac m4a mp4 wav ogg silk wasm br 基础 场景值： 描述用户进入小程序的路径，目前还无法获取到按 Home 键退出到桌面，然后从桌面再次进小程序的场景值，对于这种情况，会保留上一次的场景值。 获取方式：onLaunch 和 onShow，wx.getLaunchOptionsSync 场景值 场景 appId含义 1020 公众号 profile 页相关小程序列表 来源公众号 1035 公众号自定义菜单 来源公众号 1036 App 分享消息卡片 来源App 1037 小程序打开小程序 来源小程序 1038 从另一个小程序返回 来源小程序 1043 公众号模板消息 来源公众号 逻辑层App Service JavaScript 的基础上，增加一些功能，由于并非运行在浏览器中，window，document等一些web能力无法使用： 增加 App 和 Page 方法，进行程序注册和页面注册。 增加 getApp 和 getCurrentPages 方法，分别用来获取 App 实例和当前页面栈。 提供丰富的 API，如微信用户数据，扫一扫，支付等微信特有能力。 提供模块化能力，每个页面有独立的作用域。 注册小程序 app.js 中调用 App 方法注册小程序实例，绑定生命周期回调函数、错误监听和页面不存在监听函数等。 12345整个小程序只有一个 App 实例，是全部页面共享的。开发者可以通过 getApp 方法获取到全局唯一的 App 实例，获取App上的数据或调用开发者注册在 App 上的函数。// xxx.jsconst appInstance = getApp()console.log(appInstance.globalData) // I am global data 注册页面 Page() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253Page({ data: { text: &quot;This is page data.&quot; }, onLoad: function(options) { // 页面创建时执行 }, onShow: function() { // 页面出现在前台时执行 }, onReady: function() { // 页面首次渲染完毕时执行 }, onHide: function() { // 页面从前台变为后台时执行 }, onUnload: function() { // 页面销毁时执行 }, onPullDownRefresh: function() { // 触发下拉刷新时执行 }, onReachBottom: function() { // 页面触底时执行 }, onShareAppMessage: function () { // 页面被用户分享时执行 }, onPageScroll: function() { // 页面滚动时执行 }, onResize: function() { // 页面尺寸变化时执行 }, onTabItemTap(item) { // tab 点击时执行 console.log(item.index) console.log(item.pagePath) console.log(item.text) }, // 事件响应函数 viewTap: function() { this.setData({ text: 'Set some data for updating view.' }, function() { // this is setData callback }) }, // 自由数据 customData: { hi: 'MINA' }}) behaviors 2.9.2 开始支持,低版本需做兼容处理。 behaviors 可以用来让多个页面有相同的数据字段和方法。 12345678910111213141516171819// my-behavior.jsmodule.exports = Behavior({ data: { sharedText: 'This is a piece of data shared between pages.' }, methods: { sharedMethod: function() { this.data.sharedText === 'This is a piece of data shared between pages.' } }})// page-a.jsvar myBehavior = require('./my-behavior.js')Page({ behaviors: [myBehavior], onLoad: function() { this.data.sharedText === 'This is a piece of data shared between pages.' }}) Component () 基础库 1.6.3 开始支持，低版本需做兼容处理。方法需要放在 methods: { } 里面。类似自定义组件，适合复杂页面 1234567891011121314151617Component({ data: { text: &quot;This is page data.&quot; }, methods: { onLoad: function(options) { // 页面创建时执行 }, onPullDownRefresh: function() { // 下拉刷新时执行 }, // 事件响应函数 viewTap: function() { // ... } }}) 页面生命周期 页面路由 在小程序中所有页面的路由全部由框架进行管理。 页面栈 框架以栈的形式维护了当前的所有页面。 当发生路由切换的时候，页面栈的表现如下： 路由方式 页面栈表现 初始化 新页面入栈 打开新页面 新页面入栈 页面重定向 当前页面出栈，新页面入栈 页面返回 页面不断出栈，直到目标返回页 Tab 切换 页面全部出栈，只留下新的 Tab 页面 重加载 页面全部出栈，只留下新的页面 开发者可以使用 getCurrentPages() 函数获取当前页面栈。 路由方式 对于路由的触发方式以及页面生命周期函数如下： 路由方式 触发时机 路由前页面 路由后页面 初始化 小程序打开的第一个页面 onLoad, onShow 打开新页面 调用 API wx.navigateTo 使用组件 `` onHide onLoad, onShow 页面重定向 调用 API wx.redirectTo 使用组件 `` onUnload onLoad, onShow 页面返回 调用 API wx.navigateBack 使用组件`` 用户按左上角返回按钮 onUnload onShow Tab 切换 调用 API wx.switchTab 使用组件 `` 用户切换 Tab 各种情况请参考下表 重启动 调用 API wx.reLaunch 使用组件 `` onUnload onLoad, onShow Tab 切换对应的生命周期（以 A、B 页面为 Tabbar 页面，C 是从 A 页面打开的页面，D 页面是从 C 页面打开的页面为例）： 当前页面 路由后页面 触发的生命周期（按顺序） A A Nothing happend A B A.onHide(), B.onLoad(), B.onShow() A B（再次打开） A.onHide(), B.onShow() C A C.onUnload(), A.onShow() C B C.onUnload(), B.onLoad(), B.onShow() D B D.onUnload(), C.onUnload(), B.onLoad(), B.onShow() D（从转发进入） A D.onUnload(), A.onLoad(), A.onShow() D（从转发进入） B D.onUnload(), B.onLoad(), B.onShow() 注意事项 navigateTo, redirectTo 只能打开非 tabBar 页面。 switchTab 只能打开 tabBar 页面。 reLaunch 可以打开任意页面。 页面底部的 tabBar 由页面决定，即只要是定义为 tabBar 的页面，底部都有 tabBar。 调用页面路由带的参数可以在目标页面的onLoad中获取。 模块化 公共的代码抽离成为一个单独的 js 文件，作为一个模块。模块只有通过 module.exports 或者 exports【exports 是 module.exports 的一个引用，因此在模块里边随意更改 exports 的指向会造成未知的错误。】 才能对外暴露接口。不支持直接引入 node_modules , 开发者需要使用到 node_modules 时候建议拷贝出相关的代码到小程序的目录中，或者使用小程序支持的 npm 功能 123456789101112131415161718192021// common.jsfunction sayHello(name) { console.log(`Hello ${name} !`)}function sayGoodbye(name) { console.log(`Goodbye ${name} !`)}module.exports.sayHello = sayHelloexports.sayGoodbye = sayGoodbye​在需要使用这些模块的文件中，使用 require 将公共代码引入var common = require('common.js')Page({ helloMINA: function() { common.sayHello('MINA') }, goodbyeMINA: function() { common.sayGoodbye('MINA') }}) 文件作用域 在 JavaScript 文件中声明的变量和函数只在该文件中有效；不同的文件中可以声明相同名字的变量和函数，不会互相影响。 通过全局函数 getApp 可以获取全局的应用实例，如果需要全局的数据可以在 App() 中设置 1234567891011121314151617// app.jsApp({ globalData: 1})// a.js// The localValue can only be used in file a.js.var localValue = 'a'// Get the app instance.var app = getApp()// Get the global data and change it.app.globalData++// b.js// You can redefine localValue in file b.js, without interference with the localValue in a.js.var localValue = 'b'// If a.js it run before b.js, now the globalData shoule be 2.console.log(getApp().globalData) API 事件监听 API on 开头,监听某个事件是否触发,如：wx.onSocketOpen，wx.onCompassChange 等。 同步 API Sync 结尾,如 wx.setStorageSync，wx.getSystemInfoSync 等 异步 API 如 wx.request，wx.login 等 云开发 API 视图层 View WXML WXSS (WeiXin Style Sheets) @import语句可以导入外联样式表 内联样式 框架组件上支持使用 style、class 属性来控制组件的样式。 选择器 目前支持的选择器有： 选择器 样例 样例描述 .class .intro 选择所有拥有 class=&quot;intro&quot; 的组件 #id #firstname 选择拥有 id=&quot;firstname&quot; 的组件 element view 选择所有 view 组件 element, element view, checkbox 选择所有文档的 view 组件和所有的 checkbox 组件 ::after view::after 在 view 组件后边插入内容 ::before view::before 在 view 组件前边插入内容 WXS WXS（WeiXin Script）是小程序的一套脚本语言 WXS 不依赖于运行时的基础库版本，可以在所有版本的小程序中运行。 WXS 与 JavaScript 是不同的语言，有自己的语法，并不和 JavaScript 一致。 WXS 的运行环境和其他 JavaScript 代码是隔离的，WXS 中不能调用其他 JavaScript 文件中定义的函数，也不能调用小程序提供的API。 WXS 函数不能作为组件的事件回调。 由于运行环境的差异，在 iOS 设备上小程序内的 WXS 会比 JavaScript 代码快 2 ~ 20 倍。在 android 设备上二者运行效率无差异。 1234567&lt;wxs module=&quot;m1&quot;&gt;var msg = &quot;hello world&quot;;module.exports.message = msg;&lt;/wxs&gt;&lt;view&gt; {{m1.message}} &lt;/view&gt; 事件系统 简意双向绑定 只能是一个单一字段的绑定 12&lt;input model:value=&quot;值为 {{value}}&quot; /&gt;&lt;input model:value=&quot;{{ a + b }}&quot; /&gt; 都是非法的； 目前，尚不能 data 路径 1&lt;input model:value=&quot;{{ a.b }}&quot; /&gt; 组件中传递双向绑定并触发更新 12345678910111213Component({ properties: { myValue: String }, methods: { update: function() { // 更新 myValue this.setData({ myValue: 'leaf' }) }})&lt;input model:value=&quot;{{myValue}}&quot; /&gt; 基础组件 获取界面上的节点信息 WXML节点信息：获取节点属性、样式、在界面上的位置等信息 WXML节点布局相交状态： 参照节点：监听的参照节点，取它的布局区域作为参照区域。如果有多个参照节点，则会取它们布局区域的 交集 作为参照区域。页面显示区域也可作为参照区域之一。 目标节点：监听的目标，默认只能是一个节点（使用 selectAll 选项时，可以同时监听多个节点）。 相交区域：目标节点的布局区域与参照区域的相交区域。 相交比例：相交区域占参照区域的比例。 阈值：相交比例如果达到阈值，则会触发监听器的回调函数。阈值可以有多个。 1234567891011121314Page({ onLoad: function(){ wx.createIntersectionObserver().relativeToViewport().observe('.target-class', (res) =&gt; { res.id // 目标节点 id res.dataset // 目标节点 dataset res.intersectionRatio // 相交区域占目标节点的布局区域的比例 res.intersectionRect // 相交区域 res.intersectionRect.left // 相交区域的左边界坐标 res.intersectionRect.top // 相交区域的上边界坐标 res.intersectionRect.width // 相交区域的宽度 res.intersectionRect.height // 相交区域的高度 }) }}) 响应显示区域变化 在手机上启用屏幕旋转支持 1app.json` 的 `window` 段中设置 `&quot;pageOrientation&quot;: &quot;auto&quot;` ，或在页面 json 文件中配置 `&quot;pageOrientation&quot;: &quot;auto&quot;, 2.5.0 开始， pageOrientation 还可以被设置为 landscape ，表示固定为横屏显示 在 iPad 上启用屏幕旋转支持 1app.json` 中添加 `&quot;resizable&quot;: true，不能单独配置某个页面是否支持屏幕旋转 Media Query 对于不同尺寸的显示区域，页面的布局会有所差异。此时可以使用 media query 来解决大多数问题。 代码示例： 12345678910.my-class { width: 40px;}@media (min-width: 480px) { /* 仅在 480px 或更宽的屏幕上生效的样式规则 */ .my-class { width: 200px; }} 在 WXML 中，可以使用 match-media 组件来根据 media query 匹配状态展示、隐藏节点。 此外，可以在页面或者自定义组件 JS 中使用 this.createMediaQueryObserver() 方法来创建一个 MediaQueryObserver 对象，用于监听指定的 media query 的匹配状态。 分栏模式 启用 3.3版本以上在pc等大屏幕上支持分栏模式， app.json 中同时添加 &quot;resizable&quot;: true 和 &quot;frameset&quot;: true 分栏占位图片 当某一栏没有展示任何页面时，会展示一张图片在此栏正中央。 如果代码包中的 frameset/placeholder.png 文件存在，这张图片将作为此时展示的图片。 动画 初始渲染缓存 自定义组件 介绍 创建自定义组件 类似于页面，一个自定义组件由 json wxml wxss js 4个文件组成。要编写一个自定义组件，首先需要在组件的 json 文件中进行自定义组件声明： 123{ &quot;component&quot;: true} 同时，还要在 wxml 文件中编写组件模板，在 wxss 文件中加入组件样式，它们的写法与页面的写法类似。 123456789&lt;!-- 这是自定义组件的内部WXML结构 --&gt;&lt;view class=&quot;inner&quot;&gt; {{innerText}}&lt;/view&gt;&lt;slot&gt;&lt;/slot&gt;/* 这里的样式只应用于这个自定义组件 */.inner { color: red;} 组件wxss中不应使用ID选择器、属性选择器和标签名选择器。 在自定义组件的 js 文件中，需要使用 Component() 来注册组件，并提供组件的属性定义、内部数据和自定义方法。 组件的属性值和内部数据将被用于组件 wxml 的渲染，其中，属性值是可由组件外部传入的。 1234567891011121314151617Component({ properties: { // 这里定义了innerText属性，属性值可以在组件使用时指定 innerText: { type: String, value: 'default value', } }, data: { // 这里是一些组件内部数据 someData: {} }, methods: { // 这里是一个自定义方法 customMethod: function(){} }}) 使用自定义组件 使用已注册的自定义组件前，首先要在用组件的页面的 json 文件中进行引用声明。此时需要提供每个自定义组件的标签名和对应的自定义组件文件路径： 12345{ &quot;usingComponents&quot;: { &quot;component-tag-name&quot;: &quot;path/to/the/custom/component&quot;//同目录下直接写文件名 }} 这样，在页面的 wxml 中就可以像使用基础组件一样使用自定义组件。节点名即自定义组件的标签名，节点属性即传递给组件的属性值。 1234&lt;view&gt; &lt;!-- 以下是对一个自定义组件的引用 --&gt; &lt;component-tag-name inner-text=&quot;Some text&quot;&gt;&lt;/component-tag-name&gt;&lt;/view&gt; 组件模板和样式 组件模板 组件模板的写法与页面模板相同。组件模板与组件数据结合后生成的节点树，将被插入到组件的引用位置上。 在组件模板中可以提供一个 &lt;slot&gt; 节点，用于承载组件引用时提供的子节点。 代码示例： 在开发者工具中预览效果 123456789101112&lt;!-- 组件模板 --&gt;&lt;view class=&quot;wrapper&quot;&gt; &lt;view&gt;这里是组件的内部节点&lt;/view&gt; &lt;slot&gt;&lt;/slot&gt;&lt;/view&gt;&lt;!-- 引用组件的页面模板 --&gt;&lt;view&gt; &lt;component-tag-name&gt; &lt;!-- 这部分内容将被放置在组件 &lt;slot&gt; 的位置上 --&gt; &lt;view&gt;这里是插入到组件slot中的内容&lt;/view&gt; &lt;/component-tag-name&gt;&lt;/view&gt; 注意，在模板中引用到的自定义组件及其对应的节点名需要在 json 文件中显式定义，否则会被当作一个无意义的节点。除此以外，节点名也可以被声明为抽象节点 模板数据绑定 与普通的 WXML 模板类似，可以使用数据绑定，这样就可以向子组件的属性传递动态数据。 代码示例： 在开发者工具中预览效果 1234567&lt;!-- 引用组件的页面模板 --&gt;&lt;view&gt; &lt;component-tag-name prop-a=&quot;{{dataFieldA}}&quot; prop-b=&quot;{{dataFieldB}}&quot;&gt; &lt;!-- 这部分内容将被放置在组件 &lt;slot&gt; 的位置上 --&gt; &lt;view&gt;这里是插入到组件slot中的内容&lt;/view&gt; &lt;/component-tag-name&gt;&lt;/view&gt; 在以上例子中，组件的属性 propA 和 propB 将收到页面传递的数据。页面可以通过 setData 来改变绑定的数据字段。 注意：这样的数据绑定只能传递 JSON 兼容数据。自基础库版本 2.0.9 开始，还可以在数据中包含函数（但这些函数不能在 WXML 中直接调用，只能传递给子组件）。 组件 wxml 的 slot 在组件的 wxml 中可以包含 slot 节点，用于承载组件使用者提供的 wxml 结构。 默认情况下，一个组件的 wxml 中只能有一个 slot 。需要使用多 slot 时，可以在组件 js 中声明启用。 1234567Component({ options: { multipleSlots: true // 在组件定义时的选项中启用多slot支持 }, properties: { /* ... */ }, methods: { /* ... */ }}) 此时，可以在这个组件的 wxml 中使用多个 slot ，以不同的 name 来区分。 123456&lt;!-- 组件模板 --&gt;&lt;view class=&quot;wrapper&quot;&gt; &lt;slot name=&quot;before&quot;&gt;&lt;/slot&gt; &lt;view&gt;这里是组件的内部细节&lt;/view&gt; &lt;slot name=&quot;after&quot;&gt;&lt;/slot&gt;&lt;/view&gt; 使用时，用 slot 属性来将节点插入到不同的 slot 上。 123456789&lt;!-- 引用组件的页面模板 --&gt;&lt;view&gt; &lt;component-tag-name&gt; &lt;!-- 这部分内容将被放置在组件 &lt;slot name=&quot;before&quot;&gt; 的位置上 --&gt; &lt;view slot=&quot;before&quot;&gt;这里是插入到组件slot name=&quot;before&quot;中的内容&lt;/view&gt; &lt;!-- 这部分内容将被放置在组件 &lt;slot name=&quot;after&quot;&gt; 的位置上 --&gt; &lt;view slot=&quot;after&quot;&gt;这里是插入到组件slot name=&quot;after&quot;中的内容&lt;/view&gt; &lt;/component-tag-name&gt;&lt;/view&gt; 组件样式 组件对应 wxss 文件的样式，只对组件wxml内的节点生效。编写组件样式时，需要注意以下几点： 组件和引用组件的页面不能使用id选择器（#a）、属性选择器（[a]）和标签名选择器，请改用class选择器。 组件和引用组件的页面中使用后代选择器（.a .b）在一些极端情况下会有非预期的表现，如遇，请避免使用。 子元素选择器（.a&gt;.b）只能用于 view 组件与其子节点之间，用于其他组件可能导致非预期的情况。 继承样式，如 font 、 color ，会从组件外继承到组件内。 除继承样式外， app.wxss 中的样式、组件所在页面的的样式对自定义组件无效（除非更改组件样式隔离选项）。 1234#a { } /* 在组件中不能使用 */[a] { } /* 在组件中不能使用 */button { } /* 在组件中不能使用 */.a &gt; .b { } /* 除非 .a 是 view 组件节点，否则不一定会生效 */ 除此以外，组件可以指定它所在节点的默认样式，使用 :host 选择器（需要包含基础库 1.7.2 或更高版本的开发者工具支持）。 代码示例： 123456/* 组件 custom-component.wxss */:host { color: yellow;}&lt;!-- 页面的 WXML --&gt;&lt;custom-component&gt;这段文本是黄色的&lt;/custom-component&gt; 组件样式隔离 默认情况下，自定义组件的样式只受到自定义组件 wxss 的影响。除非以下两种情况： app.wxss 或页面的 wxss 中使用了标签名选择器（或一些其他特殊选择器）来直接指定样式，这些选择器会影响到页面和全部组件。通常情况下这是不推荐的做法。 指定特殊的样式隔离选项 styleIsolation 。 12345Component({ options: { styleIsolation: 'isolated' }}) 在开发者工具中预览效果 styleIsolation 选项从基础库版本 2.6.5 开始支持。它支持以下取值： isolated 表示启用样式隔离，在自定义组件内外，使用 class 指定的样式将不会相互影响（一般情况下的默认值）； apply-shared 表示页面 wxss 样式将影响到自定义组件，但自定义组件 wxss 中指定的样式不会影响页面； shared 表示页面 wxss 样式将影响到自定义组件，自定义组件 wxss 中指定的样式也会影响页面和其他设置了 apply-shared 或 shared 的自定义组件。（这个选项在插件中不可用。） 使用后两者时，请务必注意组件间样式的相互影响。 如果这个 Component 构造器用于构造页面 ，则默认值为 shared ，且还有以下几个额外的样式隔离选项可用： page-isolated 表示在这个页面禁用 app.wxss ，同时，页面的 wxss 不会影响到其他自定义组件； page-apply-shared 表示在这个页面禁用 app.wxss ，同时，页面 wxss 样式不会影响到其他自定义组件，但设为 shared 的自定义组件会影响到页面； page-shared 表示在这个页面禁用 app.wxss ，同时，页面 wxss 样式会影响到其他设为 apply-shared 或 shared 的自定义组件，也会受到设为 shared 的自定义组件的影响。 从小程序基础库版本 2.10.1 开始，也可以在页面或自定义组件的 json 文件中配置 styleIsolation （这样就不需在 js 文件的 options 中再配置）。例如： 123{ &quot;styleIsolation&quot;: &quot;isolated&quot;} 此外，小程序基础库版本 2.2.3 以上支持 addGlobalClass 选项，即在 Component 的 options 中设置 addGlobalClass: true 。 这个选项等价于设置 styleIsolation: apply-shared ，但设置了 styleIsolation 选项后这个选项会失效。 代码示例： 在开发者工具中预览效果 123456789101112/* 组件 custom-component.js */Component({ options: { addGlobalClass: true, }})&lt;!-- 组件 custom-component.wxml --&gt;&lt;text class=&quot;red-text&quot;&gt;这段文本的颜色由 `app.wxss` 和页面 `wxss` 中的样式定义来决定&lt;/text&gt;/* app.wxss */.red-text { color: red;} 外部样式类 基础库 1.9.90 开始支持，低版本需做兼容处理。 有时，组件希望接受外部传入的样式类。此时可以在 Component 中用 externalClasses 定义段定义若干个外部样式类。 这个特性可以用于实现类似于 view 组件的 hover-class 属性：页面可以提供一个样式类，赋予 view 的 hover-class ，这个样式类本身写在页面中而非 view 组件的实现中。 注意：在同一个节点上使用普通样式类和外部样式类时，两个类的优先级是未定义的，因此最好避免这种情况。 代码示例： 123456/* 组件 custom-component.js */Component({ externalClasses: ['my-class']})&lt;!-- 组件 custom-component.wxml --&gt;&lt;custom-component class=&quot;my-class&quot;&gt;这段文本的颜色由组件外的 class 决定&lt;/custom-component&gt; 这样，组件的使用者可以指定这个样式类对应的 class ，就像使用普通属性一样。在 2.7.1 之后，可以指定多个对应的 class 。 代码示例： 在开发者工具中预览效果 1234567891011&lt;!-- 页面的 WXML --&gt;&lt;custom-component my-class=&quot;red-text&quot; /&gt;&lt;custom-component my-class=&quot;large-text&quot; /&gt;&lt;!-- 以下写法需要基础库版本 2.7.1 以上 --&gt;&lt;custom-component my-class=&quot;red-text large-text&quot; /&gt;.red-text { color: red;}.large-text { font-size: 1.5em;} 引用页面或父组件的样式 基础库 2.9.2 开始支持，低版本需做兼容处理。 即使启用了样式隔离 isolated ，组件仍然可以在局部引用组件所在页面的样式或父组件的样式。 例如，如果在页面 wxss 中定义了： 123.blue-text { color: blue;} 在这个组件中可以使用 ~ 来引用这个类的样式： 1&lt;view class=&quot;~blue-text&quot;&gt; 这段文本是蓝色的 &lt;/view&gt; 如果在一个组件的父组件 wxss 中定义了： 123.red-text { color: red;} 在这个组件中可以使用 ^ 来引用这个类的样式： 1&lt;view class=&quot;^red-text&quot;&gt; 这段文本是红色的 &lt;/view&gt; 也可以连续使用多个 ^ 来引用祖先组件中的样式。 注意：如果组件是比较独立、通用的组件，请优先使用外部样式类的方式，而非直接引用父组件或页面的样式。 虚拟化组件节点 基础库 2.11.2 开始支持，低版本需做兼容处理。 默认情况下，自定义组件本身的那个节点是一个“普通”的节点，使用时可以在这个节点上设置 class style 、动画、 flex 布局等，就如同普通的 view 组件节点一样。 12345&lt;!-- 页面的 WXML --&gt;&lt;view style=&quot;display: flex&quot;&gt; &lt;!-- 默认情况下，这是一个普通的节点 --&gt; &lt;custom-component style=&quot;color: blue; flex: 1&quot;&gt;蓝色、满宽的&lt;/custom-component&gt;&lt;/view&gt; 但有些时候，自定义组件并不希望这个节点本身可以设置样式、响应 flex 布局等，而是希望自定义组件内部的第一层节点能够响应 flex 布局或者样式由自定义组件本身完全决定。 这种情况下，可以将这个自定义组件设置为“虚拟的”： 1234567891011Component({ options: { virtualHost: true }, properties: { style: { // 定义 style 属性可以拿到 style 属性上设置的值 type: String, } }, externalClasses: ['class'], // 可以将 class 设为 externalClasses}) 这样，可以将 flex 放入自定义组件内： 12345678910&lt;!-- 页面的 WXML --&gt;&lt;view style=&quot;display: flex&quot;&gt; &lt;!-- 如果设置了 virtualHost ，节点上的样式将失效 --&gt; &lt;custom-component style=&quot;color: blue&quot;&gt;不是蓝色的&lt;/custom-component&gt;&lt;/view&gt;&lt;!-- custom-component.wxml --&gt;&lt;view style=&quot;flex: 1&quot;&gt; 满宽的 &lt;slot&gt;&lt;/slot&gt;&lt;/view&gt; 需要注意的是，自定义组件节点上的 class style 和动画将不再生效，但仍可以： 将 style 定义成 properties 属性来获取 style 上设置的值； 将 class 定义成 externalClasses 外部样式类使得自定义组件 wxml 可以使用 class 值。 Component 构造器 Component 构造器可用于定义组件，调用 Component 构造器时可以指定组件的属性、数据、方法等。 详细的参数含义和使用请参考 Component 参考文档。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051Component({ behaviors: [], properties: { myProperty: { // 属性名 type: String, value: '' }, myProperty2: String // 简化的定义方式 }, data: {}, // 私有数据，可用于模板渲染 lifetimes: { // 生命周期函数，可以为函数，或一个在methods段中定义的方法名 attached: function () { }, moved: function () { }, detached: function () { }, }, // 生命周期函数，可以为函数，或一个在methods段中定义的方法名 attached: function () { }, // 此处attached的声明会被lifetimes字段中的声明覆盖 ready: function() { }, pageLifetimes: { // 组件所在页面的生命周期函数 show: function () { }, hide: function () { }, resize: function () { }, }, methods: { onMyButtonTap: function(){ this.setData({ // 更新属性和数据的方法与更新页面数据的方法类似 }) }, // 内部方法建议以下划线开头 _myPrivateMethod: function(){ // 这里将 data.A[0].B 设为 'myPrivateData' this.setData({ 'A[0].B': 'myPrivateData' }) }, _propertyChange: function(newVal, oldVal) { } }}) 使用 Component 构造器构造页面 事实上，小程序的页面也可以视为自定义组件。因而，页面也可以使用 Component 构造器构造，拥有与普通组件一样的定义段与实例方法。但此时要求对应 json 文件中包含 usingComponents 定义段。 此时，组件的属性可以用于接收页面的参数，如访问页面 /pages/index/index?paramA=123&amp;paramB=xyz ，如果声明有属性 paramA 或 paramB ，则它们会被赋值为 123 或 xyz 。 页面的生命周期方法（即 on 开头的方法），应写在 methods 定义段中。 代码示例： 123456789101112131415161718{ &quot;usingComponents&quot;: {}}Component({ properties: { paramA: Number, paramB: String, }, methods: { onLoad: function() { this.data.paramA // 页面参数 paramA 的值 this.data.paramB // 页面参数 paramB 的值 } }}) 使用 Component 构造器来构造页面的一个好处是可以使用 behaviors 来提取所有页面中公用的代码段。 例如，在所有页面被创建和销毁时都要执行同一段代码，就可以把这段代码提取到 behaviors 中。 代码示例： 12345678910111213141516171819202122232425// page-common-behavior.jsmodule.exports = Behavior({ attached: function() { // 页面创建时执行 console.info('Page loaded!') }, detached: function() { // 页面销毁时执行 console.info('Page unloaded!') }})// 页面 Avar pageCommonBehavior = require('./page-common-behavior')Component({ behaviors: [pageCommonBehavior], data: { /* ... */ }, methods: { /* ... */ },})// 页面 Bvar pageCommonBehavior = require('./page-common-behavior')Component({ behaviors: [pageCommonBehavior], data: { /* ... */ }, methods: { /* ... */ },}) 组件间通信与事件 组件间通信 组件间的基本通信方式有以下几种。 WXML 数据绑定：用于父组件向子组件的指定属性设置数据，仅能设置 JSON 兼容数据（自基础库版本 2.0.9 开始，还可以在数据中包含函数）。具体在 组件模板和样式 章节中介绍。 事件：用于子组件向父组件传递数据，可以传递任意数据。 如果以上两种方式不足以满足需要，父组件还可以通过 this.selectComponent 方法获取子组件实例对象，这样就可以直接访问组件的任意数据和方法。 监听事件 事件系统是组件间通信的主要方式之一。自定义组件可以触发任意的事件，引用组件的页面可以监听这些事件。关于事件的基本概念和用法，参见 事件 。 监听自定义组件事件的方法与监听基础组件事件的方法完全一致： 代码示例： 123456789&lt;!-- 当自定义组件触发“myevent”事件时，调用“onMyEvent”方法 --&gt;&lt;component-tag-name bindmyevent=&quot;onMyEvent&quot; /&gt;&lt;!-- 或者可以写成 --&gt;&lt;component-tag-name bind:myevent=&quot;onMyEvent&quot; /&gt;Page({ onMyEvent: function(e){ e.detail // 自定义组件触发事件时提供的detail对象 }}) 触发事件 自定义组件触发事件时，需要使用 triggerEvent 方法，指定事件名、detail对象和事件选项： 代码示例： 在开发者工具中预览效果 123456789101112&lt;!-- 在自定义组件中 --&gt;&lt;button bindtap=&quot;onTap&quot;&gt;点击这个按钮将触发“myevent”事件&lt;/button&gt;Component({ properties: {}, methods: { onTap: function(){ var myEventDetail = {} // detail对象，提供给事件监听函数 var myEventOption = {} // 触发事件的选项 this.triggerEvent('myevent', myEventDetail, myEventOption) } }}) 触发事件的选项包括： 选项名 类型 是否必填 默认值 描述 bubbles Boolean 否 false 事件是否冒泡 composed Boolean 否 false 事件是否可以穿越组件边界，为false时，事件将只能在引用组件的节点树上触发，不进入其他任何组件内部 capturePhase Boolean 否 false 事件是否拥有捕获阶段 关于冒泡和捕获阶段的概念，请阅读 事件 章节中的相关说明。 代码示例： 在开发者工具中预览效果 12345678910111213141516171819202122// 页面 page.wxml&lt;another-component bindcustomevent=&quot;pageEventListener1&quot;&gt; &lt;my-component bindcustomevent=&quot;pageEventListener2&quot;&gt;&lt;/my-component&gt;&lt;/another-component&gt;// 组件 another-component.wxml&lt;view bindcustomevent=&quot;anotherEventListener&quot;&gt; &lt;slot /&gt;&lt;/view&gt;// 组件 my-component.wxml&lt;view bindcustomevent=&quot;myEventListener&quot;&gt; &lt;slot /&gt;&lt;/view&gt;// 组件 my-component.jsComponent({ methods: { onTap: function(){ this.triggerEvent('customevent', {}) // 只会触发 pageEventListener2 this.triggerEvent('customevent', {}, { bubbles: true }) // 会依次触发 pageEventListener2 、 pageEventListener1 this.triggerEvent('customevent', {}, { bubbles: true, composed: true }) // 会依次触发 pageEventListener2 、 anotherEventListener 、 pageEventListener1 } }}) 获取组件实例 可在父组件里调用 this.selectComponent ，获取子组件的实例对象。 调用时需要传入一个匹配选择器 selector，如：this.selectComponent(&quot;.my-component&quot;)。 selector 详细语法可查看 selector 语法参考文档。 代码示例： 在开发者工具中预览效果 12345678// 父组件Page({ data: {}, getChildComponent: function () { const child = this.selectComponent('.my-component'); console.log(child) }}) 在上例中，父组件将会获取 class 为 my-component 的子组件实例对象，即子组件的 this 。 注意 ：默认情况下，小程序与插件之间、不同插件之间的组件将无法通过 selectComponent 得到组件实例（将返回 null）。如果想让一个组件在上述条件下依然能被 selectComponent 返回，可以自定义其返回结果（见下）。 自定义的组件实例获取结果 若需要自定义 selectComponent 返回的数据，可使用内置 behavior: wx://component-export 从基础库版本 2.2.3 开始提供支持。 使用该 behavior 时，自定义组件中的 export 定义段将用于指定组件被 selectComponent 调用时的返回值。 代码示例： 在开发者工具中预览效果 1234567891011// 自定义组件 my-component 内部Component({ behaviors: ['wx://component-export'], export() { return { myField: 'myValue' } }})&lt;!-- 使用自定义组件时 --&gt;&lt;my-component id=&quot;the-id&quot; /&gt;// 父组件调用const child = this.selectComponent('#the-id') // 等于 { myField: 'myValue' } 在上例中，父组件获取 id 为 the-id 的子组件实例的时候，得到的是对象 { myField: 'myValue' } 。 转载整理来源：https://developers.weixin.qq.com/miniprogram/dev/framework/app-service/route.html","link":"/2021/02/25/Draft/2021/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"title":"RabbitMQ","text":"RabbitMQ RabbitMQ简介 MQ全称为Message Queue，消息队列是应用程序和应用程序之间的通信方法。 RabbitMQ是由erlang语言开发，基于AMQP（Advanced Message Queue 高级消息队列协议）协议实现的消息队列，它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。RabbitMQ官方地址：http://www.rabbitmq.com/ AMQP 一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。 AMQP是一个二进制协议，拥有一些现代化特点：多信道、协商式，异步，安全，扩平台，中立，高效。 RabbitMQ是AMQP协议的Erlang的实现。 概念 说明 连接Connection 一个网络连接，比如TCP/IP套接字连接。 会话Session 端点之间的命名对话。在一个会话上下文中，保证“恰好传递一次”。 信道Channel 多路复用连接中的一条独立的双向数据流通道。为会话提供物理传输介质。 客户端Client AMQP连接或者会话的发起者。AMQP是非对称的，客户端生产和消费消息，服务器存储和路由这些消息。 服务节点Broker 消息中间件的服务节点；一般情况下可以将一个RabbitMQ Broker看作一台RabbitMQ 服务器。 端点 AMQP对话的任意一方。一个AMQP连接包括两个端点（一个是客户端，一个是服务器）。 消费者Consumer 一个从消息队列里请求消息的客户端程序。 生产者Producer 一个向交换机发布消息的客户端应用程序。 6种工作模式： 简单模式，work模式，Publish/Subscribe发布与订阅模式，Routing路由模式，Topics主题模式，RPC远程调用模式（远程调用，不太算MQ；暂不作介绍）； 官网对应模式介绍：https://www.rabbitmq.com/getstarted.html 优势： 应用解耦，提升容错性和可维护性 异步提速，提升用户体验，系统吞吐量 削峰填谷，提高系统稳定性 劣势： 系统可用性降低（需保证MQ高可用） 系统复杂度提高（不被重复消费，保证消息顺序） 数据一致性问题 使用条件: 生产者不需要从消费者处获得反馈 容许短暂的不一致性 确实用了有效果 ，好处大于复杂性等劣势 常见MQ产品 JMS JMS即Java消息服务（JavaMessage Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。 AMQP 与 JMS 区别 JMS是定义了统一的接口，来对消息操作进行统一；AMQP是通过规定协议来统一数据交互的格式 JMS限定了必须使用Java语言；AMQP只是协议，不规定实现方式，因此是跨语言的。 JMS规定了两种消息模式；而AMQP的消息模式更加丰富 RabbitMQ 安装配置 MQ版本选择和erlang相关 使用资料里提供的CentOS-7-x86_64-DVD-1810.iso 安装虚拟机. 1. 安装依赖环境 在线安装依赖环境： 1yum install build-essential openssl openssl-devel unixODBC unixODBC-devel make gcc gcc-c++ kernel-devel m4 ncurses-devel tk tc xz 2. 安装Erlang 上传 alt+p进入sftp界面 erlang-18.3-1.el7.centos.x86_64.rpm socat-1.7.3.2-5.el7.lux.x86_64.rpm rabbitmq-server-3.6.5-1.noarch.rpm 12# 安装rpm -ivh erlang-18.3-1.el7.centos.x86_64.rpm 如果出现如下错误 说明gblic 版本太低。我们可以查看当前机器的gblic 版本 1strings /lib64/libc.so.6 | grep GLIBC 当前最高版本2.12，需要2.15.所以需要升级glibc 使用yum更新安装依赖 1sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make -y 下载rpm包 1234567wget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-utils-2.17-55.el6.x86_64.rpm &amp;wget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-static-2.17-55.el6.x86_64.rpm &amp;wget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-2.17-55.el6.x86_64.rpm &amp;wget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-common-2.17-55.el6.x86_64.rpm &amp;wget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-devel-2.17-55.el6.x86_64.rpm &amp;wget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/glibc-headers-2.17-55.el6.x86_64.rpm &amp;wget http://copr-be.cloud.fedoraproject.org/results/mosquito/myrepo-el6/epel-6-x86_64/glibc-2.17-55.fc20/nscd-2.17-55.el6.x86_64.rpm &amp; 安装rpm包 1sudo rpm -Uvh *-2.17-55.el6.x86_64.rpm --force --nodeps 安装完毕后再查看glibc版本,发现glibc版本已经到2.17了 1strings /lib64/libc.so.6 | grep GLIBC 3. 安装RabbitMQ 123456# 安装rpm -ivh socat-1.7.3.2-5.el7.lux.x86_64.rpm# 安装rpm -ivh rabbitmq-server-3.6.5-1.noarch.rpm 12345678910111213[root@softbank126011009150 rabbitmq]# lserlang-18.3-1.el7.centos.x86_64.rpm rabbitmq-server-3.6.5-1.noarch.rpm socat-1.7.3.2-1.1.el7.x86_64.rpm[root@softbank126011009150 rabbitmq]# rpm -ivh erlang-18.3-1.el7.centos.x86_64.rpm 准备中... ################################# [100%] 软件包 erlang-18.3-1.el7.centos.x86_64 已经安装[root@softbank126011009150 rabbitmq]# rpm -ivh socat-1.7.3.2-1.1.el7.x86_64.rpm 警告：socat-1.7.3.2-1.1.el7.x86_64.rpm: 头V4 RSA/SHA1 Signature, 密钥 ID 87e360b8: NOKEY准备中... ################################# [100%] 软件包 socat-1.7.3.2-1.1.el7.x86_64 已经安装[root@softbank126011009150 rabbitmq]# rpm -ivh rabbitmq-server-3.6.5-1.noarch.rpm 警告：rabbitmq-server-3.6.5-1.noarch.rpm: 头V4 RSA/SHA1 Signature, 密钥 ID 6026dfca: NOKEY准备中... ################################# [100%] 软件包 rabbitmq-server-3.6.5-1.noarch 已经安装 4. 开启管界面及配置 123456# 开启管理界面rabbitmq-plugins enable rabbitmq_management# 修改默认配置信息vim /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.5/ebin/rabbit.app # 比如修改密码、配置等等，例如：loopback_users 中的 &lt;&lt;&quot;guest&quot;&gt;&gt;,只保留guesthttp://ip:15672 访问 5. 启动 123456service rabbitmq-server start # 启动服务service rabbitmq-server stop # 停止服务service rabbitmq-server restart # 重启服务service iptables stop#关闭防火墙systemctl stop firewalld #conos7关闭防火墙方法 设置配置文件 1234cd /usr/share/doc/rabbitmq-server-3.6.5/cp rabbitmq.config.example /etc/rabbitmq/rabbitmq.config 6. 配置虚拟主机及用户 6.1. 用户角色 RabbitMQ在安装好后，可以访问http://ip地址:15672 ；其自带了guest/guest的用户名和密码；如果需要创建自定义用户；那么也可以登录管理界面后，如下操作： 角色说明： 1、 超级管理员(administrator) 可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 2、 监控者(monitoring) 可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 3、 策略制定者(policymaker) 可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 4、 普通管理者(management) 仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 5、 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。 6.2. Virtual Hosts配置 像mysql拥有数据库的概念并且可以指定用户对库和表等操作的权限。RabbitMQ也有类似的权限管理；在RabbitMQ中可以虚拟消息服务器Virtual Host，每个Virtual Hosts相当于一个相对独立的RabbitMQ服务器，每个VirtualHost之间是相互隔离的。exchange、queue、message不能互通。 相当于mysql的db。Virtual Name一般以/开头。 6.2.1. 创建Virtual Hosts 6.2.2. 设置Virtual Hosts权限 解决配置文件未找到 1234567891011121314151617181920212223242526272829[root@softbank126011009150 rabbitmq]# cd /usr/share/doc/rabbitmq-server-3.6.5/[root@softbank126011009150 rabbitmq-server-3.6.5]# lsLICENSE LICENSE-APL2-Stomp-Websocket LICENSE-EPL-OTP LICENSE-MIT-jQuery164 LICENSE-MIT-Sammy060 LICENSE-MPL-RabbitMQ set_rabbitmq_policy.sh.exampleLICENSE-APACHE2-ExplorerCanvas LICENSE-BSD-base64js LICENSE-MIT-EJS10 LICENSE-MIT-Mochi LICENSE-MIT-SockJS rabbitmq.config.exampleLICENSE-APL2-Rebar LICENSE-BSD-glMatrix LICENSE-MIT-Flot LICENSE-MIT-Mochiweb LICENSE-MPL2 README[root@softbank126011009150 rabbitmq-server-3.6.5]# ll总用量 200-rw-r--r--. 1 root root 28945 8月 5 2016 LICENSE-rw-r--r--. 1 root root 11358 8月 5 2016 LICENSE-APACHE2-ExplorerCanvas-rw-r--r--. 1 root root 10175 8月 5 2016 LICENSE-APL2-Rebar-rw-r--r--. 1 root root 10851 8月 5 2016 LICENSE-APL2-Stomp-Websocket-rw-r--r--. 1 root root 1206 8月 5 2016 LICENSE-BSD-base64js-rw-r--r--. 1 root root 1304 8月 5 2016 LICENSE-BSD-glMatrix-rw-r--r--. 1 root root 14041 8月 5 2016 LICENSE-EPL-OTP-rw-r--r--. 1 root root 1087 8月 5 2016 LICENSE-MIT-EJS10-rw-r--r--. 1 root root 1069 8月 5 2016 LICENSE-MIT-Flot-rw-r--r--. 1 root root 1075 8月 5 2016 LICENSE-MIT-jQuery164-rw-r--r--. 1 root root 1087 3月 31 2016 LICENSE-MIT-Mochi-rw-r--r--. 1 root root 1087 8月 5 2016 LICENSE-MIT-Mochiweb-rw-r--r--. 1 root root 1076 8月 5 2016 LICENSE-MIT-Sammy060-rw-r--r--. 1 root root 1056 8月 5 2016 LICENSE-MIT-SockJS-rw-r--r--. 1 root root 16726 8月 5 2016 LICENSE-MPL2-rw-r--r--. 1 root root 24897 8月 5 2016 LICENSE-MPL-RabbitMQ-rw-r--r--. 1 root root 21023 4月 11 2016 rabbitmq.config.example-rw-r--r--. 1 root root 943 3月 31 2016 README-rw-r--r--. 1 root root 277 3月 31 2016 set_rabbitmq_policy.sh.example[root@softbank126011009150 rabbitmq-server-3.6.5]# cp ./rabbitmq.config.example /etc/rabbitmq/rabbitmq.config[root@softbank126011009150 rabbitmq-server-3.6.5]# service rabbitmq-server restartRestarting rabbitmq-server (via systemctl): [ 确定 ] 工作模式 简单模式 生产者 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.lxl.producer;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.util.concurrent.TimeoutException;public class Producer_HelloWord { public static void main(String[] args) throws IOException, TimeoutException { //1.创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //2. 设置参数 factory.setHost(&quot;126.11.41.128&quot;);//ip 默认值 localhost factory.setPort(5672); //端口 默认值 5672 factory.setVirtualHost(&quot;/lxlv&quot;);//虚拟机 默认值/ factory.setUsername(&quot;lxl&quot;);//用户名 默认 guest factory.setPassword(&quot;lxl&quot;);//密码 默认值 guest //3. 创建连接 Connection Connection connection = factory.newConnection(); //4. 创建Channel Channel channel = connection.createChannel(); //5. 创建队列Queue /* queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments) 参数： 1. queue：队列名称 2. durable:是否持久化，当mq重启之后，还在 3. exclusive： * 是否独占。只能有一个消费者监听这队列 * 当Connection关闭时，是否删除队列 * 4. autoDelete:是否自动删除。当没有Consumer时，自动删除掉 5. arguments：参数。 */ //如果没有一个名字叫hello_world的队列，则会创建该队列，如果有则不会创建 channel.queueDeclare(&quot;hello_world&quot;,true,false,false,null); /* basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body) 参数： 1. exchange：交换机名称。简单模式下交换机会使用默认的 &quot;&quot; 2. routingKey：路由名称 3. props：配置信息 4. body：发送消息数据 */ String body = &quot;hello rabbitmq~~~&quot;; //6. 发送消息 channel.basicPublish(&quot;&quot;,&quot;hello_world&quot;,null,body.getBytes()); //7.释放资源// channel.close();// connection.close(); }} 消费者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package com.lxl.consumer;import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeoutException;public class Consumer_HelloWorld { public static void main(String[] args) throws IOException, TimeoutException { //1.创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //2. 设置参数 factory.setHost(&quot;126.11.41.128&quot;);//ip 默认值 localhost factory.setPort(5672); //端口 默认值 5672 factory.setVirtualHost(&quot;/lxlv&quot;);//虚拟机 默认值/ factory.setUsername(&quot;lxl&quot;);//用户名 默认 guest factory.setPassword(&quot;lxl&quot;);//密码 默认值 guest //3. 创建连接 Connection Connection connection = factory.newConnection(); //4. 创建Channel Channel channel = connection.createChannel(); //5. 创建队列Queue /* queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments) 参数： 1. queue：队列名称 2. durable:是否持久化，当mq重启之后，还在 3. exclusive： * 是否独占。只能有一个消费者监听这队列 * 当Connection关闭时，是否删除队列 * 4. autoDelete:是否自动删除。当没有Consumer时，自动删除掉 5. arguments：参数。 */ //如果没有一个名字叫hello_world的队列，则会创建该队列，如果有则不会创建 channel.queueDeclare(&quot;hello_world&quot;,true,false,false,null); /* basicConsume(String queue, boolean autoAck, Consumer callback) 参数： 1. queue：队列名称 2. autoAck：是否自动确认 3. callback：回调对象 */ // 接收消息 Consumer consumer = new DefaultConsumer(channel){ /* 回调方法，当收到消息后，会自动执行该方法 1. consumerTag：标识 2. envelope：获取一些信息，交换机，路由key... 3. properties:配置信息 4. body：数据 */ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(&quot;consumerTag：&quot;+consumerTag); System.out.println(&quot;Exchange：&quot;+envelope.getExchange()); System.out.println(&quot;RoutingKey：&quot;+envelope.getRoutingKey()); System.out.println(&quot;properties：&quot;+properties); System.out.println(&quot;body：&quot;+new String(body)); } }; channel.basicConsume(&quot;hello_world&quot;,true,consumer); //关闭资源？不要 }} RabbitMQ运转流程 在入门案例中： 生产者发送消息 生产者创建连接（Connection），开启一个信道（Channel），连接到RabbitMQ Broker； 声明队列并设置属性；是否排它，是否持久化，是否自动删除； 将路由键（空字符串）与队列绑定起来； 发送消息至RabbitMQ Broker； 关闭信道； 关闭连接； 消费者接收消息 消费者创建连接（Connection），开启一个信道（Channel），连接到RabbitMQ Broker 向Broker 请求消费相应队列中的消息，设置相应的回调函数； 等待Broker回应闭关投递响应队列中的消息，消费者接收消息； 确认（ack，自动确认）接收到的消息； RabbitMQ从队列中删除相应已经被确认的消息； 关闭信道； 关闭连接； 生产者流转过程说明 客户端与代理服务器Broker建立连接。会调用newConnection() 方法,这个方法会进一步封装Protocol Header 0-9-1 的报文头发送给Broker ，以此通知Broker 本次交互采用的是AMQPO-9-1 协议，紧接着Broker 返回Connection.Start 来建立连接，在连接的过程中涉及Connection.Start/.Start-OK 、Connection.Tune/.Tune-Ok ，Connection.Open/ .Open-Ok 这6 个命令的交互。 客户端调用connection.createChannel方法。此方法开启信道，其包装的channel.open命令发送给Broker,等待channel.basicPublish方法，对应的AMQP命令为Basic.Publish,这个命令包含了content Header 和content Body()。content Header 包含了消息体的属性，例如:投递模式，优先级等，content Body 包含了消息体本身。 客户端发送完消息需要关闭资源时，涉及到Channel.Close和Channl.Close-Ok 与Connetion.Close和Connection.Close-Ok的命令交互。 消费者流转过程说明 消费者客户端与代理服务器Broker建立连接。会调用newConnection() 方法,这个方法会进一步封装Protocol Header 0-9-1 的报文头发送给Broker ，以此通知Broker 本次交互采用的是AMQPO-9-1 协议，紧接着Broker 返回Connection.Start 来建立连接，在连接的过程中涉及Connection.Start/.Start-OK 、Connection.Tune/.Tune-Ok ，Connection.Open/ .Open-Ok 这6 个命令的交互。 消费者客户端调用connection.createChannel方法。和生产者客户端一样，协议涉及Channel . Open/Open-Ok命令。 在真正消费之前，消费者客户端需要向Broker 发送Basic.Consume 命令(即调用channel.basicConsume 方法〉将Channel 置为接收模式，之后Broker 回执Basic . Consume - Ok 以告诉消费者客户端准备好消费消息。 Broker 向消费者客户端推送(Push) 消息，即Basic.Deliver 命令，这个命令和Basic.Publish 命令一样会携带Content Header 和Content Body。 消费者接收到消息并正确消费之后，向Broker 发送确认，即Basic.Ack 命令。 客户端发送完消息需要关闭资源时，涉及到Channel.Close和Channl.Close-Ok 与Connetion.Close和Connection.Close-Ok的命令交互。 工作队列模式 模式说明（只有一盒糖你们几个抢） Work Queues与入门程序的简单模式相比，多了一个或一些消费端，多个消费端共同消费同一个队列中的消息。 应用场景：对于 任务过重或任务较多情况使用工作队列可以提高任务处理的速度。 代码 Work Queues与入门程序的简单模式的代码是几乎一样的；可以完全复制，并复制多一个消费者进行多个消费者同时消费消息的测试。 生产者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.itheima.rabbitmq.work;import com.itheima.rabbitmq.util.ConnectionUtil;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;public class Producer { static final String QUEUE_NAME = &quot;work_queue&quot;; public static void main(String[] args) throws Exception { //创建连接 Connection connection = ConnectionUtil.getConnection(); // 创建频道 Channel channel = connection.createChannel(); // 声明（创建）队列 /** * 参数1：队列名称 * 参数2：是否定义持久化队列 * 参数3：是否独占本次连接 * 参数4：是否在不使用的时候自动删除队列 * 参数5：队列其它参数 */ channel.queueDeclare(QUEUE_NAME, true, false, false, null); for (int i = 1; i &lt;= 30; i++) { // 发送信息 String message = &quot;你好；小兔子！work模式--&quot; + i; /** * 参数1：交换机名称，如果没有指定则使用默认Default Exchage * 参数2：路由key,简单模式可以传递队列名称 * 参数3：消息其它属性 * 参数4：消息内容 */ channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes()); System.out.println(&quot;已发送消息：&quot; + message); } // 关闭资源 channel.close(); connection.close(); }} 消费者1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.itheima.rabbitmq.work;import com.itheima.rabbitmq.util.ConnectionUtil;import com.rabbitmq.client.*;import java.io.IOException;public class Consumer1 { public static void main(String[] args) throws Exception { Connection connection = ConnectionUtil.getConnection(); // 创建频道 Channel channel = connection.createChannel(); // 声明（创建）队列 /** * 参数1：队列名称 * 参数2：是否定义持久化队列 * 参数3：是否独占本次连接 * 参数4：是否在不使用的时候自动删除队列 * 参数5：队列其它参数 */ channel.queueDeclare(Producer.QUEUE_NAME, true, false, false, null); //一次只能接收并处理一个消息 channel.basicQos(1); //创建消费者；并设置消息处理 DefaultConsumer consumer = new DefaultConsumer(channel){ @Override /** * consumerTag 消息者标签，在channel.basicConsume时候可以指定 * envelope 消息包的内容，可从中获取消息id，消息routingkey，交换机，消息和重传标志(收到消息失败后是否需要重新发送) * properties 属性信息 * body 消息 */ public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { try { //路由key System.out.println(&quot;路由key为：&quot; + envelope.getRoutingKey()); //交换机 System.out.println(&quot;交换机为：&quot; + envelope.getExchange()); //消息id System.out.println(&quot;消息id为：&quot; + envelope.getDeliveryTag()); //收到的消息 System.out.println(&quot;消费者1-接收到的消息为：&quot; + new String(body, &quot;utf-8&quot;)); Thread.sleep(1000); //确认消息 channel.basicAck(envelope.getDeliveryTag(), false); } catch (InterruptedException e) { e.printStackTrace(); } } }; //监听消息 /** * 参数1：队列名称 * 参数2：是否自动确认，设置为true为表示消息接收到自动向mq回复接收到了，mq接收到回复会删除消息，设置为false则需要手动确认 * 参数3：消息接收到后回调 */ channel.basicConsume(Producer.QUEUE_NAME, false, consumer); }} 消费者2 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.itheima.rabbitmq.work;import com.itheima.rabbitmq.util.ConnectionUtil;import com.rabbitmq.client.*;import java.io.IOException;public class Consumer2 { public static void main(String[] args) throws Exception { Connection connection = ConnectionUtil.getConnection(); // 创建频道 Channel channel = connection.createChannel(); // 声明（创建）队列 /** * 参数1：队列名称 * 参数2：是否定义持久化队列 * 参数3：是否独占本次连接 * 参数4：是否在不使用的时候自动删除队列 * 参数5：队列其它参数 */ channel.queueDeclare(Producer.QUEUE_NAME, true, false, false, null); //一次只能接收并处理一个消息 channel.basicQos(1); //创建消费者；并设置消息处理 DefaultConsumer consumer = new DefaultConsumer(channel){ @Override /** * consumerTag 消息者标签，在channel.basicConsume时候可以指定 * envelope 消息包的内容，可从中获取消息id，消息routingkey，交换机，消息和重传标志(收到消息失败后是否需要重新发送) * properties 属性信息 * body 消息 */ public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { try { //路由key System.out.println(&quot;路由key为：&quot; + envelope.getRoutingKey()); //交换机 System.out.println(&quot;交换机为：&quot; + envelope.getExchange()); //消息id System.out.println(&quot;消息id为：&quot; + envelope.getDeliveryTag()); //收到的消息 System.out.println(&quot;消费者2-接收到的消息为：&quot; + new String(body, &quot;utf-8&quot;)); Thread.sleep(1000); //确认消息 channel.basicAck(envelope.getDeliveryTag(), false); } catch (InterruptedException e) { e.printStackTrace(); } } }; //监听消息 /** * 参数1：队列名称 * 参数2：是否自动确认，设置为true为表示消息接收到自动向mq回复接收到了，mq接收到回复会删除消息，设置为false则需要手动确认 * 参数3：消息接收到后回调 */ channel.basicConsume(Producer.QUEUE_NAME, false, consumer); }} 测试 启动两个消费者，然后再启动生产者发送消息；到IDEA的两个消费者对应的控制台查看是否竞争性的接收到消息。 小结 在一个队列中如果有多个消费者，那么消费者之间对于同一个消息的关系是竞争的关系。 Publish/Subscribe发布与订阅模式 模式说明（给喜欢的人一样的糖）【FANOUT】 在订阅模型中，多了一个 Exchange 角色，而且过程略有变化： P：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） 123456789//1.创建连接工厂//2. 设置参数//3. 创建连接 Connection//4. 创建Channel//5. 创建交换机//6. 创建队列//7. 绑定队列和交换机//8. 发送消息//9. 释放资源 C：消费者，消息的接收者，会一直等待消息到来 Queue：消息队列，接收消息、缓存消息 Exchange：交换机（X）。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有常见以下3种类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与 Exchange 绑定，或者没有符合路由规则的队列，那么消息会丢失！ Routing路由工作模式 模式说明：给更爱的人更甜的糖【DIRECT】 队列与交换机的绑定，不能是任意绑定了，而是要指定一个 RoutingKey（路由key） l消息的发送方在向 Exchange 发送消息时，也必须指定消息的 RoutingKey lExchange 不再把消息交给每一个绑定的队列，而是根据消息的 Routing Key 进行判断，只有队列的Routingkey 与消息的 Routing key 完全一致，才会接收到消息 lP：生产者，向 Exchange 发送消息，发送消息时，会指定一个routing key lX：Exchange（交换机），接收生产者的消息，然后把消息递交给与 routing key 完全匹配的队列 lC1：消费者，其所在队列指定了需要 routing key 为 error 的消息 lC2：消费者，其所在队列指定了需要 routing key 为 info、error、warning 的消息 Routing 模式要求队列在绑定交换机时要指定 routing key，消息会转发到符合 routing key 的队列 Topics通配符工作模式 模式说明：给姓李的人类棉花糖，姓梁的人类鸡屎麻糖【TOPIC】 Topic类型与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！ Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 通配符规则： #：匹配一个或多个词 *：匹配不多不少恰好1个词 举例： item.#：能够匹配item.insert.abc 或者 item.insert item.*：只能匹配item.insert 图解： 红色Queue：绑定的是usa.# ，因此凡是以 usa.开头的routing key 都会被匹配到 黄色Queue：绑定的是#.news ，因此凡是以 .news结尾的 routing key 都会被匹配 Spring-RabbitMQ 详情见代码 SpringBoot-RabbitMQ RabbitMQ高级特性 发、收、限、时、达、 1.1消息可靠投递 【寄的糖你收到了吗】 confirm确认模式 【消息从 producer 到 exchange 无论如何会返回一个confirmCallback】 return退回模式 【消息从producer到 queue 失败则会返回一个returnCallback】 rabbitmq整各消息投递的路径为： profucer-----》rabbitmq broker----》exchange-----》queue----》consumer 设置ConnectionFactory的publisher-confirm=&quot;true&quot; 开启确认模式 使用rabbitTemplate.setConfirmCallback设置回调函数。当消息发送到exchange后回调confirm方法。在方法中判断true，则发送成功，反之失败，需要处理 设置ConnectionFactory的publisher-returns=&quot;true&quot; 开启退回模式 使用rabbitTemplate.setReturnCallback设置回调函数。当消息从exchange路由到queue失败后，如果设置了rabbitTemplate.setMandatory(true)参数，则会将消息退回给producer。并执行回调函数returnedMessage。 在RabbitMQ中也提供了事物机制，但是性能较差。 1.2Consumer ACK 【收到糖给你怎么回复】 ack指acknowledge，确认。表示消费端收到消息后的确认方式 三种确认方式： ​ 自动确认：acknowledge=&quot;none&quot;【业务出问题也会回复收到】 ​ 手动确认：acknowledge=&quot;manual&quot;【等业务处理没问题后回复收到，有问题可处理】 ​ 根据异常情况确认：acknowledge=&quot;auto&quot; ​ 自动确认消息被consumer接收到，则自动确认，并将响应message从缓存中移除，实际业务中小细节受到，业务出现异常，那么消息会丢失，如果是设置的手动确认方式，则需要业务处理成功后，调用channel.basicAck(),手动签收，如果出现异常，则调用channel.basicNack（）方法，让其自动重发消息。 1234* 1. 设置手动签收。acknowledge=&quot;manual&quot;* 2. 让监听器类实现ChannelAwareMessageListener接口* 3. 如果消息成功处理，则调用channel的 basicAck()签收* 4. 如果消息处理失败，则调用channel的basicNack()拒绝签收，broker重新发送给consumer 1.3消费端限流qos 【我每次只收1000颗糖】 12341. 确保ack机制为手动确认。2. listener-container配置属性 perfetch = 1,表示消费端每次从mq拉去一条消息来消费，直到手动确认消费完毕后，才会继续拉去下一条消息。 &lt;rabbit:listener-container connection-factory=&quot;connectionFactory&quot; acknowledge=&quot;manual&quot; prefetch=&quot;1&quot; &gt; 1.4TTL 【糖放快递站十年就不能吃了】 1234567* TTL:过期时间* 1. 队列统一过期* 2. 消息单独过期** 如果设置了消息的过期时间，也设置了队列的过期时间，它以时间短的为准。* 队列过期后，会将队列所有消息全部移除。* 消息过期后，只有消息在队列顶端，才会判断其是否过期(移除掉) 1.5死信队列 【不好吃的糖都给其他人吧】 死信队列（DXL）。Dead Letter Exchange（死信队列交换机），当消息成为Dead Message后，可以被重新发送到另外一个交换机，这个交换机就是DEX。死信队列和死信交换机和普通的没有区别。 问题： 1.消息什么时候成为死信? 消息成为死信的三种情况： 1.队列消息的长度达到限制 2.消费者拒收消费消息，basicNack/basicReject，并且不把消息重新放入原目标队列，requeue=false 3.原队列存在消息过期设置，消息达超时间未被消费； 2.队列如何与DEX绑定？ 1.6延迟队列 【我妈叫我三十分钟后才能吃这颗糖】 消息进入队列后不会被立即被消费，只有达到指定时间后，才会被消费。 需求： ​ 1.下单后三十分钟未支付，取消订单，回滚库存 ​ 2.新用户注册7天后，发送短信问候 实现方式 ​ 1.定时器（有延迟，对数据库有影响） ​ 2.延迟队列（MQ中未直接提供延迟队列，DLX+TTL实现） 1.7日志与监控 RabbitMQ默认日志存放路径： /var/log/rabbitmq/rabbit@xxx.log 日志包含了RabbitMQ的版本号、Erlang的版本号、RabbitMQ服务节点名称、cookie的hash值、RabbitMQ配置文件地址、内存限制、磁盘限制、默认账户guest的创建以及权限配置等等。 123456789101112131415161718查看队列# rabbitmqctl list_queues查看exchanges# rabbitmqctl list_exchanges查看用户# rabbitmqctl list_users查看连接# rabbitmqctl list_connections查看消费者信息# rabbitmqctl list_consumers查看环境变量# rabbitmqctl environment查看未被确认的队列# rabbitmqctl list_queues name messages_unacknowledged查看单个队列的内存使用# rabbitmqctl list_queues name memory查看准备就绪的队列# rabbitmqctl list_queues name messages_ready 1.8 消息追踪 在使用任何消息中间件的过程中，难免会出现某条消息异常丢失的情况。对于RabbitMQ而言，可能是因为生产者或消费者与RabbitMQ断开了连接，而它们与RabbitMQ又采用了不同的确认机制；也有可能是因为交换器与队列之间不同的转发策略；甚至是交换器并没有与任何队列进行绑定，生产者又不感知或者没有采取相应的措施；另外RabbitMQ本身的集群策略也可能导致消息的丢失。这个时候就需要有一个较好的机制跟踪记录消息的投递过程，以此协助开发和运维人员进行问题的定位。 在RabbitMQ中可以使用Firehose和rabbitmq_tracing插件功能来实现消息追踪。 Firehose firehose的机制是将生产者投递给rabbitmq的消息，rabbitmq投递给消费者的消息按照指定的格式发送到默认的exchange上。这个默认的exchange的名称为amq.rabbitmq.trace，它是一个topic类型的exchange。发送到这个exchange上的消息的routing key为 publish.exchangename 和 deliver.queuename。其中exchangename和queuename为实际exchange和queue的名称，分别对应生产者投递到exchange的消息，和消费者从queue上获取的消息。 注意：打开 trace 会影响消息写入功能，适当打开后请关闭。 rabbitmqctl trace_on：开启Firehose命令 rabbitmqctl trace_off：关闭Firehose命令 rabbitmq_tracing rabbitmq_tracing和Firehose在实现上如出一辙，只不过rabbitmq_tracing的方式比Firehose多了一层GUI的包装，更容易使用和管理。 启用插件：rabbitmq-plugins enable rabbitmq_tracing 应用问题 1.消息可靠性保障------消息补偿 2.消息幂等性保障-----乐观锁机制 幂等性指一次和多次请求某一个资源，对于资源本身应该具有同样的结果。也就是说，其任意多次执行对资源本身所产生的影响均与一次执行的影响相同。 在MQ中指，消费多条相同的消息，得到与消费该消息一次相同的结果。 3.RabbitMQ集群搭建 摘要：实际生产应用中都会采用消息队列的集群方案，如果选择RabbitMQ那么有必要了解下它的集群方案原理 一般来说，如果只是为了学习RabbitMQ或者验证业务工程的正确性那么在本地环境或者测试环境上使用其单实例部署就可以了，但是出于MQ中间件本身的可靠性、并发性、吞吐量和消息堆积能力等问题的考虑，在生产环境上一般都会考虑使用RabbitMQ的集群方案。 3.1 集群方案的原理 RabbitMQ这款消息队列中间件产品本身是基于Erlang编写，Erlang语言天生具备分布式特性（通过同步Erlang集群各节点的magic cookie来实现）。因此，RabbitMQ天然支持Clustering。这使得RabbitMQ本身不需要像ActiveMQ、Kafka那样通过ZooKeeper分别来实现HA方案和保存集群的元数据。集群是保证可靠性的一种方式，同时可以通过水平扩展以达到增加消息吞吐量能力的目的。 3.2 单机多实例部署 由于某些因素的限制，有时候你不得不在一台机器上去搭建一个rabbitmq集群，这个有点类似zookeeper的单机版。真实生成环境还是要配成多机集群的。有关怎么配置多机集群的可以参考其他的资料，这里主要论述如何在单机中配置多个rabbitmq实例。 主要参考官方文档：https://www.rabbitmq.com/clustering.html 首先确保RabbitMQ运行没有问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@super ~]# rabbitmqctl statusStatus of node rabbit@super ...[{pid,10232}, {running_applications, [{rabbitmq_management,&quot;RabbitMQ Management Console&quot;,&quot;3.6.5&quot;}, {rabbitmq_web_dispatch,&quot;RabbitMQ Web Dispatcher&quot;,&quot;3.6.5&quot;}, {webmachine,&quot;webmachine&quot;,&quot;1.10.3&quot;}, {mochiweb,&quot;MochiMedia Web Server&quot;,&quot;2.13.1&quot;}, {rabbitmq_management_agent,&quot;RabbitMQ Management Agent&quot;,&quot;3.6.5&quot;}, {rabbit,&quot;RabbitMQ&quot;,&quot;3.6.5&quot;}, {os_mon,&quot;CPO CXC 138 46&quot;,&quot;2.4&quot;}, {syntax_tools,&quot;Syntax tools&quot;,&quot;1.7&quot;}, {inets,&quot;INETS CXC 138 49&quot;,&quot;6.2&quot;}, {amqp_client,&quot;RabbitMQ AMQP Client&quot;,&quot;3.6.5&quot;}, {rabbit_common,[],&quot;3.6.5&quot;}, {ssl,&quot;Erlang/OTP SSL application&quot;,&quot;7.3&quot;}, {public_key,&quot;Public key infrastructure&quot;,&quot;1.1.1&quot;}, {asn1,&quot;The Erlang ASN1 compiler version 4.0.2&quot;,&quot;4.0.2&quot;}, {ranch,&quot;Socket acceptor pool for TCP protocols.&quot;,&quot;1.2.1&quot;}, {mnesia,&quot;MNESIA CXC 138 12&quot;,&quot;4.13.3&quot;}, {compiler,&quot;ERTS CXC 138 10&quot;,&quot;6.0.3&quot;}, {crypto,&quot;CRYPTO&quot;,&quot;3.6.3&quot;}, {xmerl,&quot;XML parser&quot;,&quot;1.3.10&quot;}, {sasl,&quot;SASL CXC 138 11&quot;,&quot;2.7&quot;}, {stdlib,&quot;ERTS CXC 138 10&quot;,&quot;2.8&quot;}, {kernel,&quot;ERTS CXC 138 10&quot;,&quot;4.2&quot;}]}, {os,{unix,linux}}, {erlang_version, &quot;Erlang/OTP 18 [erts-7.3] [source] [64-bit] [async-threads:64] [hipe] [kernel-poll:true]\\n&quot;}, {memory, [{total,56066752}, {connection_readers,0}, {connection_writers,0}, {connection_channels,0}, {connection_other,2680}, {queue_procs,268248}, {queue_slave_procs,0}, {plugins,1131936}, {other_proc,18144280}, {mnesia,125304}, {mgmt_db,921312}, {msg_index,69440}, {other_ets,1413664}, {binary,755736}, {code,27824046}, {atom,1000601}, {other_system,4409505}]}, {alarms,[]}, {listeners,[{clustering,25672,&quot;::&quot;},{amqp,5672,&quot;::&quot;}]}, {vm_memory_high_watermark,0.4}, {vm_memory_limit,411294105}, {disk_free_limit,50000000}, {disk_free,13270233088}, {file_descriptors, [{total_limit,924},{total_used,6},{sockets_limit,829},{sockets_used,0}]}, {processes,[{limit,1048576},{used,262}]}, {run_queue,0}, {uptime,43651}, {kernel,{net_ticktime,60}}] 停止rabbitmq服务 123[root@super sbin]# service rabbitmq-server stopStopping rabbitmq-server: rabbitmq-server. 启动第一个节点： 12345678910[root@super sbin]# RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit1 rabbitmq-server start RabbitMQ 3.6.5. Copyright (C) 2007-2016 Pivotal Software, Inc. ## ## Licensed under the MPL. See http://www.rabbitmq.com/ ## ## ########## Logs: /var/log/rabbitmq/rabbit1.log ###### ## /var/log/rabbitmq/rabbit1-sasl.log ########## Starting broker... completed with 6 plugins. 启动第二个节点： web管理插件端口占用,所以还要指定其web插件占用的端口号。 1234567891011[root@super ~]# RABBITMQ_NODE_PORT=5674 RABBITMQ_SERVER_START_ARGS=&quot;-rabbitmq_management listener [{port,15674}]&quot; RABBITMQ_NODENAME=rabbit2 rabbitmq-server start RabbitMQ 3.6.5. Copyright (C) 2007-2016 Pivotal Software, Inc. ## ## Licensed under the MPL. See http://www.rabbitmq.com/ ## ## ########## Logs: /var/log/rabbitmq/rabbit2.log ###### ## /var/log/rabbitmq/rabbit2-sasl.log ########## Starting broker... completed with 6 plugins. 结束命令： 12rabbitmqctl -n rabbit1 stoprabbitmqctl -n rabbit2 stop rabbit1操作作为主节点： 1234567[root@super ~]# rabbitmqctl -n rabbit1 stop_app Stopping node rabbit1@super ...[root@super ~]# rabbitmqctl -n rabbit1 reset Resetting node rabbit1@super ...[root@super ~]# rabbitmqctl -n rabbit1 start_appStarting node rabbit1@super ...[root@super ~]# rabbit2操作为从节点： 123456789[root@super ~]# rabbitmqctl -n rabbit2 stop_appStopping node rabbit2@super ...[root@super ~]# rabbitmqctl -n rabbit2 resetResetting node rabbit2@super ...[root@super ~]# rabbitmqctl -n rabbit2 join_cluster rabbit1@'super' ###''内是主机名换成自己的Clustering node rabbit2@super with rabbit1@super ...[root@super ~]# rabbitmqctl -n rabbit2 start_appStarting node rabbit2@super ... 查看集群状态： 1234567[root@super ~]# rabbitmqctl cluster_status -n rabbit1Cluster status of node rabbit1@super ...[{nodes,[{disc,[rabbit1@super,rabbit2@super]}]}, {running_nodes,[rabbit2@super,rabbit1@super]}, {cluster_name,&lt;&lt;&quot;rabbit1@super&quot;&gt;&gt;}, {partitions,[]}, {alarms,[{rabbit2@super,[]},{rabbit1@super,[]}]}] web监控： 3.3 集群管理 rabbitmqctl join_cluster {cluster_node} [–ram] 将节点加入指定集群中。在这个命令执行前需要停止RabbitMQ应用并重置节点。 rabbitmqctl cluster_status 显示集群的状态。 rabbitmqctl change_cluster_node_type {disc|ram} 修改集群节点的类型。在这个命令执行前需要停止RabbitMQ应用。 rabbitmqctl forget_cluster_node [–offline] 将节点从集群中删除，允许离线执行。 rabbitmqctl update_cluster_nodes {clusternode} 在集群中的节点应用启动前咨询clusternode节点的最新信息，并更新相应的集群信息。这个和join_cluster不同，它不加入集群。考虑这样一种情况，节点A和节点B都在集群中，当节点A离线了，节点C又和节点B组成了一个集群，然后节点B又离开了集群，当A醒来的时候，它会尝试联系节点B，但是这样会失败，因为节点B已经不在集群中了。 rabbitmqctl cancel_sync_queue [-p vhost] {queue} 取消队列queue同步镜像的操作。 rabbitmqctl set_cluster_name {name} 设置集群名称。集群名称在客户端连接时会通报给客户端。Federation和Shovel插件也会有用到集群名称的地方。集群名称默认是集群中第一个节点的名称，通过这个命令可以重新设置。 3.4 RabbitMQ镜像集群配置 上面已经完成RabbitMQ默认集群模式，但并不保证队列的高可用性，尽管交换机、绑定这些可以复制到集群里的任何一个节点，但是队列内容不会复制。虽然该模式解决一项目组节点压力，但队列节点宕机直接导致该队列无法应用，只能等待重启，所以要想在队列节点宕机或故障也能正常应用，就要复制队列内容到集群里的每个节点，必须要创建镜像队列。 镜像队列是基于普通的集群模式的，然后再添加一些策略，所以你还是得先配置普通集群，然后才能设置镜像队列，我们就以上面的集群接着做。 设置的镜像队列可以通过开启的网页的管理端Admin-&gt;Policies，也可以通过命令。 rabbitmqctl set_policy my_ha &quot;^&quot; '{&quot;ha-mode&quot;:&quot;all&quot;}' Name:策略名称 Pattern：匹配的规则，如果是匹配所有的队列，是^. Definition:使用ha-mode模式中的all，也就是同步所有匹配的队列。问号链接帮助文档。 3.5 负载均衡-HAProxy HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案,包括Twitter，Reddit，StackOverflow，GitHub在内的多家知名互联网公司在使用。HAProxy实现了一种事件驱动、单一进程模型，此模型支持非常大的并发连接数。 3.5.1 安装HAProxy 12345678910111213141516//下载依赖包yum install gcc vim wget//上传haproxy源码包//解压tar -zxvf haproxy-1.6.5.tar.gz -C /usr/local//进入目录、进行编译、安装cd /usr/local/haproxy-1.6.5make TARGET=linux31 PREFIX=/usr/local/haproxymake install PREFIX=/usr/local/haproxymkdir /etc/haproxy//赋权groupadd -r -g 149 haproxyuseradd -g haproxy -r -s /sbin/nologin -u 149 haproxy//创建haproxy配置文件mkdir /etc/haproxyvim /etc/haproxy/haproxy.cfg 3.5.2 配置HAProxy 配置文件路径：/etc/haproxy/haproxy.cfg 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#logging optionsglobal log 127.0.0.1 local0 info maxconn 5120 chroot /usr/local/haproxy uid 99 gid 99 daemon quiet nbproc 20 pidfile /var/run/haproxy.piddefaults log global mode tcp option tcplog option dontlognull retries 3 option redispatch maxconn 2000 contimeout 5s clitimeout 60s srvtimeout 15s #front-end IP for consumers and producterslisten rabbitmq_cluster bind 0.0.0.0:5672 mode tcp #balance url_param userid #balance url_param session_id check_post 64 #balance hdr(User-Agent) #balance hdr(host) #balance hdr(Host) use_domain_only #balance rdp-cookie #balance leastconn #balance source //ip balance roundrobin server node1 127.0.0.1:5673 check inter 5000 rise 2 fall 2 server node2 127.0.0.1:5674 check inter 5000 rise 2 fall 2listen stats bind 172.16.98.133:8100 mode http option httplog stats enable stats uri /rabbitmq-stats stats refresh 5s 启动HAproxy负载 123456/usr/local/haproxy/sbin/haproxy -f /etc/haproxy/haproxy.cfg//查看haproxy进程状态ps -ef | grep haproxy访问如下地址对mq节点进行监控http://172.16.98.133:8100/rabbitmq-stats 代码中访问mq集群地址，则变为访问haproxy地址:5672 参考文献：黑马视频相关笔记","link":"/2021/03/24/Draft/2021/RabbitMQ/"},{"title":"魑魅先生 | 服务器","text":"Linux常用知识、服务器选择、搭建个人网盘、JAVA开发相关软件配置、博客搭建、域名配置、相关软件推荐。 Linux 常用命令 基本 1234567891011121314关机 shutdown -h now 立刻关机 shutdown -h 5 5分钟后关机 poweroff 立刻关机重启 shutdown -r now 立刻重启 shutdown -r 5 5分钟后重启 reboot 立刻重启--help命令 shutdown --help： ifconfig --help：查看网卡信息man命令（命令说明书） man shutdown 注意：man shutdown打开命令说明书之后，使用按键q退出 文件 新建 touch 文件名 删除 rm -rf 文件名 修改 打开：vi/vim 文件名 i:在光标所在字符前开始插入 a:在光标所在字符后开始插入 o:在光标所在行的下面另起一新行插入 保存文件： 第一步：ESC 进入命令行模式 第二步：: 进入底行模式 第三步：wq 保存并退出编辑 取消编辑： 第一步：ESC 进入命令行模式 第二步：: 进入底行模式 第三步：q! 撤销本次修改并退出编辑 1) 命令行模式command mode） 控制屏幕光标的移动，字符、字或行的删除，查找，移动复制某区段及进入Insert mode下，或者到 last line mode。 命令行模式下的常用命令： 【1】控制光标移动：↑，↓，j 【2】删除当前行：dd 【3】查找：/字符 【4】进入编辑模式：i o a 【5】进入底行模式：: 2) 编辑模式（Insert mode） 只有在Insert mode下，才可以做文字输入，按「ESC」键可回到命令行模式。 编辑模式下常用命令： 【1】ESC 退出编辑模式到命令行模式； 3) 底行模式（last line mode） 将文件保存或退出vi，也可以设置编辑环境，如寻找字符串、列出行号……等。 底行模式下常用命令： 【1】退出编辑： :q 【2】强制退出： :q! 【3】保存并退出： :wq 查看 cat：看最后一屏 示例：使用cat查看/etc/sudo.conf文件，只能显示最后一屏内容 cat sudo.conf more：百分比显示 示例：使用more查看/etc/sudo.conf文件，可以显示百分比，回车可以向下一行，空格可以向下一页，q可以退出查看 more sudo.conf less：翻页查看 示例：使用less查看/etc/sudo.conf文件，可以使用键盘上的PgUp和PgDn向上 和向下翻页，q结束查看 less sudo.conf tail：指定行数或者动态查看 示例：使用tail -10 查看/etc/sudo.conf文件的后10行，Ctrl+C结束 tail -10 sudo.conf 权限 目录 压缩 查找 权限 更改文件属性 进程 系统 网络 部署 Linux简介 Linux，全称GNU/Linux，是一种免费使用和自由传播的类UNIX操作系统 应用 Linux工具 SecureCRT 7.3 rz上传文件到当前目录 sz 文件名下载 yum -y install bash-completion自动补全 tab 启动过程 内核的引导。 电源 BIOS开机自检，按照BIOS中设置的启动设备（通常是硬盘）来启动 操作系统接管硬件以后，首先读入 /boot 目录下的内核文件。 运行 init。 init程序的类型 SysV: init, CentOS 5之前, 配置文件： /etc/inittab。 Upstart: init,CentOS 6, 配置文件： /etc/inittab, /etc/init/*.conf。 Systemd： systemd, CentOS 7,配置文件： /usr/lib/systemd/system、 /etc/systemd/system。 init 进程是系统所有进程的起点，你可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。 init 程序首先是需要读取配置文件 /etc/inittab。 运行级别 程序需要开机启动。它们在Windows叫做&quot;服务&quot;（service），在Linux就叫做&quot;守护进程&quot;（daemon）。 init进程的一大任务，就是去运行这些开机启动的程序。 但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动Apache，用作桌面就不需要。 Linux允许为不同的场合，分配不同的开机启动程序，这就叫做&quot;运行级别&quot;（runlevel）。也就是说，启动时根据&quot;运行级别&quot;，确定要运行哪些程序。 - 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登陆后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 系统初始化。 si::sysinit:/etc/rc.d/rc.sysinit 它调用执行了/etc/rc.d/rc.sysinit，而rc.sysinit是一个bash shell的脚本，它主要是完成一些系统初始化的工作，rc.sysinit是每一个运行级别都要首先运行的重要脚本。 它主要完成的工作有：激活交换分区，检查磁盘，加载硬件模块以及其它一些需要优先执行任务。 l5:5:wait:/etc/rc.d/rc 5 这一行表示以5为参数运行/etc/rc.d/rc，/etc/rc.d/rc是一个Shell脚本，它接受5作为参数，去执行/etc/rc.d/rc5.d/目录下的所有的rc启动脚本，/etc/rc.d/rc5.d/目录中的这些启动脚本实际上都是一些连接文件，而不是真正的rc启动脚本，真正的rc启动脚本实际上都是放在/etc/rc.d/init.d/目录下。 而这些rc启动脚本有着类似的用法，它们一般能接受start、stop、restart、status等参数。 /etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件，对于以 S 开头的启动脚本，将以start参数来运行。 而如果发现存在相应的脚本也存在K打头的连接，而且已经处于运行态了(以/var/lock/subsys/下的文件作为标志)，则将首先以stop为参数停止这些已经启动了的守护进程，然后再重新运行。 这样做是为了保证是当init改变运行级别时，所有相关的守护进程都将重启。 至于在每个运行级中将运行哪些守护进程，用户可以通过chkconfig或setup中的&quot;System Services&quot;来自行设定。 建立终端 。 rc执行完毕后，返回init。这时基本系统环境已经设置好了，各种守护进程也已经启动了。 init接下来会打开6个终端，以便用户登录系统。在inittab中的以下6行就是定义了6个终端： 1:2345:respawn:/sbin/mingetty tty1 2:2345:respawn:/sbin/mingetty tty2 3:2345:respawn:/sbin/mingetty tty3 4:2345:respawn:/sbin/mingetty tty4 5:2345:respawn:/sbin/mingetty tty5 6:2345:respawn:/sbin/mingetty tty6 从上面可以看出在2、3、4、5的运行级别中都将以respawn方式运行mingetty程序，mingetty程序能打开终端、设置模式。 同时它会显示一个文本登录界面，这个界面就是我们经常看到的登录界面，在这个登录界面中会提示用户输入用户名，而用户输入的用户将作为参数传给login程序来验证用户的身份。 用户登录系统。 一般来说，用户的登录方式有三种： （1）命令行登录 （2）ssh登录 （3）图形界面登录 对于运行级别为5的图形方式用户来说，他们的登录是通过一个图形化的登录界面。登录成功后可以直接进入 KDE、Gnome 等窗口管理器。 而本文主要讲的还是文本方式登录的情况：当我们看到mingetty的登录界面时，我们就可以输入用户名和密码来登录系统了。 Linux 的账号验证程序是 login，login 会接收 mingetty 传来的用户名作为用户名参数。 然后 login 会对用户名进行分析：如果用户名不是 root，且存在 /etc/nologin 文件，login 将输出 nologin 文件的内容，然后退出。 这通常用来系统维护时防止非root用户登录。只有/etc/securetty中登记了的终端才允许 root 用户登录，如果不存在这个文件，则 root 用户可以在任何终端上登录。 /etc/usertty文件用于对用户作出附加访问限制，如果不存在这个文件，则没有其他限制。 图形模式与文字模式的切换方式 Linux预设提供了六个命令窗口终端机让我们来登录。 默认我们登录的就是第一个窗口，也就是tty1，这个六个窗口分别为tty1,tty2 … tty6，你可以按下Ctrl + Alt + F1 ~ F6 来切换它们。 如果你安装了图形界面，默认情况下是进入图形界面的，此时你就可以按Ctrl + Alt + F1 ~ F6来进入其中一个命令窗口界面。 当你进入命令窗口界面后再返回图形界面只要按下Ctrl + Alt + F7 就回来了。 如果你用的vmware 虚拟机，命令窗口切换的快捷键为 Alt + Space + F1~F6. 如果你在图形界面下请按Alt + Shift + Ctrl + F1~F6 切换至命令窗口。 Linux 关机 在linux领域内大多用在服务器上，很少遇到关机的操作。毕竟服务器上跑一个服务是永无止境的，除非特殊情况下，不得已才会关机。 正确的关机流程为：sync &gt; shutdown &gt; reboot &gt; halt 关机指令为：shutdown ，你可以man shutdown 来看一下帮助文档。 例如你可以运行如下命令关机： sync 将数据由内存同步到硬盘中。 shutdown 关机指令，你可以man shutdown 来看一下帮助文档。例如你可以运行如下命令关机： shutdown –h 10 ‘This server will shutdown after 10 mins’ 这个命令告诉大家，计算机将在10分钟后关机，并且会显示在登陆用户的当前屏幕中。 shutdown –h now 立马关机 shutdown –h 20:25 系统会在今天20:25关机 shutdown –h +10 十分钟后关机 shutdown –r now 系统立马重启 shutdown –r +10 系统十分钟后重启 reboot 就是重启，等同于 shutdown –r now halt 关闭系统，等同于shutdown –h now 和 poweroff 最后总结一下，不管是重启系统还是关闭系统，首先要运行 sync 命令，把内存中的数据写到磁盘中。 关机的命令有 shutdown –h now halt poweroff 和 init 0 , 重启系统的命令有 shutdown –r now reboot init 6。 注意事项 严格区分大小写 所有内容以文件形式保存，包括硬件 硬件/dev/sd[a-p] 光盘文件/dec/sr0等 不靠扩展名区分文件类型 有扩展都是给管理员看的 所有存储设备都需要挂载之后才能使用 windows程序不能直接在linux安装运行 服务器不允许关机，只能重启 重启时应该关闭服务 服务器访问高峰不要使用高负载命令 远程配置防火墙时不要把自己踢出服务器 指定合理密码规范并定期更新 合理分配权限 定期备份重要数据和日志 系统目录结构 ls / 查看目录 /bin： bin 是 Binaries (二进制文件) 的缩写, 这个目录存放着最经常使用的命令。 /boot： 这里存放的是启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev ： dev 是 Device(设备) 的缩写, 该目录下存放的是 Linux 的外部设备，在 Linux 中访问设备的方式和访问文件的方式是相同的。 /etc： etc 是 Etcetera(等等) 的缩写,这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home： 用户的主目录，在 Linux 中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的，如上图中的 alice、bob 和 eve。 /lib： lib 是 Library(库) 的缩写这个目录里存放着系统最基本的动态连接共享库，其作用类似于 Windows 里的 DLL 文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found： 这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media： linux 系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux 会把识别的设备挂载到这个目录下。 /mnt： 系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在 /mnt/ 上，然后进入该目录就可以查看光驱里的内容了。 /opt： opt 是 optional(可选) 的缩写，这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc： proc 是 Processes(进程) 的缩写，/proc 是一种伪文件系统（也即虚拟文件系统），存储的是当前内核运行状态的一系列特殊文件，这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。 这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器： echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all /root： 该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin： s 就是 Super User 的意思，是 Superuser Binaries (超级用户的二进制文件) 的缩写，这里存放的是系统管理员使用的系统管理程序。 /selinux： 这个目录是 Redhat/CentOS 所特有的目录，Selinux 是一个安全机制，类似于 windows 的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。 /srv： 该目录存放一些服务启动之后需要提取的数据。 /sys： 这是 Linux2.6 内核的一个很大的变化。该目录下安装了 2.6 内核中新出现的一个文件系统 sysfs 。 sysfs 文件系统集成了下面3种文件系统的信息：针对进程信息的 proc 文件系统、针对设备的 devfs 文件系统以及针对伪终端的 devpts 文件系统。 该文件系统是内核设备树的一个直观反映。 当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。 /tmp： tmp 是 temporary(临时) 的缩写这个目录是用来存放一些临时文件的。 /usr： usr 是 unix shared resources(共享资源) 的缩写，这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于 windows 下的 program files 目录。 /usr/bin： 系统用户使用的应用程序。 /usr/sbin： 超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src： 内核源代码默认的放置目录。 /var： var 是 variable(变量) 的缩写，这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 /run： 是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。 在 Linux 系统中，有几个目录是比较重要的，平时需要注意不要误删除或者随意更改内部文件。 /etc： 上边也提到了，这个是系统中的配置文件，如果你更改了该目录下的某个文件可能会导致系统不能启动。 /bin, /sbin, /usr/bin, /usr/sbin: 这是系统预设的执行文件的放置目录，比如 ls 就是在 /bin/ls 目录下的。 值得提出的是，/bin, /usr/bin 是给系统用户使用的指令（除root外的通用户），而/sbin, /usr/sbin 则是给 root 使用的指令。 /var： 这是一个非常重要的目录，系统上跑了很多程序，那么每个程序都会有相应的日志产生，而这些日志就被记录到这个目录下，具体在 /var/log 目录下，另外 mail 的预设放置也是在这里。 忘记密码解决方法https://www.runoob.com/linux/linux-forget-password.html 重启linux系统 3 秒之内要按一下回车 输入e 第二行最后边输入 single，有一个空格。具体方法为按向下尖头移动到第二行，按&quot;e&quot;进入编辑模式 在后边加上single 回车 最后按&quot;b&quot;启动，启动后就进入了单用户模式了 更改root密码了。更密码的命令为 passwd 光盘启动，按F5 进入rescue模式 输入linux rescue 回车 选择英语 选择us 键盘 问你是否启动网络，有时候可能会联网调试。我们选no 这里告诉我们，接下来会把系统挂载在/mnt/sysimage 中。 其中有三个选项: Continue 就是挂载后继续下一步。 Read-Only 挂载成只读，这样更安全，有时文件系统损坏时，只读模式会防止文件系统近一步损坏。 Skip就是不挂载，进入一个命令窗口模式。 这里我们选择Continue。 - 至此，系统已经挂载到了/mnt/sysimage中。接下来回车，输入chroot /mnt/sysimage 进入管理员环境。 远程登录 Linux 一般作为服务器使用，而服务器一般放在机房，你不可能在机房操作你的 Linux 服务器。这时我们就需要远程登录到Linux服务器来管理维护系统。 Linux 系统中是通过 ssh 服务实现的远程登录功能，默认 ssh 服务端口号为 22。 Window 系统上 Linux 远程登录客户端有 SecureCRT, Putty, SSH Secure Shell 等，本文以 Putty 为例来登录远程服务器。 Putty 下载地址：https://www.putty.org/ 在Host Name( or IP address) 下面的框中输入你要登录的远程服务器IP(可以通过ifconfig命令查看服务器ip)，然后回车。 输入要登录的用户名。 再输入密码，就能登录到远程的linux系统了 使用密钥认证机制远程登录linux SSH 为 Secure Shell 的缩写，由 IETF 的网络工作小组（Network Working Group）所制定。 SSH 为建立在应用层和传输层基础上的安全协议。 首先使用工具 PUTTYGEN.EXE 生成密钥对。打开工具 PUTTYGEN.EXE 后如下图所示： 该工具可以生成三种格式的key ：SSH-1(RSA) SSH-2(RSA) SSH-2(DSA) ，我们采用默认的格式即 SSH-2(RSA)。Number of bits in a generated key 这个是指生成的key的大小，这个数值越大，生成的key就越复杂，安全性就越高。这里我们写 2048。 Generate 过程中鼠标要来回的动，否则这个进度条是不会动的。 可以给你的密钥输入一个密码，（在Key Passphrase那里）也可以留空。然后点 Save public key 保存公钥，点 Save private Key 保存私钥。笔者建议你放到一个比较安全的地方，一来防止别人偷窥，二来防止误删除。接下来就该到远程 linux 主机上设置了。 1）创建目录 /root/.ssh 并设置权限 [root@localhost ~]# mkdir /root/.ssh mkdir 命令用来创建目录，以后会详细介绍，暂时只了解即可。 [root@localhost ~]# chmod 700 /root/.ssh chmod 命令是用来修改文件属性权限的，以后会详细介绍。 2）创建文件 / root/.ssh/authorized_keys [root@localhost ~]# vim /root/.ssh/authorized_keys vim 命令是编辑一个文本文件的命令，同样在后续章节详细介绍。 3）打开刚才生成的public key 文件，建议使用写字板打开，这样看着舒服一些，复制从AAAA开头至 &quot;---- END SSH2 PUBLIC KEY ----&quot; 该行上的所有内容，粘贴到/root/.ssh/authorized_keys 文件中，要保证所有字符在一行。（可以先把复制的内容拷贝至记事本，然后编辑成一行载粘贴到该文件中）。 在这里要简单介绍一下，如何粘贴，用vim打开那个文件后，该文件不存在，所以vim会自动创建。按一下字母&quot;i&quot;然后同时按shift + Insert 进行粘贴（或者单击鼠标右键即可），前提是已经复制到剪切板中了。粘贴好后，然后把光标移动到该行最前面输入 ssh-rsa ，然后按空格。再按ESC，然后输入冒号wq 即 :wq 就保存了。格式如下图： - 再设置putty选项，点窗口左侧的SSh –&gt; Auth ，单击窗口右侧的Browse… 选择刚刚生成的私钥， 再点Open ，此时输入root，就不用输入密码就能登录了。如果在前面你设置了Key Passphrase ，那么此时就会提示你输入密码的。为了更加安全建议大家要设置一个Key Passphrase。 文件基本属性 Linux 系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限。 为了保护系统的安全性，Linux 系统对不同的用户访问同一文件（包括目录文件）的权限做了不同的规定。 在 Linux 中我们通常使用以下两个命令来修改文件或目录的所属用户与权限： chown (change ownerp) ： 修改所属用户与组。 chmod (change mode) ： 修改用户的权限。 使用 ll 或者 ls –l 命令来显示一个文件的属性以及文件所属的用户和组，如： [root@www /]# ls -l total 64 dr-xr-xr-x 2 root root 4096 Dec 14 2012 bin dr-xr-xr-x 4 root root 4096 Apr 19 2012 boot …… - 实例中，bin 文件的第一个属性用 d 表示。d 在 Linux 中代表该文件是一个目录文件。 在 Linux 中第一个字符代表这个文件是目录、文件或链接文件等等。 当为 d 则是目录 当为 - 则是文件； 若是 l 则表示为链接文档(link file)； 若是 b 则表示为装置文件里面的可供储存的接口设备(可随机存取装置)； 若是 c 则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。 - 接下来的字符中，以三个为一组，且均为 rwx 的三个参数的组合。其中， r 代表可读(read)、 w 代表可写(write)、 x 代表可执行(execute)。 要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号 - 而已。 - 每个文件的属性由左边第一部分的 10 个字符来确定（如图）。 363003_1227493859FdXT 从左至右用 0-9 这些数字来表示。 第 0 位确定文件类型，第 1-3 位确定属主（该文件的所有者）拥有该文件的权限。 第4-6位确定属组（所有者的同组用户）拥有该文件的权限，第7-9位确定其他用户拥有该文件的权限。 其中，第 1、4、7 位表示读权限，如果用 r 字符表示，则有读权限，如果用 - 字符表示，则没有读权限； 第 2、5、8 位表示写权限，如果用 w 字符表示，则有写权限，如果用 - 字符表示没有写权限；第 3、6、9 位表示可执行权限，如果用 x 字符表示，则有执行权限，如果用 - 字符表示，则没有执行权限。 Linux文件属主和属组 [root@www /]# ls -l total 64 drwxr-xr-x 2 root root 4096 Feb 15 14:46 cron drwxr-xr-x 3 mysql mysql 4096 Apr 21 2014 mysql …… 对于文件来说，它都有一个特定的所有者，也就是对该文件具有所有权的用户。 同时，在Linux系统中，用户是按组分类的，一个用户属于一个或多个组。 文件所有者以外的用户又可以分为文件所有者的同组用户和其他用户。 因此，Linux系统按文件所有者、文件所有者同组用户和其他用户来规定了不同的文件访问权限。 在以上实例中，mysql 文件是一个目录文件，属主和属组都为 mysql，属主有可读、可写、可执行的权限；与属主同组的其他用户有可读和可执行的权限；其他用户也有可读和可执行的权限。 对于 root 用户来说，一般情况下，文件的权限对其不起作用。 更改文件属性 chgrp：更改文件属组 语法：chgrp [-R] 属组名 文件名 参数选项 -R：递归更改文件属组，就是在更改某个目录文件的属组时，如果加上-R的参数，那么该目录下的所有文件的属组都会更改。 chown：更改文件属主，也可以同时更改文件属组 语法： chown [–R] 属主名 文件名 chown [-R] 属主名：属组名 文件名 进入 /root 目录（~）将install.log的拥有者改为bin这个账号： [root@www ~] cd ~ [root@www ~]# chown bin install.log [root@www ~]# ls -l -rw-r--r-- 1 bin users 68495 Jun 25 08:53 install.log 将install.log的拥有者与群组改回为root： [root@www ~]# chown root:root install.log [root@www ~]# ls -l -rw-r--r-- 1 root root 68495 Jun 25 08:53 install.log chmod：更改文件9个属性 Linux文件属性有两种设置方法，一种是数字，一种是符号。 Linux 文件的基本权限就有九个，分别是 owner/group/others(拥有者/组/其他) 三种身份各有自己的 read/write/execute 权限。 先复习一下刚刚上面提到的数据：文件的权限字符为： -rwxrwxrwx ， 这九个权限是三个三个一组的！其中，我们可以使用数字来代表各个权限，各权限的分数对照表如下： r:4 w:2 x:1 每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，例如当权限为： -rwxrwx--- 分数则是： owner = rwx = 4+2+1 = 7 group = rwx = 4+2+1 = 7 others= --- = 0+0+0 = 0 所以等一下我们设定权限的变更时，该文件的权限数字就是 770。变更权限的指令 chmod 的语法是这样的： chmod [-R] xyz 文件或目录 选项与参数： xyz : 就是刚刚提到的数字类型的权限属性，为 rwx 属性数值的相加。 -R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有文件都会变更 举例来说，如果要将 .bashrc 这个文件所有的权限都设定启用，那么命令如下： [root@www ~]# ls -al .bashrc -rw-r--r-- 1 root root 395 Jul 4 11:45 .bashrc [root@www ~]# chmod 777 .bashrc [root@www ~]# ls -al .bashrc -rwxrwxrwx 1 root root 395 Jul 4 11:45 .bashrc 那如果要将权限变成 -rwxr-xr-- 呢？那么权限的分数就成为 [4+2+1][4+0+1][4+0+0]=754。 符号类型改变文件权限 还有一个改变权限的方法，从之前的介绍中我们可以发现，基本上就九个权限分别是： user：用户 group：组 others：其他 那么我们就可以使用 u, g, o 来代表三种身份的权限。 此外， a 则代表 all，即全部的身份。读写的权限可以写成 r, w, x，也就是可以使用下表的方式来看： chmod u g o a +(加入) -(除去) =(设定) r w x 文件或目录 如果我们需要将文件权限设置为 -rwxr-xr-- ，可以使用 chmod u=rwx,g=rx,o=r 文件名 来设定: touch test1 // 创建 test1 文件 ls -al test1 // 查看 test1 默认权限 -rw-r--r-- 1 root root 0 Nov 15 10:32 test1 chmod u=rwx,g=rx,o=r test1 // 修改 test1 权限 ls -al test1 -rwxr-xr-- 1 root root 0 Nov 15 10:32 test1 而如果是要将权限去掉而不改变其他已存在的权限呢？例如要拿掉全部人的可执行权限，则： chmod a-x test1 ls -al test1 -rw-r--r-- 1 root root 0 Nov 15 10:32 test1 文件与目录管理 Linux的目录结构为树状结构，最顶级的目录为根目录 /。 其他目录通过挂载可以将它们添加到树中，通过解除挂载可以移除它们。 在开始本教程前我们需要先知道什么是绝对路径与相对路径。 绝对路径： 路径的写法，由根目录 / 写起，例如： /usr/share/doc 这个目录。 相对路径： 路径的写法，不是由 / 写起，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写成： cd ../man 这就是相对路径的写法。 处理目录的常用命令 ls（英文全拼：list files）: 列出目录及文件名 cd（英文全拼：change directory）：切换目录 pwd（英文全拼：print work directory）：显示目前的目录 mkdir（英文全拼：make directory）：创建一个新的目录 rmdir（英文全拼：remove directory）：删除一个空的目录 cp（英文全拼：copy file）: 复制文件或目录 rm（英文全拼：remove）: 移除文件或目录 mv（英文全拼：move file）: 移动文件与目录，或修改文件与目录的名称 你可以使用 man [命令] 来查看各个命令的使用文档，如 ：man cp。 ls (列出目录) 在Linux系统当中， ls 命令可能是最常被运行的。 语法： [root@www ~]# ls [-aAdfFhilnrRSt] 目录名称 [root@www ~]# ls [--color={never,auto,always}] 目录名称 [root@www ~]# ls [--full-time] 目录名称 选项与参数： -a ：全部的文件，连同隐藏文件( 开头为 . 的文件) 一起列出来(常用) -d ：仅列出目录本身，而不是列出目录内的文件数据(常用) -l ：长数据串列出，包含文件的属性与权限等等数据；(常用) 将家目录下的所有文件列出来(含属性与隐藏档) [root@www ~]# ls -al ~ cd (切换目录) cd是Change Directory的缩写，这是用来变换工作目录的命令。 语法： cd [相对路径或绝对路径] #使用 mkdir 命令创建 runoob 目录 [root@www ~]# mkdir runoob #使用绝对路径切换到 runoob 目录 [root@www ~]# cd /root/runoob/ #使用相对路径切换到 runoob 目录 [root@www ~]# cd ./runoob/ 表示回到自己的家目录，亦即是 /root 这个目录 [root@www runoob]# cd ~ 表示去到目前的上一级目录，亦即是 /root 的上一级目录的意思； [root@www ~]# cd .. 接下来大家多操作几次应该就可以很好的理解 cd 命令的。 - pwd (显示目前所在的目录) pwd 是 Print Working Directory 的缩写，也就是显示目前所在目录的命令。 [root@www ~]# pwd [-P] 选项与参数： -P ：显示出确实的路径，而非使用连结 (link) 路径。 实例：单纯显示出目前的工作目录： [root@www ~]# pwd /root &lt;== 显示出目录啦～ 实例显示出实际的工作目录，而非连结档本身的目录名而已。 [root@www ~]# cd /var/mail &lt;==注意，/var/mail是一个连结档 [root@www mail]# pwd /var/mail &lt;==列出目前的工作目录 [root@www mail]# pwd -P /var/spool/mail &lt;==怎么回事？有没有加 -P 差很多～ [root@www mail]# ls -ld /var/mail lrwxrwxrwx 1 root root 10 Sep 4 17:54 /var/mail -&gt; spool/mail 看到这里应该知道为啥了吧？因为 /var/mail 是连结档，连结到 /var/spool/mail 所以，加上 pwd -P 的选项后，会不以连结档的数据显示，而是显示正确的完整路径啊！ - mkdir (创建新目录) 如果想要创建新的目录的话，那么就使用mkdir (make directory)吧。 语法： mkdir [-mp] 目录名称 选项与参数： -m ：配置文件的权限喔！直接配置，不需要看默认权限 (umask) 的脸色～ -p ：帮助你直接将所需要的目录(包含上一级目录)递归创建起来！ 实例：请到/tmp底下尝试创建数个新目录看看： [root@www ~]# cd /tmp [root@www tmp]# mkdir test &lt;创建一名为 test 的新目录 [root@www tmp]# mkdir test1/test2/test3/test4 mkdir: cannot create directory `test1/test2/test3/test4': No such file or directory &lt; 没办法直接创建此目录啊！ [root@www tmp]# mkdir -p test1/test2/test3/test4 加了这个 -p 的选项，可以自行帮你创建多层目录！ 实例：创建权限为 rwx--x--x 的目录。 [root@www tmp]# mkdir -m 711 test2 [root@www tmp]# ls -l drwxr-xr-x 3 root root 4096 Jul 18 12:50 test drwxr-xr-x 3 root root 4096 Jul 18 12:53 test1 drwx--x--x 2 root root 4096 Jul 18 12:54 test2 上面的权限部分，如果没有加上 -m 来强制配置属性，系统会使用默认属性。 如果我们使用 -m ，如上例我们给予 -m 711 来给予新的目录 drwx--x--x 的权限。 - rmdir (删除空的目录) 语法： rmdir [-p] 目录名称 选项与参数： -p ：连同上一级『空的』目录也一起删除 删除 runoob 目录 [root@www tmp]# rmdir runoob/ 将 mkdir 实例中创建的目录(/tmp 底下)删除掉！ [root@www tmp]# ls -l &lt;==看看有多少目录存在？ drwxr-xr-x 3 root root 4096 Jul 18 12:50 test drwxr-xr-x 3 root root 4096 Jul 18 12:53 test1 drwx--x--x 2 root root 4096 Jul 18 12:54 test2 [root@www tmp]# rmdir test &lt;==可直接删除掉，没问题 [root@www tmp]# rmdir test1 &lt;==因为尚有内容，所以无法删除！ rmdir: `test1': Directory not empty [root@www tmp]# rmdir -p test1/test2/test3/test4 [root@www tmp]# ls -l &lt;==您看看，底下的输出中test与test1不见了！ drwx--x--x 2 root root 4096 Jul 18 12:54 test2 利用 -p 这个选项，立刻就可以将 test1/test2/test3/test4 一次删除。 不过要注意的是，这个 rmdir 仅能删除空的目录，你可以使用 rm 命令来删除非空目录。 - cp (复制文件或目录) cp 即拷贝文件和目录。 语法: [root@www ~]# cp [-adfilprsu] 来源档(source) 目标档(destination) [root@www ~]# cp [options] source1 source2 source3 .... directory 选项与参数： -a：相当於 -pdr 的意思，至於 pdr 请参考下列说明；(常用) -d：若来源档为连结档的属性(link file)，则复制连结档属性而非文件本身； -f：为强制(force)的意思，若目标文件已经存在且无法开启，则移除后再尝试一次； -i：若目标档(destination)已经存在时，在覆盖时会先询问动作的进行(常用) -l：进行硬式连结(hard link)的连结档创建，而非复制文件本身； -p：连同文件的属性一起复制过去，而非使用默认属性(备份常用)； -r：递归持续复制，用於目录的复制行为；(常用) -s：复制成为符号连结档 (symbolic link)，亦即『捷径』文件； -u：若 destination 比 source 旧才升级 destination ！ 用 root 身份，将 root 目录下的 .bashrc 复制到 /tmp 下，并命名为 bashrc [root@www ~]# cp ~/.bashrc /tmp/bashrc [root@www ~]# cp -i ~/.bashrc /tmp/bashrc cp: overwrite `/tmp/bashrc'? n &lt;==n不覆盖，y为覆盖 - rm (移除文件或目录) 语法： rm [-fir] 文件或目录 选项与参数： -f ：就是 force 的意思，忽略不存在的文件，不会出现警告信息； -i ：互动模式，在删除前会询问使用者是否动作 -r ：递归删除啊！最常用在目录的删除了！这是非常危险的选项！！！ 将刚刚在 cp 的实例中创建的 bashrc 删除掉！ [root@www tmp]# rm -i bashrc rm: remove regular file `bashrc'? y 如果加上 -i 的选项就会主动询问喔，避免你删除到错误的档名！ - mv (移动文件与目录，或修改名称) 语法： [root@www ~]# mv [-fiu] source destination [root@www ~]# mv [options] source1 source2 source3 .... directory 选项与参数： -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖； -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u ：若目标文件已经存在，且 source 比较新，才会升级 (update) 复制一文件，创建一目录，将文件移动到目录中 [root@www ~]# cd /tmp [root@www tmp]# cp ~/.bashrc bashrc [root@www tmp]# mkdir mvtest [root@www tmp]# mv bashrc mvtest 将某个文件移动到某个目录去，就是这样做！ 将刚刚的目录名称更名为 mvtest2 [root@www tmp]# mv mvtest mvtest2 - Linux 文件内容查看 Linux系统中使用以下命令来查看文件的内容： cat 由第一行开始显示文件内容 tac 从最后一行开始显示，可以看出 tac 是 cat 的倒着写！ nl 显示的时候，顺道输出行号！ more 一页一页的显示文件内容 less 与 more 类似，但是比 more 更好的是，他可以往前翻页！ head 只看头几行 tail 只看尾巴几行 你可以使用 man [命令]来查看各个命令的使用文档，如 ：man cp。 - cat 由第一行开始显示文件内容 语法： cat [-AbEnTv] 选项与参数： -A ：相当於 -vET 的整合选项，可列出一些特殊字符而不是空白而已； -b ：列出行号，仅针对非空白行做行号显示，空白行不标行号！ -E ：将结尾的断行字节 $ 显示出来； -n ：列印出行号，连同空白行也会有行号，与 -b 的选项不同； -T ：将 [tab] 按键以 ^I 显示出来； -v ：列出一些看不出来的特殊字符 检看 /etc/issue 这个文件的内容： [root@www ~]# cat /etc/issue CentOS release 6.4 (Final) Kernel \\r on an \\m - tac tac与cat命令刚好相反，文件内容从最后一行开始显示，可以看出 tac 是 cat 的倒着写！如： [root@www ~]# tac /etc/issue Kernel \\r on an \\m CentOS release 6.4 (Final) - nl 显示行号 语法： nl [-bnw] 文件 选项与参数： -b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)； -b t ：如果有空行，空的那一行不要列出行号(默认值)； -n ：列出行号表示的方法，主要有三种： -n ln ：行号在荧幕的最左方显示； -n rn ：行号在自己栏位的最右方显示，且不加 0 ； -n rz ：行号在自己栏位的最右方显示，且加 0 ； -w ：行号栏位的占用的位数。 实例一：用 nl 列出 /etc/issue 的内容 [root@www ~]# nl /etc/issue 1 CentOS release 6.4 (Final) 2 Kernel \\r on an \\m - more 一页一页翻动 [root@www ~]# more /etc/man_db.config Generated automatically from man.conf.in by the configure script. man.conf from man-1.6d ....(中间省略).... --More--(28%) &lt;== 重点在这一行喔！你的光标也会在这里等待你的命令 在 more 这个程序的运行过程中，你有几个按键可以按的： 空白键 (space)：代表向下翻一页； Enter ：代表向下翻『一行』； /字串 ：代表在这个显示的内容当中，向下搜寻『字串』这个关键字； :f ：立刻显示出档名以及目前显示的行数； q ：代表立刻离开 more ，不再显示该文件内容。 b 或 [ctrl]-b ：代表往回翻页，不过这动作只对文件有用，对管线无用。 - less 一页一页翻动，以下实例输出/etc/man.config文件的内容： [root@www ~]# less /etc/man.config Generated automatically from man.conf.in by the configure script. man.conf from man-1.6d ....(中间省略).... &lt;== 这里可以等待你输入命令！ less运行时可以输入的命令有： 空白键 ：向下翻动一页； [pagedown]：向下翻动一页； [pageup] ：向上翻动一页； /字串 ：向下搜寻『字串』的功能； ?字串 ：向上搜寻『字串』的功能； n ：重复前一个搜寻 (与 / 或 ? 有关！) N ：反向的重复前一个搜寻 (与 / 或 ? 有关！) q ：离开 less 这个程序； - head 取出文件前面几行 语法： head [-n number] 文件 选项与参数： -n ：后面接数字，代表显示几行的意思 [root@www ~]# head /etc/man.config 默认的情况中，显示前面 10 行！若要显示前 20 行，就得要这样： [root@www ~]# head -n 20 /etc/man.config - tail 取出文件后面几行 语法： tail [-n number] 文件 选项与参数： -n ：后面接数字，代表显示几行的意思 -f ：表示持续侦测后面所接的档名，要等到按下[ctrl]-c才会结束tail的侦测 [root@www ~]# tail /etc/man.config 默认的情况中，显示最后的十行！若要显示最后的 20 行，就得要这样： [root@www ~]# tail -n 20 /etc/man.config 用户和用户组管理 Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。 用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。 每个用户账号都拥有一个唯一的用户名和各自的口令。 用户在登录时键入正确的用户名和口令后，就能够进入系统和自己的主目录。 实现用户账号的管理，要完成的工作主要有如下几个方面： 用户账号的添加、删除与修改。 用户口令的管理。 用户组的管理。 一、Linux系统用户账号的管理 用户账号的管理工作主要涉及到用户账号的添加、修改和删除。 添加用户账号就是在系统中创建一个新账号，然后为新账号分配用户号、用户组、主目录和登录Shell等资源。刚添加的账号是被锁定的，无法使用。 1、添加新的用户账号使用useradd命令，其语法如下： useradd 选项 用户名 参数说明： 选项: -c comment 指定一段注释性描述。 -d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。 -g 用户组 指定用户所属的用户组。 -G 用户组，用户组 指定用户所属的附加组。 -s Shell文件 指定用户的登录Shell。 -u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。 用户名: 指定新账号的登录名。 实例1 useradd –d /home/sam -m sam 此命令创建了一个用户sam，其中-d和-m选项用来为登录名sam产生一个主目录 /home/sam（/home为默认的用户主目录所在的父目录）。 实例2 useradd -s /bin/sh -g group –G adm,root gem 此命令新建了一个用户gem，该用户的登录Shell是 /bin/sh，它属于group用户组，同时又属于adm和root用户组，其中group用户组是其主组。 这里可能新建组：#groupadd group及groupadd adm 增加用户账号就是在/etc/passwd文件中为新用户增加一条记录，同时更新其他系统文件如/etc/shadow, /etc/group等。 Linux提供了集成的系统管理工具userconf，它可以用来对用户账号进行统一管理。 2、删除帐号 如果一个用户的账号不再使用，可以从系统中删除。删除用户账号就是要将/etc/passwd等系统文件中的该用户记录删除，必要时还删除用户的主目录。 删除一个已有的用户账号使用userdel命令，其格式如下： userdel 选项 用户名 常用的选项是 -r，它的作用是把用户的主目录一起删除。 例如： userdel -r sam 此命令删除用户sam在系统文件中（主要是/etc/passwd, /etc/shadow, /etc/group等）的记录，同时删除用户的主目录。 3、修改帐号 修改用户账号就是根据实际情况更改用户的有关属性，如用户号、主目录、用户组、登录Shell等。 修改已有用户的信息使用usermod命令，其格式如下： usermod 选项 用户名 常用的选项包括-c, -d, -m, -g, -G, -s, -u以及-o等，这些选项的意义与useradd命令中的选项一样，可以为用户指定新的资源值。 另外，有些系统可以使用选项：-l 新用户名 这个选项指定一个新的账号，即将原来的用户名改为新的用户名。 例如： usermod -s /bin/ksh -d /home/z –g developer sam 此命令将用户sam的登录Shell修改为ksh，主目录改为/home/z，用户组改为developer。 4、用户口令的管理 用户管理的一项重要内容是用户口令的管理。用户账号刚创建时没有口令，但是被系统锁定，无法使用，必须为其指定口令后才可以使用，即使是指定空口令。 指定和修改用户口令的Shell命令是passwd。超级用户可以为自己和其他用户指定口令，普通用户只能用它修改自己的口令。命令的格式为： passwd 选项 用户名 可使用的选项： -l 锁定口令，即禁用账号。 -u 口令解锁。 -d 使账号无口令。 -f 强迫用户下次登录时修改口令。 如果默认用户名，则修改当前用户的口令。 例如，假设当前用户是sam，则下面的命令修改该用户自己的口令： $ passwd Old password:****** New password:******* Re-enter new password:******* 如果是超级用户，可以用下列形式指定任何用户的口令： passwd sam New password:******* Re-enter new password:******* 普通用户修改自己的口令时，passwd命令会先询问原口令，验证后再要求用户输入两遍新口令，如果两次输入的口令一致，则将这个口令指定给用户；而超级用户为用户指定口令时，就不需要知道原口令。 为了系统安全起见，用户应该选择比较复杂的口令，例如最好使用8位长的口令，口令中包含有大写、小写字母和数字，并且应该与姓名、生日等不相同。 为用户指定空口令时，执行下列形式的命令： passwd -d sam 此命令将用户 sam 的口令删除，这样用户 sam 下一次登录时，系统就不再允许该用户登录了。 passwd 命令还可以用 -l(lock) 选项锁定某一用户，使其不能登录，例如： passwd -l sam 二、Linux系统用户组的管理 每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同Linux 系统对用户组的规定有所不同，如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。 用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新。 1、增加一个新的用户组使用groupadd命令。其格式如下： groupadd 选项 用户组 可以使用的选项有： -g GID 指定新用户组的组标识号（GID）。 -o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同。 实例1： groupadd group1 此命令向系统中增加了一个新组group1，新组的组标识号是在当前已有的最大组标识号的基础上加1。 实例2： groupadd -g 101 group2 此命令向系统中增加了一个新组group2，同时指定新组的组标识号是101。 2、如果要删除一个已有的用户组，使用groupdel命令，其格式如下： groupdel 用户组 例如： groupdel group1 此命令从系统中删除组group1。 3、修改用户组的属性使用groupmod命令。其语法如下： groupmod 选项 用户组 常用的选项有： -g GID 为用户组指定新的组标识号。 -o 与-g选项同时使用，用户组的新GID可以与系统已有用户组的GID相同。 -n新用户组 将用户组的名字改为新名字 实例1： groupmod -g 102 group2 此命令将组group2的组标识号修改为102。 实例2： groupmod –g 10000 -n group3 group2 此命令将组group2的标识号改为10000，组名修改为group3。 4、如果一个用户同时属于多个用户组，那么用户可以在用户组之间切换，以便具有其他用户组的权限。 用户可以在登录后，使用命令newgrp切换到其他用户组，这个命令的参数就是目的用户组。例如： $ newgrp root 这条命令将当前用户切换到root用户组，前提条件是root用户组确实是该用户的主组或附加组。类似于用户账号的管理，用户组的管理也可以通过集成的系统管理工具来完成。 三、与用户账号有关的系统文件 完成用户管理的工作有许多种方法，但是每一种方法实际上都是对有关的系统文件进行修改。 与用户和用户组相关的信息都存放在一些系统文件中，这些文件包括/etc/passwd, /etc/shadow, /etc/group等。 下面分别介绍这些文件的内容。 1、/etc/passwd文件是用户管理工作涉及的最重要的一个文件。 Linux系统中的每个用户都在/etc/passwd文件中有一个对应的记录行，它记录了这个用户的一些基本属性。 这个文件对所有用户都是可读的。它的内容类似下面的例子： ＃ cat /etc/passwd root❌0:0:Superuser:/: daemon❌1:1:System daemons:/etc: bin❌2:2:Owner of system commands:/bin: sys❌3:3:Owner of system files:/usr/sys: adm❌4:4:System accounting:/usr/adm: uucp❌5:5:UUCP administrator:/usr/lib/uucp: auth❌7:21:Authentication administrator:/tcb/files/auth: cron❌9:16:Cron daemon:/usr/spool/cron: listen❌37:4:Network daemon:/usr/net/nls: lp❌71:18:Printer administrator:/usr/spool/lp: sam❌200:50:Sam san:/home/sam:/bin/sh 从上面的例子我们可以看到，/etc/passwd中一行记录对应着一个用户，每行记录又被冒号(:)分隔为7个字段，其格式和具体含义如下： 用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell 1）&quot;用户名&quot;是代表用户账号的字符串。 通常长度不超过8个字符，并且由大小写字母和/或数字组成。登录名中不能有冒号(😃，因为冒号在这里是分隔符。 为了兼容起见，登录名中最好不要包含点字符(.)，并且不使用连字符(-)和加号(+)打头。 2）“口令”一些系统中，存放着加密后的用户口令字。 虽然这个字段存放的只是用户口令的加密串，不是明文，但是由于/etc/passwd文件对所有用户都可读，所以这仍是一个安全隐患。因此，现在许多Linux 系统（如SVR4）都使用了shadow技术，把真正的加密后的用户口令字存放到/etc/shadow文件中，而在/etc/passwd文件的口令字段中只存放一个特殊的字符，例如“x”或者“*”。 3）“用户标识号”是一个整数，系统内部用它来标识用户。 一般情况下它与用户名是一一对应的。如果几个用户名对应的用户标识号是一样的，系统内部将把它们视为同一个用户，但是它们可以有不同的口令、不同的主目录以及不同的登录Shell等。 通常用户标识号的取值范围是0～65 535。0是超级用户root的标识号，1～99由系统保留，作为管理账号，普通用户的标识号从100开始。在Linux系统中，这个界限是500。 4）“组标识号”字段记录的是用户所属的用户组。 它对应着/etc/group文件中的一条记录。 5)“注释性描述”字段记录着用户的一些个人情况。 例如用户的真实姓名、电话、地址等，这个字段并没有什么实际的用途。在不同的Linux 系统中，这个字段的格式并没有统一。在许多Linux系统中，这个字段存放的是一段任意的注释性描述文字，用做finger命令的输出。 6)“主目录”，也就是用户的起始工作目录。 它是用户在登录到系统之后所处的目录。在大多数系统中，各用户的主目录都被组织在同一个特定的目录下，而用户主目录的名称就是该用户的登录名。各用户对自己的主目录有读、写、执行（搜索）权限，其他用户对此目录的访问权限则根据具体情况设置。 7)用户登录后，要启动一个进程，负责将用户的操作传给内核，这个进程是用户登录到系统后运行的命令解释器或某个特定的程序，即Shell。 Shell是用户与Linux系统之间的接口。Linux的Shell有许多种，每种都有不同的特点。常用的有sh(Bourne Shell), csh(C Shell), ksh(Korn Shell), tcsh(TENEX/TOPS-20 type C Shell), bash(Bourne Again Shell)等。 系统管理员可以根据系统情况和用户习惯为用户指定某个Shell。如果不指定Shell，那么系统使用sh为默认的登录Shell，即这个字段的值为/bin/sh。 用户的登录Shell也可以指定为某个特定的程序（此程序不是一个命令解释器）。 利用这一特点，我们可以限制用户只能运行指定的应用程序，在该应用程序运行结束后，用户就自动退出了系统。有些Linux 系统要求只有那些在系统中登记了的程序才能出现在这个字段中。 8)系统中有一类用户称为伪用户（pseudo users）。 这些用户在/etc/passwd文件中也占有一条记录，但是不能登录，因为它们的登录Shell为空。它们的存在主要是方便系统管理，满足相应的系统进程对文件属主的要求。 常见的伪用户如下所示： 伪 用 户 含 义 bin 拥有可执行的用户命令文件 sys 拥有系统文件 adm 拥有帐户文件 uucp UUCP使用 lp lp或lpd子系统使用 nobody NFS使用 拥有帐户文件 1、除了上面列出的伪用户外，还有许多标准的伪用户，例如：audit, cron, mail, usenet等，它们也都各自为相关的进程和文件所需要。 由于/etc/passwd文件是所有用户都可读的，如果用户的密码太简单或规律比较明显的话，一台普通的计算机就能够很容易地将它破解，因此对安全性要求较高的Linux系统都把加密后的口令字分离出来，单独存放在一个文件中，这个文件是/etc/shadow文件。 有超级用户才拥有该文件读权限，这就保证了用户密码的安全性。 2、/etc/shadow中的记录行与/etc/passwd中的一一对应，它由pwconv命令根据/etc/passwd中的数据自动产生 它的文件格式与/etc/passwd类似，由若干个字段组成，字段之间用&quot;:&quot;隔开。这些字段是： 登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志 &quot;登录名&quot;是与/etc/passwd文件中的登录名相一致的用户账号 &quot;口令&quot;字段存放的是加密后的用户口令字，长度为13个字符。如果为空，则对应用户没有口令，登录时不需要口令；如果含有不属于集合 { ./0-9A-Za-z }中的字符，则对应的用户不能登录。 &quot;最后一次修改时间&quot;表示的是从某个时刻起，到用户最后一次修改口令时的天数。时间起点对不同的系统可能不一样。例如在SCO Linux 中，这个时间起点是1970年1月1日。 &quot;最小时间间隔&quot;指的是两次修改口令之间所需的最小天数。 &quot;最大时间间隔&quot;指的是口令保持有效的最大天数。 &quot;警告时间&quot;字段表示的是从系统开始警告用户到用户密码正式失效之间的天数。 &quot;不活动时间&quot;表示的是用户没有登录活动但账号仍能保持有效的最大天数。 &quot;失效时间&quot;字段给出的是一个绝对的天数，如果使用了这个字段，那么就给出相应账号的生存期。期满后，该账号就不再是一个合法的账号，也就不能再用来登录了。 下面是/etc/shadow的一个例子： ＃ cat /etc/shadow root:Dnakfw28zf38w:8764:0:168:7::: daemon:::0:0:::: bin:::0:0:::: sys:::0:0:::: adm:::0:0:::: uucp:::0:0:::: nuucp:::0:0:::: auth:::0:0:::: cron:::0:0:::: listen:::0:0:::: lp:::0:0:::: sam:EkdiSECLWPdSa:9740:0:0:::: 3、用户组的所有信息都存放在/etc/group文件中。 将用户分组是Linux 系统中对用户进行管理及控制访问权限的一种手段。 每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不同的组。 当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。 用户要访问属于附加组的文件时，必须首先使用newgrp命令使自己成为所要访问的组中的成员。 用户组的所有信息都存放在/etc/group文件中。此文件的格式也类似于/etc/passwd文件，由冒号(:)隔开若干个字段，这些字段有： 组名:口令:组标识号:组内用户列表 &quot;组名&quot;是用户组的名称，由字母或数字构成。与/etc/passwd中的登录名一样，组名不应重复。 &quot;口令&quot;字段存放的是用户组加密后的口令字。一般Linux 系统的用户组都没有口令，即这个字段一般为空，或者是*。 &quot;组标识号&quot;与用户标识号类似，也是一个整数，被系统内部用来标识组。 &quot;组内用户列表&quot;是属于这个组的所有用户的列表/b]，不同用户之间用逗号(,)分隔。这个用户组可能是用户的主组，也可能是附加组。 /etc/group文件的一个例子如下： root::0:root bin::2:root,bin sys::3:root,uucp adm::4:root,adm daemon::5:root,daemon lp::7:root,lp users::20:root,sam 四、添加批量用户 添加和删除用户对每位Linux系统管理员都是轻而易举的事，比较棘手的是如果要添加几十个、上百个甚至上千个用户时，我们不太可能还使用useradd一个一个地添加，必然要找一种简便的创建大量用户的方法。Linux系统提供了创建大量用户的工具，可以让您立即创建大量用户，方法如下： （1）先编辑一个文本用户文件。 每一列按照/etc/passwd密码文件的格式书写，要注意每个用户的用户名、UID、宿主目录都不可以相同，其中密码栏可以留做空白或输入x号。一个范例文件user.txt内容如下： user001::600💯user:/home/user001:/bin/bash user002::601💯user:/home/user002:/bin/bash user003::602💯user:/home/user003:/bin/bash user004::603💯user:/home/user004:/bin/bash user005::604💯user:/home/user005:/bin/bash user006::605💯user:/home/user006:/bin/bash （2）以root身份执行命令 /usr/sbin/newusers，从刚创建的用户文件user.txt中导入数据，创建用户： newusers &lt; user.txt 然后可以执行命令 vipw 或 vi /etc/passwd 检查 /etc/passwd 文件是否已经出现这些用户的数据，并且用户的宿主目录是否已经创建。 （3）执行命令/usr/sbin/pwunconv。 将 /etc/shadow 产生的 shadow 密码解码，然后回写到 /etc/passwd 中，并将/etc/shadow的shadow密码栏删掉。这是为了方便下一步的密码转换工作，即先取消 shadow password 功能。 pwunconv （4）编辑每个用户的密码对照文件。 格式为： 用户名:密码 实例文件 passwd.txt 内容如下： user001:123456 user002:123456 user003:123456 user004:123456 user005:123456 user006:123456 （5）以 root 身份执行命令 /usr/sbin/chpasswd。 创建用户密码，chpasswd 会将经过 /usr/bin/passwd 命令编码过的密码写入 /etc/passwd 的密码栏。 chpasswd &lt; passwd.txt （6）确定密码经编码写入/etc/passwd的密码栏后。 执行命令 /usr/sbin/pwconv 将密码编码为 shadow password，并将结果写入 /etc/shadow。 pwconv 这样就完成了大量用户的创建了，之后您可以到/home下检查这些用户宿主目录的权限设置是否都正确，并登录验证用户密码是否正确。 Linux磁盘管理 Linux磁盘管理好坏直接关系到整个系统的性能问题。 Linux磁盘管理常用三个命令为df，du和fdisk。 df：列出文件系统的整体磁盘使用量 du：检查磁盘空间使用量 fdisk：用于磁盘分区 df df命令参数功能：检查文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 语法： df [ -ahikHTm ] [目录或文件名] 选项与参数： -a：列出所有的文件系统，包括系统特有的/ proc等文件系统； -k：以KBytes的容量显示各文件系统； -m：以MBytes的容量显示各文件系统； -h：以人们较易阅读的GB，MB，KB等格式自行显示； -H：以M = 1000K取代M = 1024K的进位方式； -T：显示文件系统类型，并合并该分区的文件系统名称（例如ext3）也列出； -i：不用硬盘容量，而以inode的数量来显示 实例1 将系统内所有的文件系统列出来！ [根@ WWW 〜]＃DF 文件系统1K -块 用于推介使用％安装上 / dev的/ HDC2 9920624 3823112 5585444 41 ％/的/ dev / hdc3上 4956316 141376 4559108 4 ％/家 / dev的/ hdc1分区 101086 11126 84741 12 ％/引导 tmpfs 371332 0 371332 0 ％/ dev / shm 在Linux底下如果df没有加任何选项，那么替换重定向系统内部的所有（排除特殊内存内部的文件系统与swap）都以1 KB的容量来列出来！ 实例2 将容量结果以易读的容量格式显示出来 [根@ WWW 〜]＃DF - ħ 文件系统大小用于库存状况使用％安装上 / dev的/ HDC2 9.5克3.7G 5.4G 41 ％/的/ dev / hdc3上 4.8G 139M 4.4G 4 ％/家 / dev的/ hdc1分区 99M 11M 83M 12 ％/开机 tmpfs 363M 0 363M 0 ％/ dev / shm 实例3 将系统内的所有特殊文件格式及名称都列出来 [根@ WWW 〜]＃DF -在 文件系统类型1K -块 用于推介使用％安装上 / dev的/ HDC2 EXT3 9920624 3823112 5585444 41 ％/ PROC PROC 0 0 0 - / PROC sysfs中的sysfs 0 0 0 - / SYS devpts devpts 0 0 0 -的/ dev / PTS / dev的/位于hdc3 EXT3 4956316 141376 4559108 4 ％/家 / dev的/ hdc1分区EXT3 101086 11126 84741 12 ％/引导 tmpfs tmpfs 371332 0 371332 0 ％/ dev / shm 没有binfmt_misc 0 0 0 -的/ proc / SYS / FS / binfmt_misc sunrpc rpc_pipefs 0 0 0 -在/ var / lib中/ NFS / rpc_pipefs 实例4 将/ etc底下的可用的磁盘容量以易读的容量格式显示 [根@ WWW 〜]＃DF - ħ /等 文件系统大小用于库存状况使用％安装上 / dev的/ HDC2 9.5克3.7G 5.4G 41 ％/ du Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的，这里介绍Linux du命令。 语法： du [ -ahskm ]文件或目录名称 选项与参数： -a：列出所有的文件与目录容量，因为唯一仅统计目录底下的文件量而已。 -h：以人们较易读的容量格式（G / M）显示； -s：列出总数而已，而不列出每个各别的目录占用容量； -S：不包括子目录下的总计，与-s有点区别。 -k：以KBytes列出容量显示； -m：以MBytes列出容量显示； 实例1 只列出当前目录下的所有文件夹容量（包括隐藏文件夹）： [根@ WWW 〜]＃杜 8 ./ TEST4 &lt;==每个目录都会列出来8 ./ TEST2 ....中间省略.... 12 ./。gconfd &lt;==包括隐藏文件的目录220 。&lt;==这个目录（。）所占用的大量 直接输入du没有加任何选项时，则du会分析当前所在目录的文件与目录所占用的硬盘空间。 实例2 将文件的容量也列出来 [根@ WWW 〜]＃杜-一个 12 ./安装。日志。syslog &lt;==有文件的列表了8 ./。bash_logout 8 ./ test4 8 ./ test2 ....中间省略.... 12 ./。gconfd 220 。 实例3 检查根目录底下每个目录所占用的容量 [ root @ www〜]＃du - sm / * 7 /箱 6 /启动 .....中间省略.... 0 /进程 .....中间省略.... 1 /转 3859 / usr &lt;==系统初期最大就是他了啦！ 77 / var 通配符*来代表每个目录。 与df不一样的是，du这个命令实际上会直接到文件系统内去搜寻所有的文件数据。 fdisk fdisk是Linux的磁盘分区表操作工具。 语法： fdisk [ -l ]装置名称 选项与参数： -l：输出后面接的装置所有的分区内容。若仅有fdisk -l时，则系统将会把整个系统内部能够搜寻到的装置的分区均列出来。 实例1 列出所有分区信息 [ root @ AY120919111755c246621 tmp ]＃fdisk - l 磁盘/ dev / xvda ：21.5 GB ，21474836480字节 255磁头，63扇区/磁道，2610个柱面 单位=柱面16065 * 512 = 8225280字节 扇区大小（逻辑/物理）：512字节/ 512字节 I / O大小（最小/最佳）：512字节/ 512字节 磁盘标识符：0x00000000 设备引导启动结束块ID系统/ dev / xvda1 * 1 2550 20480000 83 Linux / dev / xvda2 2550 2611 490496 82 Linux swap / Solaris ​ 磁盘/ dev / xvdb ：21.5 GB ，21474836480字节 255磁头，63扇区/磁道，2610个柱面 单位=柱面16065 * 512 = 8225280字节 扇区大小（逻辑/物理）：512字节/ 512字节 I / O大小（最小/最佳）：512字节/ 512字节 磁盘标识符：0x56f40944 设备启动开始端块ID系统/ dev / xvdb2 1 2610 20964793 + 83 Linux 实例2 找出您系统中的根目录所在磁盘，并查阅该硬盘内的相关信息 [根@ WWW 〜]＃DF / &lt;==注意：重点在找出磁盘文件名而已文件系统1K -块 用于推介使用％安装上 / dev的/ HDC2 9920624 3823168 5585388 41 ％/ [根@ WWW 〜]＃的fdisk /开发/ HDC &lt;==仔细看，不要加上数字喔！的汽缸数为这盘被设置到5005有是没有错与那个，但是这是大于1024 ，并且可以在某些设置会导致问题与：1 ）软件，在系统启动时运行（ē 。摹。老版本的LILO ）2 ）引导和分区软件从其它操作系统（É 。克。，DOS FDISK ，OS / 2 FDISK ） 命令（m为帮助）：&lt;==等待你的输入！ 输入m后，就会看到底下这些命令介绍 命令（m为帮助）：m &lt;==输入m后，就会看到底下这些命令介绍Command action 切换可启动标志 b编辑bsd disklabel c切换dos兼容性标志 d 删除分区 &lt;==删除一个分区 l列出已知的分区类型 m 打印此菜单 n添加一个新分区 &lt;==添加一个分区 o创建一个新的空DOS分区表 p 打印分区表 &lt;==在屏幕上显示分区表 q退出而不保存更改&lt;==不保存 离开fdisk程序 创建一个新的空Sun disklabel t更改分区的系统ID u更改显示/输入单位 v验证分区表 w将表写入磁盘并退出&lt;==将刚刚的动作写入分割表 x额外功能（仅限专家） 离开fdisk时点击q，那么所有的动作都不会生效！相反的，按下w就是动作生效的意思。 命令（m为帮助）：p &lt;==这里可以输出当前磁盘的状态 磁盘/ dev / hdc ：41.1 GB ，41174138880字节 &lt;==这个磁盘的文件名与容量255个磁头，63个扇区/磁道，5005个磁柱 &lt;==磁头，增大与磁柱大小单位= 16065 * 512磁柱= 8225280字节&lt;==每个磁柱的大小 ​ 设备引导启动结束块ID系统/ dev / hdc1 * 1 13 104391 83 Linux / dev / hdc2 14 1288 10241437 + 83 Linux / dev / hdc3 1289 1925 5116702 + 83 Linux / dev / hdc4 1926 5005 24740100 5扩展/ dev / hdc5 1926 2052 1020096 82 Linux swap / Solaris ＃装置文件名启动区否开始磁柱结束磁柱1K大小容量磁盘分区槽内的系统 命令（m表示帮助）：q 想要不储存离开吗？点击q就对了！不要随便按w啊！ 使用p可以列出目前这颗磁盘的分割表信息，这个信息的上半部在显示整体磁盘的状态。 磁盘格式化 磁盘分割完成后自然就是要进行文件系统的格式化，格式化的命令非常的简单，使用mkfs（使文件系统）命令。 语法： mkfs [ -t文件系统格式]装置文件名 选项与参数： -t：可以接文件系统格式，例如ext3，ext2，vfat等（系统有支持才会生效） 实例1 查看mkfs支持的文件格式 [ root @ www〜] ＃mkfs [标签] [标签] mkfs mkfs 。cramfs mkfs 。ext2 mkfs 。ext3 mkfs 。msdos mkfs 。胖子 按下两个[tab]，会发现mkfs支持的文件格式如上所示。 实例2 将分区/ dev / hdc6（可指定你自己的分区）格式化为ext3文件系统： [ root @ www〜]＃mkfs - t ext3 / dev / hdc6 mke2fs 1.39 （29 - May - 2006 ）文件系统标签= &lt;==这里指的是分割槽的名称（label ） 操作系统类型：Linux块大小= 4096 （log = 2 ）&lt;==块的大小配置为4K片段大小= 4096 （日志= 2 ）251392个i节点，502023块 &lt;==由此配置决定的索引节点/块数量 25101块（5.00 ％）保留用于该超级用户 首先数据块= 0最大文件系统块= 515899392个16块组 32768个每块组，32768个每片段组15712个每索引节点组的超级块存储在块的备份：32768 ，98304 ，163840 ，229376 ，294912 ​ 编写inode表：完成创建日志（8192个块）：完成&lt;==有日志记录编写超级块和文件系统记帐信息：完成 该文件系统将每34坐骑或180天自动检查一次，以先到者为准。使用tune2fs - ç或-我要重写。＃这样就创建了我们所需要的Ext3文件系统了！简单明了！ 磁盘检验 fsck（文件系统检查）用来检查和维护二者的文件系统。 若系统掉电或磁盘发生问题，可利用fsck命令对文件系统进行检查。 语法： fsck [ -t文件系统] [ -ACay ]装置名称 选项与参数： -t：给定档案系统的型式，若在/ etc / fstab中已有定义或kernel本身已支持的则不需加上此参数 -s：依序一个一个地执行fsck的指令来检查 -A：对/ etc / fstab中所有列出来的分区（partition）做检查 -C：显示完整的检查进度 -d：打印出e2fsck的调试结果 -p：同时有-A条件时，同时有多个fsck的检查一起执行 -R：同时有-A条件时，省略/不检查 -V：详细显示模式 -a：如果检查有错则自动修复 -r：如果检查有错则由使用者回答是否恢复 -y：选项指定检测每个文件是自动输入yes，在不确定那些是不正常的时候，可以执行＃fsck -y全部检查修复。 实例1 查看系统有多少文件系统支持的fsck命令： [ root @ www〜] ＃fsck [标签] [标签] fsck fsck 。cramfs fsck 。ext2 fsck 。ext3 fsck 。msdos fsck 。胖子 实例2 强制检测/ dev / hdc6分区： [ root @ www〜]＃fsck - C - f - t ext3 / dev / hdc6 fsck的1.39 （29 -月- 2006年） 用e2fsck 1.39 （29 -月- 2006年）通1 ：检查索引节点，块，和尺寸 通行证2 ：检查目录结构 通行证3 ：检查目录的连接 通4 ：检查引用计数 传递5 ：检查组 摘要信息 vbird_logical ：11 /二十五万一千九百六十八文件（9.1 ％非-连续的），36926 /一百万四千零四十六块 如果没有加上-f的选项，则由于该文件系统不曾出现问题，检查的经过非常快速！若加上-f强制检查，只会有一项的显示过程。 磁盘挂载与卸除 Linux的磁盘挂载使用mount命令，卸载使用umount命令。 磁盘挂载语法： mount [ -t文件系统] [ -L标签名] [ -o其他选项] [ -n ]装置文件名挂载点 实例1 用最小的方式，将刚刚创建的/ dev / hdc6挂载到/ mnt / hdc6上面！ [根@ WWW 〜]＃MKDIR / MNT / hdc6 [根@ WWW 〜]＃安装/ dev的/ hdc6 / MNT / hdc6 [根@ WWW 〜]＃DF 文件系统1K -块 用于推介使用％安装上 .... 。中间省略..... / dev / hdc6 1976312 42072 1833836 3 ％/ mnt / hdc6 磁盘卸载命令umount语法： 卸除[ - FN ]装置文件名或挂载点 选项与参数： -f：强制卸除！可用在类似网络文件系统（NFS）无法读取到的情况下； -n：不升级/ etc / mtab情况下卸除。 卸载/ dev / hdc6 [根@ WWW 〜]＃卸除/ dev的/ hdc6 vi/vim 所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定会存在。但是目前我们使用比较多的是 vim 编辑器。vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 什么是 vim？ Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 简单的来说， vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 连 vim 的官方网站 (http://www.vim.org) 自己也说 vim 是一个程序开发工具而不是文字处理软件。 vim 键盘图： vi/vim 的使用 基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 这三种模式的作用分别是： 命令模式： 用户刚刚启动 vi/vim，便进入了命令模式。 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。 以下是常用的几个命令： i 切换到输入模式，以输入字符。 x 删除当前光标所在处的字符。 : 切换到底线命令模式，以在最底一行输入命令。 若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。 命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。 输入模式 在命令模式下按下i就进入了输入模式。 在输入模式中，可以使用以下按键： 字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END，移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 底线命令模式 在命令模式下按下:（英文冒号）就进入了底线命令模式。 底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。 在底线命令模式中，基本的命令有（已经省略了冒号）： q 退出程序 w 保存文件 按ESC键可随时退出底线命令模式。 简单的说，我们可以将这三个模式想成底下的图标来表示 vi/vim 使用实例 使用 vi/vim 进入一般模式 如果你想要使用 vi 来建立一个名为 runoob.txt 的文件时，你可以这样做： $ vim runoob.txt 直接输入 vi 文件名 就能够进入 vi 的一般模式了。请注意，记得 vi 后面一定要加文件名，不管该文件存在与否！ - 按下 i 进入输入模式(也称为编辑模式)，开始编辑文字 在一般模式之中，只要按下 i, o, a 等字符就可以进入输入模式了！ 在编辑模式当中，你可以发现在左下角状态栏中会出现 –INSERT- 的字样，那就是可以输入任意字符的提示。 这个时候，键盘上除了 Esc 这个按键之外，其他的按键都可以视作为一般的输入按钮了，所以你可以进行任何的编辑。 - 按下 ESC 按钮回到一般模式 好了，假设我已经按照上面的样式给他编辑完毕了，那么应该要如何退出呢？是的！没错！就是给他按下 Esc 这个按钮即可！马上你就会发现画面左下角的 – INSERT – 不见了！ 在一般模式中按下 :wq 储存后离开 vi OK，我们要存档了，存盘并离开的指令很简单，输入 :wq 即可保存离开！ - Linux vi_vim _ 菜鸟教程.pdf Linux yum命令 yum（Yellow dog Updater，Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端连接管理器。 基于RPM包管理，能够从指定的服务器自动下载RPM包和安装，可以自动处理相对关系，并且一次安装所有依赖的软件包，无须繁琐地一次次下载，安装。 yum提供了查找，安装，删除某人，多个甚至全部完全的命令，而且命令简洁而又好记。 yum语法 yum [选项] [命令] [包...] 选项：任选，选项包括-h（帮助），-y（当安装过程提示选择全部为“ yes”），-q（不显示安装的过程）等等。 命令：要进行的操作。 package：安装的包名。 yum常用命令 1.列出所有可更新的软件清单命令：yum check-update 2.更新所有软件命令：yum update 3.仅安装指定的软件命令：yum install &lt;程序包名称&gt; 4.仅更新指定的软件命令：yum update &lt;程序包名称&gt; 5.列出所有可安装的软件清单命令：百胜名单 6.删除删除命令：yum remove &lt;package_name&gt; 7.查找普通命令：yum search &lt;关键字&gt; 8.清除缓存命令： 百胜清洁包：清除缓存目录下的双重 yum clean headers：清除缓存目录下的headers yum clean oldheaders：清除缓存目录下旧的标题 yum clean，yum clean all（= yum clean package; yum clean oldheaders）：清除缓存目录下的副本及旧的标题 实例1 安装pam-devel [根@ WWW 〜]＃百胜安装PAM - devel的 设置了安装过程解析包安装参数 解析依赖性&lt;==先检查软件的属性相依问题- &gt;运行的事务检查 ---&gt;封装PAM - devel的。i386 0 ：0.99 。6.2 - 4.el5集被更新 处理相关：PAM = 0.99 。6.2 - 4.el5的包：PAM - devel的 运行交易检查 ---&gt;包装PAM 。i386 0 ：0.99 。6.2 - 4.el5集进行更新 文件列表。xml 。gz 100 ％| ======================== | 1.6 MB 00 ：05 的文件列表。xml 。gz 100 ％| ======================== | 138 kB 00 : 00- &gt;完成的依赖性解析……（省略） 实例2 可拆卸pam-devel [根@ WWW 〜]＃荫删除PAM - devel的 设置了删除过程解决依赖&lt;==同样的，先解决属性相依的问题- &gt;运行的事务检查 ---&gt;封装PAM - devel的。i386 0 ：0.99 。6.2 - 4.el5集被擦除 成品依赖决议 解决依赖性 ================================================== =软件包Arch版本库大小 ================================================== =删除： pam - devel i386 0.99 。6.2 - 4.el5 安装 495 ķ 交易摘要================================ =============================安装0包（小号）更新0包（小号）中取出1包（小号）&lt;==还好，并没有属性相依的问题，单纯可移除一个软件 是该行[ ÿ / Ñ ]：Ÿ 下载软件包：运行rpm_check_debug 运行交易测试已完成的交易测试的交易测试成功运行交易擦除：PAM - devel的 ################### ###### [1/1] 删除：pam - devel 。i386 0 ：0.99 。6.2 - 4.el5完成！ 实例3 利用yum的功能，发现以pam为开头的软件名称有什么？ [ root @ www〜] ＃yum list pam *已安装的软件包 pam 。i386 0.99 。6.2 - 3.27 。已安装el5 pam_ccreds 。I386 3 - 5 安装 pam_krb5 。i386 2.2 。14 - 1 安装 pam_passwdqc 。i386 1.0 。2 - 1.2 。2 安装 pam_pkcs11 。i386 0.5 。3 - 23 安装 pam_smb 。i386 1.1 。7 - 7.2 。1个 已安装的 可用软件包&lt;==底下则是『可升级』的或『未安装』的 pam 。i386 0.99 。6.2 - 4.el5基 PAM - devel的。i386 0.99 。6.2 - 4.el5基 pam_krb5的。i386 2.2 。14 - 10基 国内yum源 网易（163）yum源是国内最好的yum源之一，无论是速度还是软件版本，都非常的不错。 将yum源设置为163 yum，可以提高扩展安装和更新的速度，同时避免一些常见软件版本无法找到。 安装步骤 首先备份/etc/yum.repos.d/CentOS-Base.repo mv / etc / yum 。回购。d / CentOS的-基础。回购/ etc / yum 。回购。d / CentOS的-基础。回购。后备 下载对应版本repo文件，加入/etc/yum.repos.d/（操作前请做好相应备份） CentOS5：http：//mirrors.163.com/.help/CentOS5-Base-163.repo CentOS6：http：//mirrors.163.com/.help/CentOS6-Base-163.repo CentOS7：http：//mirrors.163.com/.help/CentOS7-Base-163.repo wget的HTTP ：//mirrors.163.com/.help/CentOS6-Base-163.repo MV CentOS6 -基地- 163.repo的CentOS -基地。回购 运行以下命令生成缓存 百胜清理所有 yum makecache 除了网易之外，国内还有其他不错的yum源，某些中科大和搜狐。 中科大的yum源，安装方法查看：https 😕/lug.ustc.edu.cn/wiki/mirrors/help/centos sohu的yum源安装方法查看：http : //mirrors.sohu.com/help/centos.html Linux apt 命令 apt（Advanced Packaging Tool）是一个在 Debian 和 Ubuntu 中的 Shell 前端软件包管理器。 apt 命令提供了查找、安装、升级、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。 apt 命令执行需要超级管理员权限(root)。 apt 语法 apt [options] [command] [package ...] options：可选，选项包括 -h（帮助），-y（当安装过程提示选择全部为&quot;yes&quot;），-q（不显示安装的过程）等等。 command：要进行的操作。 package：安装的包名。 apt 常用命令 列出所有可更新的软件清单命令：sudo apt update 升级软件包：sudo apt upgrade 列出可更新的软件包及版本信息：apt list --upgradeable 升级软件包，升级前先删除需要更新软件包：sudo apt full-upgrade 安装指定的软件命令：sudo apt install &lt;package_name&gt; 安装多个软件包：sudo apt install &lt;package_1&gt; &lt;package_2&gt; &lt;package_3&gt; 更新指定的软件命令：sudo apt update &lt;package_name&gt; 显示软件包具体信息,例如：版本号，安装大小，依赖关系等等：sudo apt show &lt;package_name&gt; 删除软件包命令：sudo apt remove &lt;package_name&gt; 清理不再使用的依赖和库文件: sudo apt autoremove 移除软件包及配置文件: sudo apt purge &lt;package_name&gt; 查找软件包命令： sudo apt search 列出所有已安装的包：apt list --installed 列出所有已安装的包的版本信息：apt list --all-versions 实例 查看一些可更新的包： sudo apt update 升级安装包： sudo apt upgrade 在以上交互式输入字母 Y 即可开始升级。 可以将以下两个命令组合起来，一键升级： sudo apt update &amp;&amp; sudo apt upgrade -y 安装 mplayer 包： sudo apt install mplayer 如过不太记得完整的包名，我们可以只输入前半部分的包名，然后按下 Tab 键，会列出相关的包名： 以上实例我们输入来 reds，然后按下 Tab 键，输出来四个相关的包。 如果我们想安装一个软件包，但如果软件包已经存在，则不要升级它，可以使用 –no-upgrade 选项: sudo apt install &lt;package_name&gt; --no-upgrade 安装 mplayer 如果存在则不要升级： sudo apt install mplayer --no-upgrade 如果只想升级，不要安装可以使用 --only-upgrade 参数： sudo apt install &lt;package_name&gt; --only-upgrade 只升级 mplayer，如果不存在就不要安装它： sudo apt install mplayer --only-upgrade 如果需要设置指定版本，语法格式如下： sudo apt install &lt;package_name&gt;=&lt;version_number&gt; package_name 为包名，version_number 为版本号。 移除包可以使用 remove 命令： sudo apt remove mplayer 查找名为 libimobile 的相关包： apt search libimobile 查看 pinta 包的相关信息： apt show pinta 列出可更新的软件包： apt list --upgradeable 清理不再使用的依赖和库文件： sudo apt autoremove 在以上交互式输入字母 Y 即可开始清理。","link":"/2021/03/01/Draft/2021/Linux/"},{"title":"MYSQL优化","text":"MySql知识及优化 相关资源：bili视频、 Linux下RPM版MYSQL安装、启停 MySQL启动问题、配置文件、编码问题 MYSQL分层、存储引擎 连接层（提供与客户端连接的服务） 服务层（提供各种用户使用的接口，提供SQL优化器【MySQL Query Optimizer】）） 引擎层（提供各种存储数据的方式【InnoDB：事物优先，适合高并发，行锁；MyISAM：性能优先，表锁】） show engines; 显示支持引擎 +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ | Engine | Support | Comment | Transactions | XA | Savepoints | +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ | MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO | | MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO | | CSV | YES | CSV storage engine | NO | NO | NO | | FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL | | PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO | | MyISAM | YES | MyISAM storage engine | NO | NO | NO | | InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES | | BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO | | ARCHIVE | YES | Archive storage engine | NO | NO | NO | +--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ show variables like ‘%storage_engine%’; 查看当前使用引擎 12345678-- 指定数据库引擎create table tb(​ id int(4) auto_increment,​ name varchar(5),​ dept varchar(5),​ primary key(id))ENGINE=MyISAM AUTO_INCREMENT=1DEFAULT CHARSET=utf-8 存储层（存储数据） SQL解析过程、索引、B树 sql优化： 原因：性能低，执行或等待时间太长，SQL语句欠佳（连接查询）、索引失效、服务器参数设置不对 SQL编写过程与解析过程： 编写:select dinstinct ..from …join ..on ..where ..group by ..having ..order by ..limit 解析:form ..on ..join ..where ..group vy ..having ..select dinstinct ..order by limit.. 索引 简介 sql优化主要是优化索引，索引（index）相当于书的目录。索引是数据结构（默认B树【小左大右】） 优点 提高查询效率（降低IO、CPU使用率） 缺点 索引本身很大（可以存放在内存/硬盘） 索引不是所有情况都适用：少量数据，频繁更新字段，很少使用的字段 索引会降低增删改查效率 分类 单值索引：单字段 唯一索引：不能重复 主键索引：不能重复，不能为null，主键默认是主键索引 复合索引：相当于二级目录（name，age） 创建索引 方式一 create 索引类型 索引名 on 表（字段） 单值索引：create index dept_index on tb(dept); 唯一索引：create unique index name-index on tb(name) 复合索引：create index dept_name_index on tb(dept,name); 方式二 alter table 表名 add 索引类型 索引名（字段） 单值索引：alter table tb add index dept_index(dept); 唯一索引：alter table tb add unique index name-index(name) 复合索引：alter table tb add index dept_name_index(dept,name); 删除索引 drop index 索引名 on 表名 查询索引 show index from 表名\\G SQL优化准备 分析SQL的执行计划：explain+sql语句，模拟sql优化器执行sql语句，从而让开发人员知道自己SQL语句情况 id select_type table partitions type possible_keys key key_len ref rows filtered Extra 1 SIMPLE user const PRIMARY PRIMARY 152 const 1 100.00 id 编号 子查询id不同，关联查询相同 **select_type ** 查询类型** **table ** 查询表 id相同数据量越少越优先查询，id不通id越大越优先 partitions **type ** 类型 **possible_keys ** 预测用到的索引 **key ** 实际用到的索引 **key_len ** 实际使用索引的长度 **ref ** 表之间的引用 **rows ** 通过索引查询到的数据量 filtered **Extra ** 额外的信息 id、table 先查内层，再查外层。子查询id不同，关联查询id相同。 id相同数据量越少越优先查询，id不通id越大越优先 explain SELECT * from teacher where tid=(select tid from course where cid='2') or tcid=(select tcid from teachercard where tcid='3') explain select t.* from teacher t,course c,teacherCard tc where t.tid=c.tid and t.tcid=tc.tcid and (c.cid='2' or tc.tcid='3') select_type（查询类型） PRIMARY：包含子查询SQL中的 主查询（最外层） SUBQUERY：包含子查询SQL中的子查询（非最外层） SIMPLE：简单查询（不包含子查询、union） union： derived：衍生查询（使用到了临时表） 在form子查询中只有一张表 explain select cr.cname from (select * from course where tid in (1,2)) cr; form子查询中，如果有table1 union table2，则table1 就是的riverd explain select cr.cname from (select * from course where tid =1 union select * from course where tid =2) cr; type（索引类型） system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all 对TYPE优化前提：有索引 system，const知识理想情况，实际能达到 ref &gt;range system（忽略）：只有一条数据的系统表；或衍生表只有一条数据的主查询 const：仅仅能查到一条数据的SQL，用于Primayr key 或unique索引（类型与索引类型有关） eq_ref：唯一性索引：对于每个索引建的查询，返回匹配唯一行数据（有且只有1个，不能多、不能0） select ·· from ··where name=···常见唯一索引和主键索引 ref：非唯一性索引，对于每个索引建的查询，返回匹配的所有行（0，多） range：检索指定范围的行，where后面是一个范围查询（between，in，&gt; &lt; &gt;=，in有时候会失效，从而转为all） index：查询全部索引中的数据，只需要扫描索引表，不需要所有表中的所有数据 all：查询全部表中的数据，需要全表所有，即需要所有表中的所有数据 possible_keys 可能用到的索引，是一种预测，不准 key 实际用到的索引 key_len： 索引长度，用于判断复合索引是否完全使用，如果索引字段可为null，则会使用1个字节用于标识，索引字段为可变长度，则会使用2个字节 ref 注意与type值中的ref值区分 作用：指明当前表所参照的字段 select 。。。 where a.c=b.x （） rows 被索引优化查询的数据个数（实际通过索引而查询到的数据个数） extra using filesort：性能消耗大,需要额外的一次排序（查询） 单索引：如果排序和查找是同一个字段，则不会出现using filesort ；如果排序和查找不是同一个字段，则会出现。 避免：where哪些字段就order by哪些字段 复合索引：不能跨列（最佳左前缀） 避免：where和order by 按照复合索引的顺序适应，不要跨列或无序使用 using temporary：性能损耗较大，用到了临时表。一般出现在 group by 语句中； explain select a1 from test02 where a1 in(‘1’,’2’,’3’) group by a1; explain select a1 from test02 where a1 in(‘1’,’2’,’3’) group by a2; —–using tempporary 避免：查询哪些列，就根据哪些列group by using temporary：性能提升，索引覆盖，原因：不读取源文件，只从索引中获取数据，使用到的列全部都在索引中 using where：需要回原表查询 impossible where：where子句永远为false 优化示例 create table test03 (a1 int(4) not null, a2 int(4) not null, a3 int(4) not null, a4 int(4) not null ) alter table test03 add index idx_a1_a2_a3_a4(a1,a2,a3,a4); explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a3=3 and a4=4;—-推荐写法 explain select a1,a2,a3,a4 from test03 where a4=1 and a2=2 and a1=3 and a4=4;—-虽然编写后的顺序和索引顺序不一致，但是sql执行前经过了sql优化器的调整，结果与上条sql是一致的。 —–以上两个sql使用了全部的索引 explain select a1,a2,a3,a4 from test03 where a4=1 and a2=2 and a4=4 order by and a1; —-以上SQL用到了a1 a2两个索引，该两个字段 不需要回表查询using index ；a4跨列使用造成了该索引失效，所以需要回表查询，因此是using where ，以上可以通过key_len验证 explain select a1,a2,a3,a4 from test03 where a4=1 and a4=4 order by and a3; —-以上SQL出现了using filesort（文件内排序，”多了一次额外的查找/排序“）不要跨列使用（where 和order by拼接起来使用） explain select a1,a2,a3,a4 from test03 where a4=1 and a4=4 order by and a2,a3; ===这样便不会出现 using filesort，如果复合索引和使用顺序全部一致，则复合索引全部使用，部分一致则使用部分索引。 单表优化及总结 （1）单表优化 create table book ( bid int(4) primary key, name varchar(20) not null, authorid int(4) not null, publicid int(4) not null, typeid int(4) not null ); insert into book values(1,'tjava',1,1,2) ; insert into book values(2,'tc',2,1,2) ; insert into book values(3,'wx',3,2,1) ; insert into book values(4,'math',4,2,3) ; commit; 查询authorid=1且 typeid为2或3的 bid explain select bid from book where typeid in(2,3) and authorid=1 order by typeid desc ; (a,b,c) (a,b) 优化：加索引 alter table book add index idx_bta (bid,typeid,authorid); 索引一旦进行 升级优化，需要将之前废弃的索引删掉，防止干扰。 drop index idx_bta on book; 根据SQL实际解析的顺序，调整索引的顺序： alter table book add index idx_tab (typeid,authorid,bid); --虽然可以回表查询bid，但是将bid放到索引中 可以提升使用using index ; 再次优化（之前是index级别）：思路。因为范围查询in有时会实现，因此交换 索引的顺序，将typeid in(2,3) 放到最后。 drop index idx_tab on book; alter table book add index idx_atb (authorid,typeid,bid); explain select bid from book where authorid=1 and typeid in(2,3) order by typeid desc ; ​ ​ --小结： a.最佳做前缀，保持索引的定义和使用的顺序一致性 b.索引需要逐步优化 c.将含In的范围查询 放到where条件的最后，防止失效。 ​ ​ 本例中同时出现了Using where（需要回原表）; Using index（不需要回原表）：原因，where authorid=1 and typeid in(2,3)中authorid在索引(authorid,typeid,bid)中，因此不需要回原表（直接在索引表中能查到）；而typeid虽然也在索引(authorid,typeid,bid)中，但是含in的范围查询已经使该typeid索引失效，因此相当于没有typeid这个索引，所以需要回原表（using where）； ​ 例如以下没有了In，则不会出现using where ​ explain select bid from book where authorid=1 and typeid =3 order by typeid desc ; ​ ​ 还可以通过key_len证明In可以使索引失效。 ​ （2）两表优化 create table teacher2 ( tid int(4) primary key, cid int(4) not null ); insert into teacher2 values(1,2); insert into teacher2 values(2,1); insert into teacher2 values(3,3); create table course2 ( cid int(4) , cname varchar(20) ); insert into course2 values(1,'java'); insert into course2 values(2,'python'); insert into course2 values(3,'kotlin'); commit; 左连接： explain select *from teacher2 t left outer join course2 c on t.cid=c.cid where c.cname='java'; 索引往哪张表加？ -小表驱动大表 -索引建立经常使用的字段上 （本题 t.cid=c.cid可知，t.cid字段使用频繁，因此给该字段加索引） [一般情况对于左外连接，给左表加索引；右外连接，给右表加索引] 小表：10 大表：300 where 小表.x 10 = 大表.y 300; --循环了几次？10 大表.y 300=小表.x 10 --循环了300次 小表:10 大表:300 select ...where 小表.x10=大表.x300 ; for(int i=0;i&lt;小表.length10;i++) { for(int j=0;j&lt;大表.length300;j++) { ... } } select ...where 大表.x300=小表.x10 ; for(int i=0;i&lt;大表.length300;i++) { for(int j=0;j&lt;小表.length10;j++) { ... } } --以上2个FOR循环，最终都会循环3000次；但是 对于双层循环来说：一般建议 将数据小的循环 放外层；数据大的循环放内存。 --当编写 ..on t.cid=c.cid 时，将数据量小的表 放左边（假设此时t表数据量小） alter table teacher2 add index index_teacher2_cid(cid) ; alter table course2 add index index_course2_cname(cname); Using join buffer:extra中的一个选项，作用：Mysql引擎使用了 连接缓存。 （3）三张表优化 ​ a.小表驱动大表 b.索引建立在经常查询的字段上 示例： create table test03 ( a1 int(4) not null, a2 int(4) not null, a3 int(4) not null, a4 int(4) not null ); alter table test03 add index idx_a1_a2_a3_4(a1,a2,a3,a4) ; 12345678910explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a3=3 and a4 =4 ; --推荐写法，因为 索引的使用顺序（where后面的顺序） 和 复合索引的顺序一致explain select a1,a2,a3,a4 from test03 where a4=1 and a3=2 and a2=3 and a1 =4 ; --虽然编写的顺序 和索引顺序不一致，但是 sql在真正执行前 经过了SQL优化器的调整，结果与上条SQL是一致的。--以上 2个SQL，使用了 全部的复合索引explain select a1,a2,a3,a4 from test03 where a1=1 and a2=2 and a4=4 order by a3; --以上SQL用到了a1 a2两个索引，该两个字段 不需要回表查询using index ;而a4因为跨列使用，造成了该索引失效，需要回表查询 因此是using where；以上可以通过 key_len进行验证explain select a1,a2,a3,a4 from test03 where a1=1 and a4=4 order by a3; --以上SQL出现了 using filesort(文件内排序，“多了一次额外的查找/排序”) ：不要跨列使用( where和order by 拼起来，不要跨列使用) 1explain select a1,a2,a3,a4 from test03 where a1=1 and a4=4 order by a2 , a3; --不会using filesort 123--总结：i.如果 (a,b,c,d)复合索引 和使用的顺序全部一致(且不跨列使用)，则复合索引全部使用。如果部分一致(且不跨列使用)，则使用部分索引。select a,c where a = and b= and d= ii.where和order by 拼起来，不要跨列使用 1using temporary:需要额外再多使用一张表. 一般出现在group by语句中；已经有表了，但不适用，必须再来一张表。 解析过程： from .. on.. join ..where ..group by ....having ...select dinstinct ..order by limit ... a. explain select * from test03 where a2=2 and a4=4 group by a2,a4 ;--没有using temporary b. explain select * from test03 where a2=2 and a4=4 group by a3 ; 避免索引失效的一些原则 12345678910111213141516171819202122232425（1）复合索引 a.复合索引，不要跨列或无序使用（最佳左前缀） (a,b,c) b.复合索引，尽量使用全索引匹配 (a,b,c) （2）不要在索引上进行任何操作（计算、函数、类型转换），否则索引失效 select ..where A.x = .. ; --假设A.x是索引 不要：select ..where A.x*3 = .. ; explain select * from book where authorid = 1 and typeid = 2 ;--用到了at2个索引 explain select * from book where authorid = 1 and typeid*2 = 2 ;--用到了a1个索引 explain select * from book where authorid*2 = 1 and typeid*2 = 2 ;----用到了0个索引 explain select * from book where authorid*2 = 1 and typeid = 2 ;----用到了0个索引,原因：对于复合索引，如果左边失效，右侧全部失效。(a,b,c)，例如如果 b失效，则b c同时失效。 drop index idx_atb on book ; alter table book add index idx_authroid (authorid) ; alter table book add index idx_typeid (typeid) ; explain select * from book where authorid*2 = 1 and typeid = 2 ;（3）复合索引不能使用不等于（!= &lt;&gt;）或is null (is not null)，否则自身以及右侧所有全部失效。 复合索引中如果有&gt;，则自身和右侧索引全部失效。explain select * from book where authorid = 1 and typeid =2 ;-- SQL优化，是一种概率层面的优化。至于是否实际使用了我们的优化，需要通过explain进行推测。explain select * from book where authorid != 1 and typeid =2 ;explain select * from book where authorid != 1 and typeid !=2 ; 1234567891011121314151617181920212223242526体验概率情况(&lt; &gt; =)：原因是服务层中有SQL优化器，可能会影响我们的优化。drop index idx_typeid on book;drop index idx_authroid on book;alter table book add index idx_book_at (authorid,typeid);explain select * from book where authorid = 1 and typeid =2 ;--复合索引at全部使用explain select * from book where authorid &gt; 1 and typeid =2 ; --复合索引中如果有&gt;，则自身和右侧索引全部失效。explain select * from book where authorid = 1 and typeid &gt;2 ;--复合索引at全部使用----明显的概率问题---explain select * from book where authorid &lt; 1 and typeid =2 ;--复合索引at只用到了1个索引explain select * from book where authorid &lt; 4 and typeid =2 ;--复合索引全部失效--我们学习索引优化 ，是一个大部分情况适用的结论，但由于SQL优化器等原因 该结论不是100%正确。--一般而言， 范围查询（&gt; &lt; in），之后的索引失效。（4）补救。尽量使用索引覆盖（using index） （a,b,c）select a,b,c from xx..where a= .. and b =.. ;(5) like尽量以“常量”开头，不要以'%'开头，否则索引失效select * from xx where name like '%x%' ; --name索引失效explain select * from teacher where tname like '%x%'; --tname索引失效explain select * from teacher where tname like 'x%'; explain select tname from teacher where tname like '%x%'; --如果必须使用like '%x%'进行模糊查询，可以使用索引覆盖 挽救一部分。 123456（6）尽量不要使用类型转换（显示、隐式），否则索引失效explain select * from teacher where tname = 'abc' ;explain select * from teacher where tname = 123 ;//程序底层将 123 -&gt; '123'，即进行了类型转换，因此索引失效（7）尽量不要使用or，否则索引失效explain select * from teacher where tname ='' or tcid &gt;1 ; --将or左侧的tname 失效。 常见优化方法及慢查询SQL排查 exist和in select 。。from table where exist/in(子查询)； 如果主查询的数据集大，则使用In效率更高 如果子查询的数据集大，则使用exist效率更高 exist语法：将主查询的结果，放到子查询结果中进行条件校验（看子查询是否有数据，如果有数据，则校验成功，保留数据） order by using filesort 有两种算法：双路排序、单路排序 （根据IO的次数） MySQL4.1之前 默认使用 双路排序；双路：扫描2次磁盘（1：从磁盘读取排序字段 ,对排序字段进行排序（在buffer中进行的排序） 2：扫描其他字段 ） --IO较消耗性能 MySQL4.1之后 默认使用 单路排序 ： 只读取一次（全部字段），在buffer中进行排序。但种单路排序 会有一定的隐患 （不一定真的是“单路|1次IO”，有可能多次IO）。原因：如果数据量特别大，则无法 将所有字段的数据 一次性读取完毕，因此 会进行“分片读取、多次读取”。 注意：单路排序 比双路排序 会占用更多的buffer。 单路排序在使用时，如果数据大，可以考虑调大buffer的容量大小： set max_length_for_sort_data = 1024 单位byte 如果max_length_for_sort_data值太低，则mysql会自动从 单路-&gt;双路 （太低：需要排序的列的总大小超过了max_length_for_sort_data定义的字节数） 提高order by查询的策略： a.选择使用单路、双路 ；调整buffer的容量大小； b.避免select * ... （*会多花一些时间，且无法索引覆盖） c.复合索引 不要跨列使用 ，避免using filesort d.保证全部的排序字段 排序的一致性（都是升序 或 降序） 慢查询阀值和mysqldumpslow工具 :MySQL提供的一种日志记录，用于记录MySQL种响应时间超过阀值的SQL语句 （long_query_time，默认10秒） 慢查询日志默认是关闭的；建议：开发调优是 打开，而 最终部署时关闭。 检查是否开启了 慢查询日志 ： show variables like '%slow_query_log%' ; 临时开启： set global slow_query_log = 1 ; --在内存种开启 exit service mysql restart 永久开启： /etc/my.cnf 中追加配置： vi /etc/my.cnf [mysqld] slow_query_log=1 slow_query_log_file=/var/lib/mysql/localhost-slow.log ​ ​ 慢查询阀值： ​ show variables like '%long_query_time%' ; ​ ​ 临时设置阀值： ​ set global long_query_time = 5 ; --设置完毕后，重新登陆后起效 （不需要重启服务） ​ ​ 永久设置阀值： ​ ​ /etc/my.cnf 中追加配置： ​ vi /etc/my.cnf ​ [mysqld] ​ long_query_time=3 select sleep(4); select sleep(5); select sleep(3); select sleep(3); --查询超过阀值的SQL数量： show global status like '%slow_queries%' ; (1)慢查询的sql被记录在了日志中，因此可以通过日志 查看具体的慢SQL。 cat /var/lib/mysql/localhost-slow.log (2)通过mysqldumpslow工具查看慢SQL,可以通过一些过滤条件 快速查找出需要定位的慢SQL mysqldumpslow --help s：排序方式 r:逆序 l:锁定时间 g:正则匹配模式 --获取返回记录最多的3个SQL mysqldumpslow -s r -t 3 /var/lib/mysql/localhost-slow.log --获取访问次数最多的3个SQL mysqldumpslow -s c -t 3 /var/lib/mysql/localhost-slow.log --按照时间排序，前10条包含left join查询语句的SQL mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/localhost-slow.log 语法： mysqldumpslow 各种参数 慢查询日志的文件 模拟并通过profiles分析海量数据 a.模拟海量数据 a.模拟海量数据 存储过程（无return）/存储函数（有return） create database testdata ; use testdata 1234567891011121314151617create table dept(dno int(5) primary key default 0,dname varchar(20) not null default '',loc varchar(30) default '')engine=innodb default charset=utf8;create table emp(eid int(5) primary key,ename varchar(20) not null default '',job varchar(20) not null default '',deptno int(5) not null default 0)engine=innodb default charset=utf8; 通过存储函数 插入海量数据： 创建存储函数： randstring(6) -&gt;aXiayx 用于模拟员工名称 1234567891011121314delimiter $ #声明分号不是结束符create function randstring(n int) returns varchar(255) begin declare all_str varchar(100) default 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' ; declare return_str varchar(255) default '' ; declare i int default 0 ; while i&lt;n do set return_str = concat( return_str, substring(all_str, FLOOR(1+rand()*52) ,1) ); set i=i+1 ; end while ; return return_str; end $ --如果报错：You have an error in your SQL syntax，说明SQL语句语法有错，需要修改SQL语句； 如果报错This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you might want to use the less safe log_bin_trust_function_creators variable) 是因为 存储过程/存储函数在创建时 与之前的 开启慢查询日志冲突了 解决冲突： 临时解决( 开启log_bin_trust_function_creators ) show variables like '%log_bin_trust_function_creators%'; set global log_bin_trust_function_creators = 1; 永久解决： /etc/my.cnf [mysqld] log_bin_trust_function_creators = 1 12345678--产生随机整数create function ran_num() returns int(5)begin declare i int default 0; set i =floor( rand()*100 ) ; return i ;end $ 1234567891011121314--通过存储过程插入海量数据：emp表中 ， 10000, 100000create procedure insert_emp( in eid_start int(10),in data_times int(10))begin declare i int default 0; set autocommit = 0 ; repeat insert into emp values(eid_start + i, randstring(5) ,'other' ,ran_num()) ; set i=i+1 ; until i=data_times end repeat ; commit ;end $ 12345678910111213--通过存储过程插入海量数据：dept表中 create procedure insert_dept(in dno_start int(10) ,in data_times int(10)) begin declare i int default 0; set autocommit = 0 ; repeat insert into dept values(dno_start+i ,randstring(6),randstring(8)) ; set i=i+1 ; until i=data_times end repeat ; commit ; end$ 1234--插入数据 delimiter ; call insert_emp(1000,800000) ; call insert_dept(10,30) ; ​ b.分析海量数据: ​ （1）profiles ​ show profiles ; --默认关闭 ​ show variables like '%profiling%'; ​ set profiling = on ; ​ show profiles ：会记录所有profiling打开之后的 全部SQL查询语句所花费的时间。缺点：不够精确，只能看到 总共消费的时间，不能看到各个硬件消费的时间（cpu io ） ​ ​ (2)精确分析:sql诊断 ​ show profile all for query 上一步查询的的Query_Id ​ show profile cpu,block io for query 上一步查询的的Query_Id ​ ​ (3)全局查询日志 ：记录开启之后的 全部SQL语句。 （这次全局的记录操作 仅仅在调优、开发过程中打开即可，在最终的部署实施时 一定关闭） ​ show variables like '%general_log%'; ​ 12345678--执行的所有SQL记录在表中set global general_log = 1 ;--开启全局日志set global log_output='table' ; --设置 将全部的SQL 记录在表中--执行的所有SQL记录在文件中set global log_output='file' ;set global general_log = on ;set global general_log_file='/tmp/general.log' ; 12开启后，会记录所有SQL ： 会被记录 mysql.general_log表中。 select * from mysql.general_log ; 锁机制详解 锁机制 ：解决因资源共享 而造成的并发问题。 示例：买最后一件衣服X A: X 买 ： X加锁 -&gt;试衣服...下单..付款..打包 -&gt;X解锁 B: X 买：发现X已被加锁，等待X解锁， X已售空 分类： 操作类型： a.读锁（共享锁）： 对同一个数据（衣服），多个读操作可以同时进行，互不干扰。 b.写锁（互斥锁）： 如果当前写操作没有完毕（买衣服的一系列操作），则无法进行其他的读操作、写操作 操作范围： a.表锁 ：一次性对一张表整体加锁。如MyISAM存储引擎使用表锁，开销小、加锁快；无死锁；但锁的范围大，容易发生锁冲突、并发度低。 b.行锁 ：一次性对一条数据加锁。如InnoDB存储引擎使用行锁，开销大，加锁慢；容易出现死锁；锁的范围较小，不易发生锁冲突，并发度高（很小概率 发生高并发问题：脏读、幻读、不可重复度、丢失更新等问题）。 c.页锁 示例： （1）表锁 ： --自增操作 MYSQL/SQLSERVER 支持；oracle需要借助于序列来实现自增 create table tablelock ( id int primary key auto_increment , name varchar(20) )engine myisam; insert into tablelock(name) values('a1'); insert into tablelock(name) values('a2'); insert into tablelock(name) values('a3'); insert into tablelock(name) values('a4'); insert into tablelock(name) values('a5'); commit; 1234567891011121314151617181920212223增加锁：locak table 表1 read/write ,表2 read/write ,...查看加锁的表：show open tables ;会话：session :每一个访问数据的dos命令行、数据库客户端工具 都是一个会话===加读锁： 会话0： lock table tablelock read ; select * from tablelock; --读（查），可以 delete from tablelock where id =1 ; --写（增删改），不可以 select * from emp ; --读，不可以 delete from emp where eid = 1; --写，不可以 结论1： --如果某一个会话 对A表加了read锁，则 该会话 可以对A表进行读操作、不能进行写操作； 且 该会话不能对其他表进行读、写操作。 --即如果给A表加了读锁，则当前会话只能对A表进行读操作。 会话1（其他会话）： select * from tablelock; --读（查），可以 delete from tablelock where id =1 ; --写，会“等待”会话0将锁释放 会话1（其他会话）： select * from emp ; --读（查），可以 delete from emp where eno = 1; --写，可以 结论2： --总结： 会话0给A表加了锁；其他会话的操作：a.可以对其他表（A表以外的表）进行读、写操作 b.对A表：读-可以； 写-需要等待释放锁。 释放锁: unlock tables ; 写锁示例与MyISAM模式特征 ===加写锁： 会话0： lock table tablelock write ; 当前会话（会话0） 可以对加了写锁的表 进行任何操作（增删改查）；但是不能 操作（增删改查）其他表 其他会话： 对会话0中加写锁的表 可以进行增删改查的前提是：等待会话0释放写锁 MySQL表级锁的锁模式 MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁， 在执行更新操作（DML）前，会自动给涉及的表加写锁。 所以对MyISAM表进行操作，会有以下情况： a、对MyISAM表的读操作（加读锁），不会阻塞其他进程（会话）对同一表的读请求， 但会阻塞对同一表的写请求。只有当读锁释放后，才会执行其它进程的写操作。 b、对MyISAM表的写操作（加写锁），会阻塞其他进程（会话）对同一表的读和写操作， 只有当写锁释放后，才会执行其它进程的读写操作。 表锁情况分析及行锁解析 分析表锁定： 查看哪些表加了锁： show open tables ; 1代表被加了锁 分析表锁定的严重程度： show status like 'table%' ; Table_locks_immediate :立刻能获取到的锁数 Table_locks_waited：需要等待的表锁数(如果该值越大，说明存在越大的锁竞争) 一般建议： Table_locks_immediate/Table_locks_waited &gt; 5000， 建议采用InnoDB引擎，否则MyISAM引擎 ​ （2）行表（InnoDB） create table linelock( id int(5) primary key auto_increment, name varchar(20) )engine=innodb ; insert into linelock(name) values('1') ; insert into linelock(name) values('2') ; insert into linelock(name) values('3') ; insert into linelock(name) values('4') ; insert into linelock(name) values('5') ; --mysql默认自动commit; oracle默认不会自动commit ; 为了研究行锁，暂时将自动commit关闭; set autocommit =0 ; 以后需要通过commit 会话0： 写操作 insert into linelock values( 'a6') ; 会话1： 写操作 同样的数据 update linelock set name='ax' where id = 6; 对行锁情况： 1.如果会话x对某条数据a进行 DML操作（研究时：关闭了自动commit的情况下），则其他会话必须等待会话x结束事务(commit/rollback)后 才能对数据a进行操作。 2.表锁 是通过unlock tables，也可以通过事务解锁 ; 行锁 是通过事务解锁。 ​ 行锁，操作不同数据： 会话0： 写操作 insert into linelock values(8,'a8') ; 会话1： 写操作， 不同的数据 update linelock set name='ax' where id = 5; 行锁，一次锁一行数据；因此 如果操作的是不同数据，则不干扰。 行锁的注意事项及使用情况分析 ​ 行锁的注意事项： ​ a.如果没有索引，则行锁会转为表锁 ​ show index from linelock ; ​ alter table linelock add index idx_linelock_name(name); ​ 会话0： 写操作 ​ update linelock set name = 'ai' where name = '3' ; ​ ​ 会话1： 写操作， 不同的数据 ​ update linelock set name = 'aiX' where name = '4' ; ​ 会话0： 写操作 ​ update linelock set name = 'ai' where name = 3 ; ​ ​ 会话1： 写操作， 不同的数据 ​ update linelock set name = 'aiX' where name = 4 ; ​ ​ --可以发现，数据被阻塞了（加锁） ​ -- 原因：如果索引类 发生了类型转换，则索引失效。 因此 此次操作，会从行锁 转为表锁。 ​ ​ b.行锁的一种特殊情况：间隙锁：值在范围内，但却不存在 ​ --此时linelock表中 没有id=7的数据 ​ update linelock set name ='x' where id &gt;1 and id&lt;9 ; --即在此where范围中，没有id=7的数据，则id=7的数据成为间隙。 ​ 间隙：Mysql会自动给 间隙 加索 -&gt;间隙锁。即 本题 会自动给id=7的数据加 间隙锁（行锁）。 ​ 行锁：如果有where，则实际加索的范围 就是where后面的范围（不是实际的值） 查询行锁 ​ 如何仅仅是查询数据，能否加锁？ 可以 for update ​ 研究学习时，将自动提交关闭： ​ set autocommit =0 ; ​ start transaction ; ​ begin ; ​ select * from linelock where id =2 for update ; ​ ​ 通过for update对query语句进行加锁。 ​ ​ 行锁： ​ InnoDB默认采用行锁； ​ 缺点： 比表锁性能损耗大。 ​ 优点：并发能力强，效率高。 ​ 因此建议，高并发用InnoDB，否则用MyISAM。 ​ ​ 行锁分析： ​ show status like '%innodb_row_lock%' ; ​ Innodb_row_lock_current_waits :当前正在等待锁的数量 ​ Innodb_row_lock_time：等待总时长。从系统启到现在 一共等待的时间 ​ Innodb_row_lock_time_avg ：平均等待时长。从系统启到现在平均等待的时间 ​ Innodb_row_lock_time_max ：最大等待时长。从系统启到现在最大一次等待的时间 ​ Innodb_row_lock_waits ： 等待次数。从系统启到现在一共等待的次数 主从复制 （集群在数据库的一种实现） ​ windows:mysql 主 ​ linux:mysql从 安装windows版mysql: 如果之前计算机中安装过Mysql，要重新再安装 则需要：先卸载 再安装 先卸载： 通过电脑自带卸载工具卸载Mysql (电脑管家也可以) 删除一个mysql缓存文件C:\\ProgramData\\MySQL 删除注册表regedit中所有mysql相关配置 --重启计算机 安装MYSQL： 安装时，如果出现未响应： 则重新打开D:\\MySQL\\MySQL Server 5.5\\bin\\MySQLInstanceConfig.exe 图形化客户端： SQLyog, Navicat 如果要远程连接数据库，则需要授权远程访问。 授权远程访问 :(A-&gt;B,则再B计算机的Mysql中执行以下命令) GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION; FLUSH PRIVILEGES; 如果仍然报错：可能是防火墙没关闭 ： 在B关闭防火墙 service iptables stop 实现主从同步（主从复制）：图 1.master将改变的数 记录在本地的 二进制日志中（binary log） ；该过程 称之为：二进制日志件事 2.slave将master的binary log拷贝到自己的 relay log（中继日志文件）中 3.中继日志事件，将数据读取到自己的数据库之中 MYSQL主从复制 是异步的，串行化的， 有延迟 master:slave = 1:n 配置： windows(mysql: my.ini) linux(mysql: my.cnf) 配置前，为了无误，先将权限(远程访问)、防火墙等处理： 关闭windows/linux防火墙： windows：右键“网络” ,linux: service iptables stop Mysql允许远程连接(windowos/linux)： GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION; FLUSH PRIVILEGES; 主机（以下代码和操作 全部在主机windows中操作）： my.ini [mysqld] #id server-id=1 #二进制日志文件（注意是/ 不是\\） log-bin=&quot;D:/MySQL/MySQL Server 5.5/data/mysql-bin&quot; #错误记录文件 log-error=&quot;D:/MySQL/MySQL Server 5.5/data/mysql-error&quot; #主从同步时 忽略的数据库 binlog-ignore-db=mysql #(可选)指定主从同步时，同步哪些数据库 binlog-do-db=test windows中的数据库 授权哪台计算机中的数据库 是自己的从数据库： GRANT REPLICATION slave,reload,super ON . TO 'root'@'192.168.2.%' IDENTIFIED BY 'root'; flush privileges ; 查看主数据库的状态（每次在左主从同步前，需要观察 主机状态的最新值） show master status; （mysql-bin.000001、 107） 从机（以下代码和操作 全部在从机linux中操作）： my.cnf [mysqld] server-id=2 log-bin=mysql-bin replicate-do-db=test linux中的数据 授权哪台计算机中的数控 是自己的主计算机 CHANGE MASTER TO MASTER_HOST = '192.168.2.2', MASTER_USER = 'root', MASTER_PASSWORD = 'root', MASTER_PORT = 3306, master_log_file='mysql-bin.000001', master_log_pos=107; 如果报错：This operation cannot be performed with a running slave; run STOP SLAVE first 解决：STOP SLAVE ;再次执行上条授权语句 开启主从同步： 从机linux: start slave ; 检验 show slave status \\G 主要观察： Slave_IO_Running和 Slave_SQL_Running，确保二者都是yes；如果不都是yes，则看下方的 Last_IO_Error。 本次 通过 Last_IO_Error发现错误的原因是 主从使用了相同的server-id， 检查:在主从中分别查看serverid: show variables like 'server_id' ; 可以发现，在Linux中的my.cnf中设置了server-id=2，但实际执行时 确实server-id=1，原因：可能是 linux版Mysql的一个bug，也可能是 windows和Linux版本不一致造成的兼容性问题。 解决改bug： set global server_id =2 ; stop slave ; set global server_id =2 ; start slave ; show slave status \\G 演示： 主windows =&gt;从 windows: 将表，插入数据 观察从数据库中该表的数据 数据库+后端 spring boot（企业级框架,目前使用较多） 命令集合 mysql -u root -p 登录 show engines; 显示支持引擎 show variables like ‘%storage_engine%’; 查看当前使用引擎 12345678-- 指定数据库引擎create table tb(​ id int(4) auto_increment,​ name varchar(5),​ dept varchar(5),​ primary key(id))ENGINE=MyISAM AUTO_INCREMENT=1DEFAULT CHARSET=utf-8 MySQL基础 为什么要使用数据库 内存 优： 存取速度快；缺： 数据不能永久保存 文件 优： 数据永久保存；缺：1）速度比内存操作慢，频繁的IO操作 2）查询不方便 数据库 1）数据永久保存 2）使用SQL语句，查询方便效率高。3）管理数据方便 什么是SQL？ 结构化查询语言(Structured Query Language)，用于存取数据、查询、更新和管理关系数据库系统的数据库查询语言 什么是MySQL? 关系型数据库管理系统 数据库三大范式是什么 第一范式：每个列都不可以再拆分。 第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分。 第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。 在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。事实上我们经常会为了性能而妥协数据库的设计。 mysql有关权限的表都有哪几个 MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。下面分别介绍一下这些表的结构和内容： user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。 db权限表：记录各个帐号在各个数据库上的操作权限。 table_priv权限表：记录数据表级的操作权限。 columns_priv权限表：记录数据列级的操作权限。 host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。 MySQL的binlog有有几种录入格式？分别有什么区别？ 有三种格式，statement，row和mixed。 statement模式下，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。 row级别下，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。 mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。 此外，新版的MySQL中对row级别也做了一些优化，当表结构发生变化的时候，会记录语句而不是逐行记录。 执行顺序 ![desc](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image002.png) CREATE（drop，use） DATABASE 数据库名; CREATE TABLE IF NOT EXISTS runoob_tbl( runoob_id INT UNSIGNED AUTO_INCREMENT, runoob_title VARCHAR(100) NOT NULL, runoob_author VARCHAR(40) NOT NULL, submission_date DATE, PRIMARY KEY ( runoob_id ) )ENGINE=InnoDB DEFAULT CHARSET=utf8; · 增删改查 • INSERT INTO table_name ( field1, field2,...fieldN ) VALUES ( value1, value2,...valueN )， ( value11, value22,...valueNN ); • SELECT column_name,column_name FROM table_name [WHERE condition1 [AND [OR]] condition2 field1 LIKE condition1 [AND [OR]] filed2 = 'somevalue'][LIMIT N][ OFFSET M] 查询语句中你可以使用一个或者多个表，表之间使用逗号(,)分割，并使用WHERE语句来设定查询条件。 SELECT 命令可以读取一条或者多条记录。 你可以使用星号（*）来代替其他字段，SELECT语句会返回表的所有字段数据 你可以使用 WHERE 语句来包含任何条件，使用 AND 或者 OR 指定一个或多个条件。 你可以使用LIKE子句代替等号 =。- 代表单个，% 表示任意 0 个或多个字符。可匹配任意类型和长度的字符，有些情况下若是中文，请使用两个百分号（%%）表示。[]：表示括号内所列字符中的一个（类似正则表达式）。指定一个字符、字符串或范围，要求所匹配对象为它们中的任一个。[^] ：表示不在括号所列之内的单个字符。其取值和 [] 相同，但它要求所匹配对象为指定字符以外的任一个字符。 查询内容包含通配符时,由于通配符的缘故，导致我们查询特殊字符 “%”、“_”、“[” 的语句无法正常实现，而把特殊字符用 “[ ]” 括起便可正常查询。 你可以使用 LIMIT 属性来设定返回的记录数。 你可以通过OFFSET指定SELECT语句开始查询的数据偏移量。默认情况下偏移量为0。 • SELECT expression1, expression2, ... expression_n FROM tables [WHERE conditions] UNION [ALL | DISTINCT] SELECT expression1, expression2, ... expression_n FROM tables [WHERE conditions]; UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。多个 SELECT 语句会删除重复的数据。 expression1, expression2, ... expression_n: 要检索的列。 tables: 要检索的数据表。 WHERE conditions: 可选， 检索条件。 DISTINCT: 可选，删除结果集中重复的数据。默认情况下 UNION 操作符已经删除了重复数据，所以 DISTINCT 修饰符对结果没啥影响。 ALL: 可选，返回所有结果集，包含重复数据。 • SELECT field1, field2,...fieldN FROM table_name1, table_name2...ORDER BY field1 [ASC [DESC][默认 ASC]], [field2...] [ASC [DESC][默认 ASC]] • SELECT column_name, function(column_name) FROM table_name WHERE column_name operator value GROUP BY column_name; • 根据一个或多个列对结果集进行分组。 在分组的列上我们可以使用 COUNT, SUM, AVG,等函数。 WITH ROLLUP 可以实现在分组统计数据基础上再进行相同的统计（SUM,AVG,COUNT…） • 使用聚合函数后需要group by分组，having只能用于group by 后面 • INNER JOIN（内连接,或等值连接）【交集】：获取两个表中字段匹配关系的记录。 LEFT JOIN（左连接）【左交】：获取左表所有记录，即使右表没有对应匹配的记录。 RIGHT JOIN（右连接）【左交】： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。 • select p.id,p.name,t.content from person p left join task t on p.id=t.person_id order by p.id • UPDATE table_name SET field1=new-value1, field2=new-value2 [WHERE Clause] 你可以同时更新一个或多个字段。 你可以在 WHERE 子句中指定任何条件。 你可以在一个单独表中同时更新数据。 • update titles_test set emp_no=replace(emp_no,'10001','10005') where id=5 • DELETE FROM table_name [WHERE Clause] 如果没有指定 WHERE 子句，MySQL 表中的所有记录将被删除。 你可以在 WHERE 子句中指定任何条件 您可以在单个表中一次性删除记录。 DROP TABLE table_name ; ALTER TABLE table_name DROP i; ADD i INT ; 删除，添加或修改表字段 MODIFY c CHAR(10) ; CHANGE i j BIGINT; 修改字段类型及名称 ALTER i SET DEFAULT 1000; ALTER i DROP DEFAULT; 修改,删除字段的默认值 ALTER TABLE testalter_tbl RENAME TO alter_tbl;改表名 · 表中只剩余一个字段则无法使用DROP来删除字段 数据类型 引擎 MySQL存储引擎MyISAM与InnoDB区别 存储引擎 Storage engine：MySQL 中的数据、索引以及其他对象是如何存储的，是一套文件系统的实现。 MyISAM索引与InnoDB索引的区别？ Innodb 引擎：Innodb 引擎提供了对数据库 ACID 事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。 MyIASM 引擎 (原本 Mysql 的默认引擎)：不提供事务的支持，也不支持行级锁和外键。 MEMORY 引擎：所有的数据都在内存中，数据的处理速度快，但是安全性不高。 InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引。 InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效。 MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。 InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。 InnoDB引擎的4大特性 插入缓冲（insert buffer) 二次写 (double write) 自适应哈希索引 (ahi) 预读 (read ahead) 存储引擎选择 如果没有特别的需求，使用默认的Innodb即可。 MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。 Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。比如 OA 自动化办公系统。 索引 什么是索引？ 索引是一种特殊的文件 (InnoDB 数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。 索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用 B 树及其变种 B + 树。 更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，它是要占据物理空间的。 索引有哪些优缺点？ 优 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 缺 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增 / 改 / 删的执行效率； 空间方面：索引需要占物理空间 索引使用场景（重点） where 可以尝试在一个字段未建立索引时，根据该字段查询的效率，然后对该字段建立索引（alter table 表名 add index(字段名)），同样的 SQL 执行的效率，你会发现查询效率会有明显的提升（数据量越大越明显）。 order by 使用order by将查询结果按照某个字段排序时，如果该字段没有建立索引，那么执行计划会将查询出的所有数据使用外部排序（将数据从硬盘分批读取到内存使用内部排序，最后合并排序结果），这操作很影响性能的，因为需要将查询涉及到的所有数据从磁盘中读到内存（如果单条数据过大或者数据量过多都会降低效率），更无论读到内存之后的排序了。 但是如果我们对该字段建立索引alter table 表名 add index(字段名)，那么由于索引本身是有序的，因此直接按照索引的顺序和映射关系逐条取出数据即可。而且如果分页的，那么只用取出索引表某个范围内的索引对应的数据，而不用像上述那取出所有数据进行排序再返回某个范围内的数据。（从磁盘取数据是最影响性能的） join 对join语句匹配关系（on）涉及的字段建立索引能够提高效率 索引覆盖 如果要查询的字段都建立过索引，那么引擎会直接在索引表中查询而不会访问原始数据（否则只要有一个字段没有建立索引就会做全表扫描），这叫索引覆盖。因此我们需要尽可能的在select后只写必要的查询字段，以增加索引覆盖的几率。 这里值得注意的是不要想着为每个字段建立索引，因为优先使用索引的优势就在于其体积小。 索引有哪几种类型？ 1）从存储结构上来划分 · Btree 索引（B+tree，B-tree) · 哈希索引 · full-index 全文索引 · RTree 2）从应用层次上来划分 · 普通索引: 基本的索引类型，没有唯一性的限制，允许为 NULL 值。 CREATE INDEX indexName ON table_name (column_name)或 ALTER TABLE table_name ADD INDEX index_name (column);创建普通索引 ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3);创建组合索引 • ALTER TABLE testalter_tbl ADD/DROP INDEX (c); · 唯一索引: 数据列不允许重复，允许为 NULL 值，一个表允许多个列创建唯一索引。 可以通过 ALTER TABLE table_name ADD UNIQUE (column); 创建唯一索引 可以通过 ALTER TABLE table_name ADD UNIQUE (column1,column2); 创建唯一组合索引 · 主键索引: 数据列不允许重复，不允许为 NULL，一个表只能有一个主键。 ALTER TABLE table_name ADD PRIMARY KEY ( column ) 3）从表记录的排列顺序和索引的排列顺序是否一致来划分 · **聚集索引：**表记录的排列顺序和索引的排列顺序一致。 • 就是以主键创建的索引。 · **非聚集索引：**表记录的排列顺序和索引的排列顺序不一致。 • 以非主键创建的索引（也叫做二级索引）。 索引的数据结构（b树，hash） 我们经常使用的 InnoDB 存储引擎的默认索引实现为：B + 树索引。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择 BTree 索引。 B 树索引 · mysql 通过存储引擎取数据，基本上 90% 的人用的就是 InnoDB 了，按照实现方式分，InnoDB 的索引类型目前只有两种：BTREE（B 树）索引和 HASH 索引。B 树索引是 Mysql 数据库中使用最频繁的索引类型，基本所有存储引擎都支持 BTree 索引。通常我们说的索引不出意外指的就是（B 树）索引（实际是用 B + 树实现的，因为在查看表索引时，mysql 一律打印 BTREE，所以简称为 B 树索引） • 查询方式： 主键索引区: PI(关联保存的时数据的地址) 按主键查询, 普通索引区: si(关联的 id 的地址, 然后再到达上面的地址)。所以按主键查询, 速度最快 B+tree 性质： 1.）n 棵子 tree 的节点包含 n 个关键字，不用来保存数据而是保存数据的索引。 2.）所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 3.）所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。 4.）B+ 树中，数据对象的插入和删除仅在叶节点上进行。 5.）B + 树有 2 个头指针，一个是树的根节点，一个是最小关键码的叶节点。 哈希索引 ![desc](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image008.png) 简要说下，类似于数据结构中简单实现的 HASH 表（散列表）一样，当我们在 mysql 中用哈希索引时，主要就是通过 Hash 算法（常见的 Hash 算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的 Hash 值，与这条数据的行指针一并存入 Hash 表的对应位置；如果发生 Hash 碰撞（两个不同关键字的 Hash 值相同），则在对应 Hash 键下以链表形式存储。当然这只是简略模拟图。 索引的基本原理 索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。 索引的原理很简单，就是把无序的数据变成有序的查询 把创建了索引的列的内容进行排序 对排序结果生成倒排表 在倒排表内容上拼上数据地址链 在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据 索引算法有哪些？ BTree 算法 BTree 是最常用的 mysql 数据库索引算法，也是 mysql 默认的算法。因为它不仅可以被用在 =,&gt;,&gt;=,&lt;,&lt;= 和 between 这些比较操作符上，而且还可以用于 like 操作符，只要它的查询条件是一个不以通配符开头的常量， 例如： -- 只要它的查询条件是一个不以通配符开头的常量 select * from user where name like 'jack%'; -- 如果一通配符开头，或者没有使用常量，则不会使用索引，例如： select * from user where name like '%jack'; Hash 算法 Hash Hash 索引只能用于对等比较，例如 =,&lt;=&gt;（相当于 =）操作符。由于是一次定位数据，不像 BTree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次 IO 访问，所以检索效率远高于 BTree 索引。 索引设计的原则？ 适合索引的列是出现在 where 子句中的列，或者连接子句中指定的列 基数较小的类，索引效果较差，没有必要在此列建立索引 使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间 不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可。 创建索引的原则（重中之重） 索引虽好，但也不是无限制的使用，最好符合一下几个原则 1） 最左前缀匹配原则，组合索引非常重要的原则，mysql 会一直向右匹配直到遇到范围查询 (&gt;、&lt;、between、like) 就停止匹配，比如 a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立 (a,b,c,d) 顺序的索引，d 是用不到索引的，如果建立 (a,b,d,c) 的索引则都可以用到，a,b,d 的顺序可以任意调整。 2）较频繁作为查询条件的字段才去创建索引 3）更新频繁字段不适合创建索引 4）若是不能有效区分数据的列不适合做索引列 (如性别，男女未知，最多也就三种，区分度实在太低) 5）尽量的扩展索引，不要新建索引。比如表中已经有 a 的索引，现在要加 (a,b) 的索引，那么只需要修改原来的索引即可。 6）定义有外键的数据列一定要建立索引。 7）对于那些查询中很少涉及的列，重复值比较多的列不要建立索引。 8）对于定义为 text、image 和 bit 的数据类型的列不要建立索引。 创建索引的三种方式，删除索引 第一种方式：在执行 CREATE TABLE 时创建索引 CREATE TABLE user_index2 ( id INT auto_increment PRIMARY KEY, first_name VARCHAR (16), last_name VARCHAR (16), id_card VARCHAR (18), information text, KEY name (first_name, last_name), FULLTEXT KEY (information), UNIQUE KEY (id_card) ); 第二种方式：使用 ALTER TABLE 命令去增加索引 ALTER TABLE table_name ADD INDEX index_name (column_list); ALTER TABLE 用来创建普通索引、UNIQUE 索引或 PRIMARY KEY 索引。 其中 table_name 是要增加索引的表名，column_list 指出对哪些列进行索引，多列时各列之间用逗号分隔。 索引名 index_name 可自己命名，缺省时，MySQL 将根据第一个索引列赋一个名称。另外，ALTER TABLE 允许在单个语句中更改多个表，因此可以在同时创建多个索引。 第三种方式：使用 CREATE INDEX 命令创建 CREATE INDEX index_name ON table_name (column_list); CREATE INDEX 可对表增加普通索引或 UNIQUE 索引。（但是，不能创建 PRIMARY KEY 索引） 删除索引 根据索引名删除普通索引、唯一索引、全文索引：alter table 表名 drop KEY 索引名 alter table user_index drop KEY name; alter table user_index drop KEY id_card; alter table user_index drop KEY information; 删除主键索引：alter table 表名 drop primary key（因为主键只有一个）。这里值得注意的是，如果主键自增长，那么不能直接执行此操作（自增长依赖于主键索引）： 需要取消自增长再行删除： alter table user_index -- 重新定义字段 MODIFY id int, drop PRIMARY KEY 但通常不会删除主键，因为设计主键一定与业务逻辑无关。 ![desc](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image010.png) 创建索引时需要注意什么？ 非空字段：应该指定列为 NOT NULL，除非你想存储 NULL。在 mysql 中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用 0、一个特殊的值或者一个空串代替空值； 取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过 count() 函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高； 索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次 IO 操作获取的数据越大效率越高。 使用索引查询一定能提高查询的性能吗？为什么 通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。 索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。 这意味着每条记录的 INSERT，DELETE，UPDATE 将为此多付出 4，5 次的磁盘 I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询 (INDEX RANGE SCAN) 适用于两种情况: 基于一个范围的检索，一般查询返回结果集小于表中记录数的 30% 基于非唯一性索引的检索 百万级别或以上的数据如何删除 关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件, 所以当我们对数据的增加, 修改, 删除, 都会产生额外的对索引文件的操作, 这些操作需要消耗额外的 IO, 会降低增 / 改 / 删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询 MySQL 官方手册得知删除数据的速度和创建的索引数量是成正比的。 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟） 然后删除其中无用数据（此过程需要不到两分钟） 删除完成后重新创建索引 (此时数据较少了) 创建索引也非常快，约十分钟左右。 与之前的直接删除绝对是要快速很多，更别说万一删除中断, 一切删除会回滚。那更是坑了。 前缀索引 语法：index(field(10))，使用字段值的前 10 个字符建立索引，默认是使用字段的全部内容建立索引。 前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。 实操的难度：在于前缀截取的长度。 我们可以利用select count(*)/count(distinct left(password,prefixLen));，通过从调整prefixLen的值（从 1 自增）查看不同前缀长度的一个平均匹配度，接近 1 时就可以了（表示一个密码的前prefixLen个字符几乎能确定唯一一条记录） 什么是最左前缀原则？什么是最左匹配原则 顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where 子句中使用最频繁的一列放在最左边。 最左前缀匹配原则，非常重要的原则，mysql 会一直向右匹配直到遇到范围查询 (&gt;、&lt;、between、like) 就停止匹配，比如 a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立 (a,b,c,d) 顺序的索引，d 是用不到索引的，如果建立 (a,b,d,c) 的索引则都可以用到，a,b,d 的顺序可以任意调整。 = 和 in 可以乱序，比如 a = 1 and b = 2 and c = 3 建立 (a,b,c) 索引可以任意顺序，mysql 的查询优化器会帮你优化成索引可以识别的形式 B树和B+树的区别 在 B 树中，你可以将键和值存放在内部节点和叶子节点；但在 B + 树中，内部节点都是键，没有值，叶子节点同时存放键和值。 B + 树的叶子节点有一条链相连，而 B 树的叶子节点各自独立。 · ![desc](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image012.png) 使用B树的好处 B 树可以在内部节点同时存储键和值，因此，把频繁访问的数据放在靠近根节点的地方将会大大提高热点数据的查询效率。这种特性使得 B 树在特定数据重复多次查询的场景中更加高效。 使用B+树的好处 由于 B + 树的内部节点只存放键，不存放值，因此，一次读取，可以在内存页中获取更多的键，有利于更快地缩小查找范围。 B + 树的叶节点由一条链相连，因此，当需要进行一次全数据遍历的时候，B + 树只需要使用 O(logN) 时间找到最小的一个节点，然后通过链进行 O(N) 的顺序遍历即可。而 B 树则需要对树的每一层进行遍历，这会需要更多的内存置换次数，因此也就需要花费更多的时间 Hash索引和B+树所有有什么区别或者说优劣呢? 首先要知道 Hash 索引和 B + 树索引的底层实现原理： hash 索引底层就是 hash 表，进行查找时，调用一次 hash 函数就可以获取到相应的键值，之后进行回表查询获得实际数据。B + 树底层实现是多路平衡查找树。对于每一次的查询都是从根节点出发，查找到叶子节点方可以获得所查键值，然后根据查询判断是否需要回表查询数据。 那么可以看出他们有以下的不同： hash 索引进行等值查询更快 (一般情况下)，但是却无法进行范围查询。 因为在 hash 索引中经过 hash 函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。而 B + 树的的所有节点皆遵循 (左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。 hash 索引不支持使用索引进行排序，原理同上。 hash 索引不支持模糊查询以及多列索引的最左前缀匹配。原理也是因为 hash 函数的不可预测。AAAA 和 AAAAB 的索引没有相关性。 hash 索引任何时候都避免不了回表查询数据，而 B + 树在符合某些条件 (聚簇索引，覆盖索引等) 的时候可以只通过索引完成查询。 hash 索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生 hash 碰撞，此时效率可能极差。而 B + 树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。 因此，在大多数情况下，直接选择 B + 树索引可以获得稳定且较好的查询速度。而不需要使用 hash 索引。 数据库为什么使用B+树而不是B树 B 树只适合随机检索，而 B + 树同时支持随机检索和顺序检索； B + 树空间利用率更高，可减少 I/O 次数，磁盘读写代价更低。一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘 I/O 消耗。B + 树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比 B 树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO 读写次数也就降低了。而 IO 读写次数是影响索引检索效率的最大因素； B + 树的查询效率更加稳定。B 树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在 B + 树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。 B - 树在提高了磁盘 IO 性能的同时并没有解决元素遍历的效率低下的问题。B + 树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而 B 树不支持这样的操作。 增删文件（节点）时，效率更高。因为 B + 树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。 B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据， 在 B + 树的索引中，叶子节点可能存储了当前的 key 值，也可能存储了当前的 key 值以及整行的数据，这就是聚簇索引和非聚簇索引。 在 InnoDB 中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。 当查询使用聚簇索引时，在对应的叶子节点，可以获取到整行数据，因此不用再次进行回表查询。 什么是聚簇索引？何时使用聚簇索引与非聚簇索引 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam 通过 key_buffer 把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在 key buffer 命中时，速度慢的原因 澄清一个概念：innodb 中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值 何时使用聚簇索引与非聚簇索引 · ![desc](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image014.png) 非聚簇索引一定会回表查询吗？ 不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。 举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age &lt; 20的查询时，在索引的叶子节点上，已经包含了 age 信息，不会再次进行回表查询。 联合索引是什么？为什么需要注意联合索引中的顺序？ MySQL 可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。 具体原因为: MySQL 使用索引时需要索引有序，假设现在建立了 &quot;name，age，school&quot; 的联合索引，那么索引的排序为: 先按照 name 排序，如果 name 相同，则按照 age 排序，如果 age 的值也相等，则按照 school 进行排序。 当进行查询时，此时索引仅仅按照 name 严格有序，因此必须首先使用 name 字段进行等值查询，之后对于匹配到的列而言，其按照 age 字段严格有序，此时可以使用 age 字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。 事务 什么是数据库事务？ 1、用 BEGIN, ROLLBACK, COMMIT来实现 BEGIN 开始一个事务 ROLLBACK 事务回滚 COMMIT 事务确认 2、直接用 SET 来改变 MySQL 的自动提交模式: SET AUTOCOMMIT=0 禁止自动提交 SET AUTOCOMMIT=1 开启自动提交 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 事物的四大特性(ACID)介绍一下? **原子性：**一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 **一致性：**在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 **隔离性：**数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 **持久性：**事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 什么是脏读？幻读？不可重复读？ 什么是事务的隔离级别？MySQL的默认隔离级别是什么？ 锁 对MySQL的锁了解吗 隔离级别与锁的关系 按照锁的粒度分数据库锁有哪些？锁机制与InnoDB锁算法 从锁的类别上分MySQL都有哪些锁呢？像上面那样子进行锁定岂不是有点阻碍并发效率了 MySQL中InnoDB引擎的行锁是怎么实现的？ InnoDB存储引擎的锁的算法有三种 什么是死锁？怎么解决？ 数据库的乐观锁和悲观锁是什么？怎么实现的？ 视图 为什么要使用视图？什么是视图？ 视图有哪些特点？ 视图的使用场景有哪些？ 视图的优点 视图的缺点 什么是游标？ 存储过程与函数 什么是存储过程？有哪些优缺点？ 触发器 什么是触发器？触发器的使用场景有哪些？ MySQL中都有哪些触发器？ 常用SQL语句 SQL语句主要分为哪几类 **数据定义语言 DDL（Data Ddefinition Language）**CREATE，DROP，ALTER 对逻辑结构等有操作的，其中包括表结构，视图和索引。 数据查询语言 DQL（Data Query Language）SELECT 查询操作，以 select 关键字。简单查询，连接查询等 都属于 DQL。 **数据操纵语言 DML（Data Manipulation Language）**INSERT，UPDATE，DELETE 数据操作，对应上面所说的查询操作 DQL 与 DML 共同构建了多数初级程序员常用的增删改查操作。查询较为特殊划分到 DQL 中。 **数据控制功能 DCL（Data Control Language）**GRANT，REVOKE，COMMIT，ROLLBACK 对数据库安全性完整性等有操作的，权限控制等 DQMC 超键、候选键、主键、外键分别是什么？ 超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。 候选键：是最小超键，即没有冗余元素的超键。 主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。 外键：在一个表中存在的另一个表的主键称此表的外键。 SQL 约束有哪几种？ NOT NULL: 用于控制字段的内容一定不能为空（NULL）。 UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。 PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。 FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。 CHECK: 用于控制字段的值范围。 六种关联查询 交叉连接（CROSS JOIN） 内连接（INNER JOIN） 外连接（LEFT JOIN/RIGHT JOIN） 联合查询（UNION 与 UNION ALL） 全连接（FULL JOIN） · 交叉连接（CROSS JOIN） SELECT * FROM A,B(,C)或者SELECT * FROM A CROSS JOIN B (CROSS JOIN C)#没有任何关联条件，结果是笛卡尔积，结果集会很大，没有意义，很少使用内连接（INNER JOIN）SELECT * FROM A,B WHERE A.id=B.id或者SELECT * FROM A INNER JOIN B ON A.id=B.id多表中同时符合某种条件的数据记录的集合，INNER JOIN可以缩写为JOIN · 内连接分为三类 等值连接：ON A.id=B.id 不等值连接：ON A.id &gt; B.id 自连接：SELECT * FROM A T1 INNER JOIN A T2 ON T1.id=T2.pid · 外连接（LEFT JOIN/RIGHT JOIN） 左外连接：LEFT OUTER JOIN, 以左表为主，先查询出左表，按照 ON 后的关联条件匹配右表，没有匹配到的用 NULL 填充，可以简写成 LEFT JOIN 右外连接：RIGHT OUTER JOIN, 以右表为主，先查询出右表，按照 ON 后的关联条件匹配左表，没有匹配到的用 NULL 填充，可以简写成 RIGHT JOIN · 联合查询（UNION 与 UNION ALL） SELECT * FROM A UNION SELECT * FROM B UNION ... 就是把多个结果集集中在一起，UNION 前的结果为基准，需要注意的是联合查询的列数要相等，相同的记录行会合并 如果使用 UNION ALL，不会合并重复的记录行 效率 UNION 高于 UNION ALL · 全连接（FULL JOIN） MySQL 不支持全连接 可以使用 LEFT JOIN 和 UNION 和 RIGHT JOIN 联合使用 SELECT * FROM A LEFT JOIN B ON A.id=B.id UNIONSELECT * FROM A RIGHT JOIN B ON A.id=B.id 什么是子查询 条件：一条 SQL 语句的查询结果做为另一条查询语句的条件或查询结果 嵌套：多条 SQL 语句嵌套使用，内部的 SQL 查询语句称为子查询。 子查询的三种情况 子查询是单行单列的情况：结果集是一个值，父查询使用：=、 &lt;、&gt; 等运算符 -- 查询工资最高的员工是谁？ select * from employee where salary=(select max(salary) from employee); 子查询是多行单列的情况：结果集类似于一个数组，父查询使用：in 运算符 -- 查询工资最高的员工是谁？ select * from employee where salary=(select max(salary) from employee); 子查询是多行多列的情况：结果集类似于一张虚拟表，不能用于 where 条件，用于 select 子句中做为子表 -- 1) 查询出2011年以后入职的员工信息 -- 2) 查询所有的部门信息，与上面的虚拟表中的信息比对，找出所有部门ID相等的员工。 select * from dept d, (select * from employee where join_date &gt; '2011-1-1') e where e.dept_id = d.id; -- 使用表连接： select d., e. from dept d inner join employee e on d.id = e.dept_id where e.join_date &gt; '2011-1-1' mysql中 in 和 exists 区别 mysql 中的 in 语句是把外表和内表作 hash 连接，而 exists 语句是对外表作 loop 循环，每次 loop 循环再对内表进行查询。一直大家都认为 exists 比 in 语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。 如果查询的两个表大小相当，那么用 in 和 exists 差别不大。 如果两个表中一个较小，一个是大表，则子查询表大的用 exists，子查询表小的用 in。 not in 和 not exists：如果查询语句使用了 not in，那么内外表都进行全表扫描，没有用到索引；而 not extsts 的子查询依然能用到表上的索引。所以无论那个表大，用 not exists 都比 not in 要快。 varchar与char的区别 char 的特点 char 表示定长字符串，长度是固定的； 如果插入数据的长度小于 char 的固定长度时，则用空格填充； 因为长度固定，所以存取速度要比 varchar 快很多，甚至能快 50%，但正因为其长度固定，所以会占据多余的空间，是空间换时间的做法； 对于 char 来说，最多能存放的字符个数为 255，和编码无关 varchar 的特点 varchar 表示可变长字符串，长度是可变的； 插入的数据是多长，就按照多长来存储； varchar 在存取方面与 char 相反，它存取慢，因为长度不固定，但正因如此，不占据多余的空间，是时间换空间的做法； 对于 varchar 来说，最多能存放的字符个数为 65532 总之，结合性能角度（char 更快）和节省磁盘空间角度（varchar 更小），具体情况还需具体来设计数据库才是妥当的做法。 varchar(50)中50的涵义 最多存放 50 个字符，varchar(50)和 (200) 存储 hello 所占空间一样，但后者在排序时会消耗更多内存，因为 order by col 采用 fixed_length 计算 col 长度(memory 引擎也一样)。在早期 MySQL 版本中， 50 代表字节数，现在代表字符数。 int(20)中20的涵义 是指显示字符的长度。20 表示最大显示宽度为 20，但仍占 4 字节存储，存储范围不变； 不影响内部存储，只是影响带 zerofill 定义的 int 时，前面补多少个 0，易于报表展示 mysql为什么这么设计 对大多数应用没有意义，只是规定一些工具用来显示字符的个数；int(1) 和 int(20) 存储和计算均一样； mysql中int(10)和char(10)以及varchar(10)的区别 int(10) 的 10 表示显示的数据的长度，不是存储数据的大小；chart(10) 和 varchar(10) 的 10 表示存储数据的大小，即表示存储多少个字符。 int(10) 10 位的数据长度 9999999999，占 32 个字节，int 型 4 位 char(10) 10 位固定字符串，不足补空格 最多 10 个字符 varchar(10) 10 位可变字符串，不足补空格 最多 10 个字符 char(10) 表示存储定长的 10 个字符，不足 10 个就用空格补齐，占用更多的存储空间 varchar(10) 表示存储 10 个变长的字符，存储多少个就是多少个，空格也按一个字符存储，这一点是和 char(10) 的空格不同的，char(10) 的空格表示占位不算一个字符 FLOAT和DOUBLE的区别是什么？ FLOAT 类型数据可以存储至多 8 位十进制数，并在内存中占 4 字节。 DOUBLE 类型数据可以存储至多 18 位十进制数，并在内存中占 8 字节。 drop、delete与truncate的区别 ​ Delete Truncate Drop 类型 属于 DML 属于 DDL 属于 DDL 回滚 可回滚 不可回滚 不可回滚 删除内容 表结构还在，删除表的全部或者一部分数据行 表结构还在，删除表中的所有数据 从数据库中删除表，所有的数据行，索引和权限也会被删除 删除速度 删除速度慢，需要逐行删除 删除速度快 删除速度最快 因此，在不再需要一张表的时候，用 drop；在想删除部分数据行时候，用 delete；在保留表而删除所有数据的时候用 truncate。 UNION与UNION ALL的区别？ 如果使用 UNION ALL，不会合并重复的记录行 效率 UNION 高于 UNION ALL SQL优化 如何定位及优化SQL语句的性能问题？创建的索引有没有被使用到?或者说怎么才可以知道这条语句运行很慢的原因？ SQL的生命周期？ 大表数据查询，怎么优化 超大分页怎么处理？ mysql 分页 慢查询日志 关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？ 为什么要尽量设定一个主键？ 主键使用自增ID还是UUID？ 字段为什么要求定义为not null？ 如果要存储用户的密码散列，应该使用什么字段进行存储？ 优化查询过程中的数据访问 优化长难的查询语句 优化特定类型的查询语句 优化关联查询 优化子查询 优化LIMIT分页 优化UNION查询 优化WHERE子句 数据库优化 为什么要优化 数据库结构优化 MySQL数据库cpu飙升到500%的话怎么处理？ 大表怎么优化？某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？ 垂直分表 适用场景 缺点 水平分表： 适用场景 水平切分的缺点 MySQL的复制原理以及流程 读写分离有哪些解决方案？ 备份计划，mysqldump以及xtranbackup的实现原理 数据表损坏的修复方式有哪些？ 常用语句 distinct字段去重 group by 。。having not in concat(last_name,' ',first_name) replace update titles_test set emp_no=replace(emp_no,'10001','10005') where id=5 alter table titles_test rename to titles_2017 round(avg(score),3) 全文索引： 是目前搜索引擎使用的一种关键技术。 可以通过ALTER TABLE table_name ADD FULLTEXT (column);创建全文索引 Postgres 查询字段备注 12select a.attnum,a.attname,concat_ws('',t.typname,SUBSTRING(format_type(a.atttypid,a.atttypmod) from '\\(.*\\)')) as type,d.description from pg_class c,pg_attribute a,pg_type t,pg_description dwhere c.relname='com_capture' and a.attnum&gt;0 and a.attrelid=c.oid and a.atttypid=t.oid and d.objoid=a.attrelid and d.objsubid=a.attnum; 取geom数据 12select st_astext(geom) from ttt # test形式SELECT st_asgeojson(geom) FROM &quot;ygjcgd&quot; # geojson形式 存geom 12点INSERT into ttt values ('1',ST_GeomFromText('POINT(119.104393005 29.3091735840001)',4490))面INSERT into ttt values ('2',ST_GeomFromText('POLYGON((120.489420304 30.2855081450001,120.48927819 30.2855092200001,120.489034534 30.2855205130001,120.488415416 30.2855540510001,120.488238647 30.285563627,120.487775051 30.2856122420001,120.487543209 30.2856365540001,120.48696129 30.28571928,120.486939727 30.285722842,120.486661766 30.2857687420001,120.48676176 30.2859599880001,120.486786439 30.2860551310001,120.486803289 30.286632664,120.487353662 30.2866268860001,120.487351682 30.2864715210001,120.487351632 30.286467605,120.487350721 30.2863964210001,120.487346937 30.2860998030001,120.487342737 30.285770433,120.487400427 30.2857633680001,120.487405079 30.285760184,120.48740623 30.285961001,120.487409165 30.2864727900001,120.487409564 30.286542108,120.487409728 30.2865708910001,120.487410051 30.2866269530001,120.487415064 30.2866269360001,120.487781689 30.2866291820001,120.488148313 30.286631426,120.488229104 30.286631782,120.488646675 30.2866336280001,120.488672652 30.2866335310001,120.489108909 30.286635501,120.489545164 30.286637469,120.489554908 30.2866377670001,120.489587466 30.2866073650001,120.489631665 30.286574779,120.489633218 30.2865468840001,120.489635952 30.286497766,120.489630193 30.2864750590001,120.489620367 30.286436291,120.489576415 30.2862629480001,120.489538252 30.286111927,120.489518579 30.286034075,120.489490667 30.2859208350001,120.489445946 30.285699532,120.489442796 30.285683949,120.489435137 30.2856060400001,120.489420304 30.2855081450001))',4490)) 上好例题 单输入，多字段查询 123&lt;if test=&quot;text!=null and text!=''&quot;&gt; and CONCAT(t.city,t.bh,t.cun,t.jsztmc,t.xmxmmc) like concat ('%',#{text},'%')&lt;/if&gt;","link":"/2022/02/24/Draft/2021/MYSQL%E4%BC%98%E5%8C%96/"},{"title":"Python 学习","text":"Python3学习 简介 Python is powerful... and fast; plays well with others; runs everywhere; is friendly &amp; easy to learn; is Open. Python 发展历史 Python 特点 Python 应用 工具 开发平台：PYCharm 语法基础 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719'''=============基本语法============='''import keyword# from modname import name1[, name2[, ... nameN]]# Python 提供了一个办法，把这些定义存放在文件中，为一些脚本或者交互式的解释器实例使用，这个文件被称为模块。# 模块是一个包含所有你定义的函数和变量的文件，其后缀名是.py。模块可以被别的程序引入，以使用该模块中的函数等功能。这也是使用 python 标准库的方法。# 从某个模块中导入多个函数,格式为： from somemodule import firstfunc, secondfunc, thirdfunc# ====__name__属性====# 一个模块被另一个程序第一次引入时，其主程序将运行。如果我们想在模块被引入时，模块中的某一程序块不执行，我们可以用__name__属性来使该程序块仅在该模块自身运行时执行。# #!/usr/bin/python3# # Filename: using_name.py# if __name__ == '__main__':# print('程序自身在运行')# else:# print('我来自另一模块')# ====dir() 函数====# 内置的函数 dir() 可以找到模块内定义的所有名称。以一个字符串列表的形式返回:'''输入和输出'''# Python两种输出值的方式: 表达式语句和 print() 函数。# 第三种方式是使用文件对象的 write() 方法，标准输出文件可以用 sys.stdout 引用。# 如果你希望输出的形式更加多样，可以使用 str.format() 函数来格式化输出值。# 如果你希望将输出的值转成字符串，可以使用 repr() 或 str() 函数来实现。# str()： 函数返回一个用户易读的表达形式。# repr()： 产生一个解释器易读的表达形式。print(&quot;Hello word!&quot;)print('{}网址： &quot;{}!&quot;'.format('菜鸟教程', 'www.runoob.com'))print('{0} 和 {1}'.format('Google', 'Runoob'))print('站点列表 {0}, {1}, 和 {other}。'.format('Google', 'Runoob', other='Taobao'))# 读取键盘输入str = input(&quot;请输入：&quot;);print (&quot;你输入的内容是: &quot;, str)# 读和写文件# open(filename, mode)# filename：包含了你要访问的文件名称的字符串值。# mode：决定了打开文件的模式：只读，写入，追加等。所有可取值见如下的完全列表。这个参数是非强制的，默认文件访问模式为只读(r)。# 模式 描述# r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。# rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。# r+ 打开一个文件用于读写。文件指针将会放在文件的开头。# rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。# w 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。# wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。# w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。# wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。# a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。# ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。# a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。# ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。# 打开一个文件f = open(&quot;/tmp/foo.txt&quot;, &quot;w&quot;)f.write( &quot;Python 是一个非常好的语言。\\n是的，的确非常好!!\\n&quot; )# f.read(size), 这将读取一定数目的数据, 然后作为字符串或字节对象返回。size 是一个可选的数字类型的参数。 当 size 被忽略了或者为负, 那么该文件的所有内容都将被读取并且返回。print(f.read())# 返回一个空字符串, 说明已经已经读取到最后一行。print(f.readline())# 返回所有行。print(f.readlines())# 将 string 写入到文件中, 然后返回写入的字符数。f.write(&quot;string&quot;)# 返回文件对象当前所处的位置, 它是从文件开头开始算起的字节数。f.tell()# 改变文件当前的位置, 可以使用 f.seek(offset, from_what) 函数。# from_what 的值, 如果是 0 表示开头, 如果是 1 表示当前位置, 2 表示文件的结尾，例如：# seek(x,0) ： 从起始位置即文件首行首字符开始移动 x 个字符# seek(x,1) ： 表示从当前位置往后移动x个字符# seek(-x,2)：表示从文件的结尾往前移动x个字符# from_what 值为默认为0，即文件开头# 关闭打开的文件f.close()# pickle 模块 实现了基本的数据序列和反序列化。import pickle# 使用pickle模块将数据对象保存到文件data1 = {'a': [1, 2.0, 3, 4+6j], 'b': ('string', u'Unicode string'), 'c': None}selfref_list = [1, 2, 3]selfref_list.append(selfref_list)output = open('data.pkl', 'wb')# Pickle dictionary using protocol 0.pickle.dump(data1, output)# Pickle the list using the highest protocol available.pickle.dump(selfref_list, output, -1)output.close()''' 注释 '''&quot;&quot;&quot;注释&quot;&quot;&quot;# 保留字 关键字end可以用于将结果输出到同一行，或者在输出的末尾添加不同的字符print(b, end=',')print(&quot;保留字&quot;, keyword.kwlist)# 缩进的空格数是可变的，但是同一个代码块的语句必须包含相同的缩进空格数if True: print(&quot;ture&quot;)else: print('false')# 多行语句，语句很长，我们可以使用反斜杠(\\)来实现多行语句，在 [], {}, 或 () 中的多行语句，不需要使用反斜杠(\\)total = 'item_one' + \\ 'item_two' + \\ 'item_three'total1 = ['item_one', 'item_two', 'item_three', 'item_four', 'item_five']print(total)print(total1)''' ================基本数据类型===================Python3 中有六个标准的数据类型：Number（数字）：int、float、bool、complex（复数）String（字符串）List（列表）Tuple（元组）Set（集合）Dictionary（字典）Python3 的六个标准数据类型中：不可变数据（3 个）：Number（数字）、String（字符串）、Tuple（元组）；可变数据（3 个）：List（列表）、Dictionary（字典）、Set（集合）。 type()查看数据类型，isinstance(a, int)进行判断'''# Number（数字）------------------------------------------------------------------------# int(x) 将x转换为一个整数。# float(x) 将x转换到一个浮点数。# complex(x) 将x转换到一个复数，实数部分为 x，虚数部分为 0。# complex(x, y) 将 x 和 y 转换到一个复数，实数部分为 x，虚数部分为 y。x 和 y 是数字表达式。# ==数学函数==# 函数 返回值 ( 描述 )# abs(x) 返回数字的绝对值，如abs(-10) 返回 10# ceil(x) 返回数字的上入整数，如math.ceil(4.1) 返回 5# cmp(x, y) 如果 x &lt; y 返回 -1, 如果 x == y 返回 0, 如果 x &gt; y 返回 1。 Python 3 已废弃，使用 (x&gt;y)-(x&lt;y) 替换。# exp(x) 返回e的x次幂(ex),如math.exp(1) 返回2.718281828459045# fabs(x) 返回数字的绝对值，如math.fabs(-10) 返回10.0# floor(x) 返回数字的下舍整数，如math.floor(4.9)返回 4# log(x) 如math.log(math.e)返回1.0,math.log(100,10)返回2.0# log10(x) 返回以10为基数的x的对数，如math.log10(100)返回 2.0# max(x1, x2,...) 返回给定参数的最大值，参数可以为序列。# min(x1, x2,...) 返回给定参数的最小值，参数可以为序列。# modf(x) 返回x的整数部分与小数部分，两部分的数值符号与x相同，整数部分以浮点型表示。# pow(x, y) x**y 运算后的值。# round(x [,n]) 返回浮点数 x 的四舍五入值，如给出 n 值，则代表舍入到小数点后的位数。其实准确的说是保留值将保留到离上一位更近的一端。# sqrt(x) 返回数字x的平方根。# ==随机数函数==# choice(seq) 从序列的元素中随机挑选一个元素，比如random.choice(range(10))，从0到9中随机挑选一个整数。# randrange ([start,] stop [,step]) 从指定范围内，按指定基数递增的集合中获取一个随机数，基数默认值为 1# random() 随机生成下一个实数，它在[0,1)范围内。# seed([x]) 改变随机数生成器的种子seed。如果你不了解其原理，你不必特别去设定seed，Python会帮你选择seed。# shuffle(lst) 将序列的所有元素随机排序# uniform(x, y) 随机生成下一个实数，它在[x,y]范围内# ==三角函数==# Python包括以下三角函数：# 函数 描述# acos(x) 返回x的反余弦弧度值。# asin(x) 返回x的反正弦弧度值。# atan(x) 返回x的反正切弧度值。# atan2(y, x) 返回给定的 X 及 Y 坐标值的反正切值。# cos(x) 返回x的弧度的余弦值。# hypot(x, y) 返回欧几里德范数 sqrt(x*x + y*y)。# sin(x) 返回的x弧度的正弦值。# tan(x) 返回x弧度的正切值。# degrees(x) 将弧度转换为角度,如degrees(math.pi/2) ， 返回90.0# radians(x) 将角度转换为弧度# ==数学常量==# 常量 描述# pi 数学常量 pi（圆周率，一般以π来表示）# e 数学常量 e，e即自然常数（自然常数）。a = b = c = counter = 100 # 同时为多个变量赋值整型变量d, e, f = 1, 2, &quot;runoob&quot; # 同时为多个变量赋值不同的值miles = 1000.0 # 浮点型变量name = &quot;runoob&quot; # 字符串# del语句删除一些对象引用del a# 数值运算Division = 2 / 4 # 除法，得到一个浮点数Division2 = 2 // 4 # 除法，得到一个整数remainder = 17 % 3 # 取余involution = 2 ** 5 # 乘方print(Division, 'Division')print(Division2, 'Division2')# String（字符串）------------------------------------------------------------------------------# 从后面索引01234567# 从前面索引-8-7-6-5-4-3-2-1# Good boy# 从前面截取:123456:# 从后面截取:-6-5-4-3-2-1:# 反斜杠(\\)可以作为续行符，表示下一行是上一行的延续。也可以使用 &quot;&quot;&quot;...&quot;&quot;&quot; 或者 '''...''' 跨越多行# 用+运算符连接在一起，用*运算符重复# ==转义字符==# \\(在行尾时) 续行符# &gt;&gt;&gt; print(&quot;line1 \\# ... line2 \\# ... line3&quot;)# line1 line2 line3# \\\\ 反斜杠符号# &gt;&gt;&gt; print(&quot;\\\\&quot;)# \\# \\' 单引号# &gt;&gt;&gt; print('\\'')# '# \\&quot; 双引号# &gt;&gt;&gt; print(&quot;\\&quot;&quot;)# &quot;# \\a 响铃# &gt;&gt;&gt; print(&quot;\\a&quot;)执行后电脑有响声。# \\b 退格(Backspace)# &gt;&gt;&gt; print(&quot;Hello \\b World!&quot;)# Hello World!# \\000 空# &gt;&gt;&gt; print(&quot;\\000&quot;)## &gt;&gt;&gt;# \\n 换行# &gt;&gt;&gt; print(&quot;\\n&quot;)## &gt;&gt;&gt;# \\v 纵向制表符# &gt;&gt;&gt; print(&quot;Hello \\v World!&quot;)# Hello# World!# &gt;&gt;&gt;# \\t 横向制表符# &gt;&gt;&gt; print(&quot;Hello \\t World!&quot;)# Hello World!# &gt;&gt;&gt;# \\r 回车，将 \\r 后面的内容移到字符串开头，并逐一替换开头部分的字符，直至将 \\r 后面的内容完全替换完成。# &gt;&gt;&gt; print(&quot;Hello\\rWorld!&quot;)# World!# &gt;&gt;&gt; print('google runoob taobao\\r123456')# 123456 runoob taobao# \\f 换页# &gt;&gt;&gt; print(&quot;Hello \\f World!&quot;)# Hello# World!# &gt;&gt;&gt;# \\yyy 八进制数，y 代表 0~7 的字符，例如：\\012 代表换行。# &gt;&gt;&gt; print(&quot;\\110\\145\\154\\154\\157\\40\\127\\157\\162\\154\\144\\41&quot;)# Hello World!# \\xyy 十六进制数，以 \\x 开头，y 代表的字符，例如：\\x0a 代表换行# &gt;&gt;&gt; print(&quot;\\x48\\x65\\x6c\\x6c\\x6f\\x20\\x57\\x6f\\x72\\x6c\\x64\\x21&quot;)# Hello World!# \\other 其它的字符以普通格式输出# ==字符串运算符==# + 字符串连接 a + b 输出结果： HelloPython# * 重复输出字符串 a*2 输出结果：HelloHello# [] 通过索引获取字符串中字符 a[1] 输出结果 e# [ : ] 截取字符串中的一部分，遵循左闭右开原则，str[0:2] 是不包含第 3 个字符的。 a[1:4] 输出结果 ell# in 成员运算符 - 如果字符串中包含给定的字符返回 True 'H' in a 输出结果 True# not in 成员运算符 - 如果字符串中不包含给定的字符返回 True 'M' not in a 输出结果 True# r/R 原始字符串 - 原始字符串：所有的字符串都是直接按照字面的意思来使用，没有转义特殊或不能打印的字符。 原始字符串除在字符串的第一个引号前加上字母 r（可以大小写）以外，与普通字符串有着几乎完全相同的语法。 print( r'\\n' ) print( R'\\n' )# % 格式字符串# ==字符串格式化==# % c 格式化字符及其ASCII码# % s 格式化字符串# % d 格式化整数# % u 格式化无符号整型# % o 格式化无符号八进制数# % x 格式化无符号十六进制数# % X 格式化无符号十六进制数（大写）# % f 格式化浮点数字，可指定小数点后的精度# % e 用科学计数法格式化浮点数# % E 作用同 % e，用科学计数法格式化浮点数# % g % f和 % e的简写# % G % f 和 % E 的简写# % p 用十六进制数格式化变量的地址# 格式化操作符辅助指令:# 符号 功能# * 定义宽度或者小数点精度# - 用做左对齐# + 在正数前面显示加号( + )# &lt;sp&gt; 在正数前面显示空格# # 在八进制数前面显示零('0')，在十六进制前面显示'0x'或者'0X'(取决于用的是'x'还是'X')# 0 显示的数字前面填充'0'而不是默认的空格# % '%%'输出一个单一的'%'# (var) 映射变量(字典参数)# m.n. m 是显示的最小总宽度,n 是小数点后的位数(如果可用的话)# ==f-string==name = 'Runoob'f'Hello {name}' # 替换变量'Hello Runoob'f'{1 + 2}' # 使用表达式'3'w = {'name': 'Runoob', 'url': 'www.runoob.com'}f'{w[&quot;name&quot;]}: {w[&quot;url&quot;]}''Runoob: www.runoob.com'para_str = &quot;&quot;&quot;这是一个多行字符串的实例多行字符串可以使用制表符TAB ( \\t )。也可以使用换行符 [ \\n ]。&quot;&quot;&quot;# ==字符串内建函数==# capitalize()# 将字符串的第一个字符转换为大写# center(width, fillchar)# 返回一个指定的宽度 width 居中的字符串，fillchar 为填充的字符，默认为空格。# count(str, beg= 0,end=len(string))# 返回 str 在 string 里面出现的次数，如果 beg 或者 end 指定则返回指定范围内 str 出现的次数# bytes.decode(encoding=&quot;utf-8&quot;, errors=&quot;strict&quot;)# Python3 中没有 decode 方法，但我们可以使用 bytes 对象的 decode() 方法来解码给定的 bytes 对象，这个 bytes 对象可以由 str.encode() 来编码返回。# encode(encoding='UTF-8',errors='strict')# 以 encoding 指定的编码格式编码字符串，如果出错默认报一个ValueError 的异常，除非 errors 指定的是'ignore'或者'replace'# endswith(suffix, beg=0, end=len(string))# 检查字符串是否以 obj 结束，如果beg 或者 end 指定则检查指定的范围内是否以 obj 结束，如果是，返回 True,否则返回 False.# expandtabs(tabsize=8)# 把字符串 string 中的 tab 符号转为空格，tab 符号默认的空格数是 8 。# find(str, beg=0, end=len(string))# 检测 str 是否包含在字符串中，如果指定范围 beg 和 end ，则检查是否包含在指定范围内，如果包含返回开始的索引值，否则返回-1# index(str, beg=0, end=len(string))# 跟find()方法一样，只不过如果str不在字符串中会报一个异常。# isalnum()# 如果字符串至少有一个字符并且所有字符都是字母或数字则返 回 True，否则返回 False# isalpha()# 如果字符串至少有一个字符并且所有字符都是字母或中文字则返回 True, 否则返回 False# isdigit()# 如果字符串只包含数字则返回 True 否则返回 False..# islower()# 如果字符串中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是小写，则返回 True，否则返回 False# isnumeric()# 如果字符串中只包含数字字符，则返回 True，否则返回 False# isspace()# 如果字符串中只包含空白，则返回 True，否则返回 False.# istitle()# 如果字符串是标题化的(见 title())则返回 True，否则返回 False# isupper()# 如果字符串中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是大写，则返回 True，否则返回 False# join(seq)# 以指定字符串作为分隔符，将 seq 中所有的元素(的字符串表示)合并为一个新的字符串# len(string)# 返回字符串长度# ljust(width[, fillchar])# 返回一个原字符串左对齐,并使用 fillchar 填充至长度 width 的新字符串，fillchar 默认为空格。# lower()# 转换字符串中所有大写字符为小写.# lstrip()# 截掉字符串左边的空格或指定字符。# maketrans()# 创建字符映射的转换表，对于接受两个参数的最简单的调用方式，第一个参数是字符串，表示需要转换的字符，第二个参数也是字符串表示转换的目标。# max(str)# 返回字符串 str 中最大的字母。# min(str)# 返回字符串 str 中最小的字母。# replace(old, new [, max])# 把 将字符串中的 old 替换成 new,如果 max 指定，则替换不超过 max 次。# rfind(str, beg=0,end=len(string))# 类似于 find()函数，不过是从右边开始查找.# rindex( str, beg=0, end=len(string))# 类似于 index()，不过是从右边开始.# rjust(width,[, fillchar])# 返回一个原字符串右对齐,并使用fillchar(默认空格）填充至长度 width 的新字符串# rstrip()# 删除字符串末尾的空格或指定字符。# split(str=&quot;&quot;, num=string.count(str))# 以 str 为分隔符截取字符串，如果 num 有指定值，则仅截取 num+1 个子字符串# splitlines([keepends])# 按照行('\\r', '\\r\\n', \\n')分隔，返回一个包含各行作为元素的列表，如果参数 keepends 为 False，不包含换行符，如果为 True，则保留换行符。# startswith(substr, beg=0,end=len(string))# 检查字符串是否是以指定子字符串 substr 开头，是则返回 True，否则返回 False。如果beg 和 end 指定值，则在指定范围内检查。# strip([chars])# 在字符串上执行 lstrip()和 rstrip()# swapcase()# 将字符串中大写转换为小写，小写转换为大写# title()# 返回&quot;标题化&quot;的字符串,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle())# translate(table, deletechars=&quot;&quot;)# 根据 str 给出的表(包含 256 个字符)转换 string 的字符, 要过滤掉的字符放到 deletechars 参数中# upper()# 转换字符串中的小写字母为大写# zfill (width)# 返回长度为 width 的字符串，原字符串右对齐，前面填充0# isdecimal()# 检查字符串是否只包含十进制字符，如果是返回 true，否则返回 false。str = 'Lxl is a good boy'print(str) # 输出字符串print(str[0:-1]) # 输出第一个到倒数第二个的所有字符print(str[0]) # 输出字符串第一个字符print(str[2:5]) # 输出从第三个开始到第五个的字符print(str[2:]) # 输出从第三个开始的后的所有字符print(str * 2) # 输出字符串两次，也可以写成 print (2 * str)print(str + &quot;TEST&quot;) # 连接字符串# 转义print('Ru\\noob')# 不转义字符串前加rprint(2 * r'Ru\\noob')# List（列表）------------------------------------------------------------------------------# 创建列表只需要方括号括起来，里面数据类型可不一致，索引正0反-1，# 列表中的元素是可以改变的# append() 追加 del 删除# ==列表脚本操作符==# Python 表达式 结果 描述# len([1, 2, 3]) 3 长度# [1, 2, 3] + [4, 5, 6] [1, 2, 3, 4, 5, 6] 组合# ['Hi!'] * 4 ['Hi!', 'Hi!', 'Hi!', 'Hi!'] 重复# 3 in [1, 2, 3] True 元素是否存在于列表中# for x in [1, 2, 3]: print(x, end=&quot; &quot;) 1 2 3 迭代# ==函数&amp;方法==# len(list) 列表元素个数# max(list) 返回列表元素最大值# min(list) 返回列表元素最小值# list(seq) 将元组转换为列表# 1 list.append(obj) 在列表末尾添加新的对象# 2 list.count(obj) 统计某个元素在列表中出现的次数# 3 list.extend(seq) 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）# 4 list.index(obj) 从列表中找出某个值第一个匹配项的索引位置# 5 list.insert(index, obj) 将对象插入列表# 6 list.pop([index=-1]) 移除列表中的一个元素（默认最后一个元素），并且返回该元素的值# 7 list.remove(obj) 移除列表中某个值的第一个匹配项# 8 list.reverse() 反向列表中元素# 9 list.sort( key=None, reverse=False) 对原列表进行排序# 10 list.clear() 清空列表# 11 list.copy() 复制列表lists = ['1', '2', '3', '4', '5']print(lists[:])print(lists[:3])print(lists[1:3])print(lists[4:])print(lists[-1:])print(lists[:-2])print(lists * 3) # 输出多次列表print(lists + lists) # 连接列表for i, v in enumerate(['tic', 'tac', 'toe']): print(i, v)def reverseWords(input): # 通过空格将字符串分隔符，把各个单词分隔为列表 inputWords = input.split(&quot; &quot;) # 翻转字符串 # 假设列表 list = [1,2,3,4], # list[0]=1, list[1]=2 ，而 -1 表示最后一个元素 list[-1]=4 ( 与 list[3]=4 一样) # inputWords[-1::-1] 有三个参数 # 第一个参数 -1 表示最后一个元素 # 第二个参数为空，表示移动到列表末尾 # 第三个参数为步长，-1 表示逆向 inputWords = inputWords[-1::-1] # 重新组合字符串 output = ' '.join(inputWords) return outputif __name__ == &quot;__main__&quot;: input = 'I like runoob' rw = reverseWords(input) print(rw)# Tuple（元组）--------------------------------------------------------------------# 元组（tuple）与列表类似，不同之处在于元组的元素不能修改，其使用小括号（）或不要括号，# 但它可以包含可变的对象，可以连接组合成新元祖，元素不允许删除但可以使用del删除整个元祖。# string、list 和 tuple 都属于 sequence（序列）。# 当元祖只有一个元素时，后面添加逗号，否则括号会被当做运算符使用，tup1 = (50)为整型，tup1 = (50，)为元祖# ==元祖运算符==# Python 表达式 结果 描述# len((1, 2, 3)) 3 计算元素个数# (1, 2, 3) + (4, 5, 6) (1, 2, 3, 4, 5, 6) 连接# ('Hi!',) * 4 ('Hi!', 'Hi!', 'Hi!', 'Hi!') 复制# 3 in (1, 2, 3) True 元素是否存在# for x in (1, 2, 3): print (x,) 1 2 3 迭代# ==内置函数==# len(tuple) 计算元组元素个数。# max(tuple) 返回元组中元素最大值。# min(tuple) 返回元组中元素最小值。# tuple(iterable) 将可迭代系列转换为元组。tuple = ('abcd', 786, 2.23, 'runoob', 70.2)tinytuple = (123, 'runoob')print(tuple) # 输出完整元组print(tuple[0]) # 输出元组的第一个元素print(tuple[1:3]) # 输出从第二个元素开始到第三个元素print(tuple[2:]) # 输出从第三个元素开始的所有元素print(tinytuple * 2) # 输出两次元组print(tuple + tinytuple) # 连接元组# Set（集合）----------------------------------------------------------------------# 创建一个空集合必须用 set() 而不是 { }，因为 { } 是用来创建一个空字典sites = {'Google', 'Taobao', 'Runoob', 'Facebook', 'Zhihu', 'Baidu'}sites1 = {}sites2 = ()set()# # 添加元素，重复不操作# sites1.add(&quot;1&quot;)# # 可以添加列表，元祖字典等# sites1.update(&quot;1&quot;)# print(sites) # 输出集合，重复的元素被自动去掉# # 移除，不存在报错# sites1.remove( x )# # 移除，不存在不报错# sites1.discard( x )# # 随机删除# sites1.pop()# # 长度# len(sites1)# # 清空# sites1.clear()# # 判断是否存在# x in s# ==内置方法完整列表==# add() 为集合添加元素# clear() 移除集合中的所有元素# copy() 拷贝一个集合# difference() 返回多个集合的差集# difference_update() 移除集合中的元素，该元素在指定的集合也存在。# discard() 删除集合中指定的元素# intersection() 返回集合的交集# intersection_update() 返回集合的交集。# isdisjoint() 判断两个集合是否包含相同的元素，如果没有返回 True，否则返回 False。# issubset() 判断指定集合是否为该方法参数集合的子集。# issuperset() 判断该方法的参数集合是否为指定集合的子集# pop() 随机移除元素# remove() 移除指定元素# symmetric_difference() 返回两个集合中不重复的元素集合。# symmetric_difference_update() 移除当前集合中在另外一个指定集合相同的元素，并将另外一个指定集合中不同的元素插入到当前集合中。# union() 返回两个集合的并集# update() 给集合添加元素# 成员测试if 'Runoob' in sites: print('Runoob 在集合中')else: print('Runoob 不在集合中')# set可以进行集合运算a = set('abracadabra')b = set('alacazam')print(a)print(a - b) # a 和 b 的差集print(a | b) # a 和 b 的并集print(a &amp; b) # a 和 b 的交集print(a ^ b) # a 和 b 中不同时存在的元素# Dictionary（字典）------------------------------------------------------------------# 字典（dictionary）是Python中另一个非常有用的内置数据类型。# 列表是有序的对象集合，字典是无序的对象集合。两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取。# 字典是一种映射类型，字典用 { } 标识，它是一个无序的 键(key) : 值(value) 的集合。# 键(key)可以是任意类型，但必须使用不可变类型。# 在同一个字典中，键(key)必须是唯一的。# ==内置函数==# len(dict) 计算字典元素个数，即键的总数。# str(dict) 输出字典，以可打印的字符串表示。# type(variable) 返回输入的变量类型，如果变量是字典就返回字典类型。# ==内置方法==# 1 radiansdict.clear() 删除字典内所有元素# 2 radiansdict.copy() 返回一个字典的浅复制# 3 radiansdict.fromkeys() 创建一个新字典，以序列seq中元素做字典的键，val为字典所有键对应的初始值# 4 radiansdict.get(key, default=None) 返回指定键的值，如果键不在字典中返回 default 设置的默认值# 5 key in dict 如果键在字典dict里返回true，否则返回false# 6 radiansdict.items() 以列表返回一个视图对象# 7 radiansdict.keys() 返回一个视图对象# 8 radiansdict.setdefault(key, default=None) 和get()类似, 但如果键不存在于字典中，将会添加键并将值设为default# 9 radiansdict.update(dict2) 把字典dict2的键/值对更新到dict里# 10 radiansdict.values() 返回一个视图对象# 11 pop(key[,default]) 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。# 12 popitem() 随机返回并删除字典中的最后一对键和值dict = {}dict['one'] = &quot;1 - 菜鸟教程&quot;dict[2] = &quot;2 - 菜鸟工具&quot;tinydict = {'name': 'runoob', 'code': 1, 'site': 'www.runoob.com'}for k, v in knights.items(): print(k, v)print(dict['one']) # 输出键为 'one' 的值print(dict[2]) # 输出键为 2 的值print(tinydict) # 输出完整的字典print(tinydict.keys()) # 输出所有键print(tinydict.values()) # 输出所有值del tinydict['name'] # 删除键 'name'dict.clear() # 清空字典del tinydict # 删除字典# 构造函数 dict() 可以直接从键值对序列中构建字典如下'''============数据类型转换==============='''# int(x [,projects]) 将x转换为一个整数# float(x)将x转换到一个浮点数# complex(real [,imag])创建一个复数# str(x)将对象 x 转换为字符串# repr(x)将对象 x 转换为表达式字符串# eval(str)用来计算在字符串中的有效Python表达式,并返回一个对象# tuple(s)将序列 s 转换为一个元组# list(s)将序列 s 转换为一个列表# set(s)转换为可变集合# dict(d)创建一个字典。d 必须是一个 (key, value)元组序列。# frozenset(s)转换为不可变集合# chr(x)将一个整数转换为一个字符# ord(x)将一个字符转换为它的整数值# hex(x)将一个整数转换为一个十六进制字符串# oct(x)将一个整数转换为一个八进制字符串'''============Python3运算符==============='''# 算术运算符【a为10，b为21】----------------------------------# + 加 - 两个对象相加 a + b 输出结果 31# - 减 - 得到负数或是一个数减去另一个数 a - b 输出结果 -11# * 乘 - 两个数相乘或是返回一个被重复若干次的字符串 a * b 输出结果 210# / 除 - x 除以 y b / a 输出结果 2.1# % 取模 - 返回除法的余数 b % a 输出结果 1# ** 幂 - 返回x的y次幂 a**b 为10的21次方# // 取整除 - 向下取接近商的整数，除后取小 9//2=4 -9//2=-5# 比较（关系）运算符【a为10，b为20】-----------------------------# == 等于 - 比较对象是否相等 (a == b) 返回 False。# != 不等于 - 比较两个对象是否不相等 (a != b) 返回 True。# &gt; 大于 - 返回x是否大于y (a &gt; b) 返回 False。# &lt; 小于 - 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量True和False等价。注意，这些变量名的大写。 (a &lt; b) 返回 True。# &gt;= 大于等于 - 返回x是否大于等于y。 (a &gt;= b) 返回 False。# &lt;= 小于等于 - 返回x是否小于等于y。 (a &lt;= b) 返回 True。# 赋值运算符【a为10，b为20】----------------------------------# = 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值为 c# += 加法赋值运算符 c += a 等效于 c = c + a# -= 减法赋值运算符 c -= a 等效于 c = c - a# *= 乘法赋值运算符 c *= a 等效于 c = c * a# /= 除法赋值运算符 c /= a 等效于 c = c / a# %= 取模赋值运算符 c %= a 等效于 c = c % a# **= 幂赋值运算符 c **= a 等效于 c = c ** a# //= 取整除赋值运算符 c //= a 等效于 c = c // a# := 海象运算符，可在表达式内部为变量赋值。Python3.8 版本新增运算符。# 在这个示例中，赋值表达式可以避免调用 len() 两次:# if (n := len(a)) &gt; 10:# print(f&quot;List is too long ({n} elements, expected &lt;= 10)&quot;)# 逻辑运算符-----------------------------------------------------# and x and y 布尔&quot;与&quot; - 如果 x 为 False，x and y 返回 x 的值，否则返回 y 的计算值。 (a and b) 返回 20。# or x or y 布尔&quot;或&quot; - 如果 x 是 True，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。# not not x 布尔&quot;非&quot; - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False# 位运算符-------------------------------------------------------# &amp; 按位与运算符：参与运算的两个值,如果两个相应位都为1,则该位的结果为1,否则为0 (a &amp; b) 输出结果 12 ，二进制解释： 0000 1100# | 按位或运算符：只要对应的二个二进位有一个为1时，结果位就为1。 (a | b) 输出结果 61 ，二进制解释： 0011 1101# ^ 按位异或运算符：当两对应的二进位相异时，结果为1 (a ^ b) 输出结果 49 ，二进制解释： 0011 0001# ~ 按位取反运算符：对数据的每个二进制位取反,即把1变为0,把0变为1。~x 类似于 -x-1 (~a ) 输出结果 -61 ，二进制解释： 1100 0011， 在一个有符号二进制数的补码形式。# &lt;&lt; 左移动运算符：运算数的各二进位全部左移若干位，由&quot;&lt;&lt;&quot;右边的数指定移动的位数，高位丢弃，低位补0。 a &lt;&lt; 2 输出结果 240 ，二进制解释： 1111 0000# &gt;&gt; 右移动运算符：把&quot;&gt;&gt;&quot;左边的运算数的各二进位全部右移若干位，&quot;&gt;&gt;&quot;右边的数指定移动的位数 a &gt;&gt; 2 输出结果 15 ，二进制解释： 0000 1111# 成员运算符----------------------------------------------------------# in 如果在指定的序列中找到值返回 True，否则返回 False。 x 在 y 序列中 , 如果 x 在 y 序列中返回 True。# not in 如果在指定的序列中没有找到值返回 True，否则返回 False。 x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True。# 身份运算符------------------------------------------------------------# is is 是判断两个标识符是不是引用自一个对象 x is y, 类似 id(x) == id(y) , 如果引用的是同一个对象则返回 True，否则返回 False# is not is not 是判断两个标识符是不是引用自不同对象 x is not y ， 类似 id(a) != id(b)。如果引用的不是同一个对象则返回结果 True，否则返回 False。# 运算符优先级# ** 指数 (最高优先级)# ~ + - 按位翻转, 一元加号和减号 (最后两个的方法名为 +@ 和 -@)# * / % // 乘，除，求余数和取整除# + - 加法减法# &gt;&gt; &lt;&lt; 右移，左移运算符# &amp; 位 'AND'# ^ | 位运算符# &lt;= &lt; &gt; &gt;= 比较运算符# == != 等于运算符# = %= /= //= -= += *= **= 赋值运算符# is is not 身份运算符# in not in 成员运算符# not and or 逻辑运算符 流程控制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485'''流程控制'''# ifif condition_1: statement_block_1elif condition_2: statement_block_2else: statement_block_3# while whlie后面为false时则执行else语句块while counter &lt;= n: sum = sum + counter counter += 1else: additional_statement(s)# for range()函数。它会生成数列# break 语句可以跳出 for 和 while 的循环体。如果你从 for 或 while 循环中终止，任何对应的循环 else 块将不执行。# continue 语句被用来告诉 Python 跳过当前循环块中的剩余语句，然后继续进行下一轮循环。for i in range(5,9) : print(i)# pass 不做任何事情，一般用做占位语句for letter in 'Runoob': if letter == 'o': pass print('执行 pass 块') print('当前字母 :', letter)print(&quot;Good bye!&quot;)'''迭代器与生成器 iter()创建迭代器对象 和 next()输出迭代器下一个元素 Python 的构造函数为 __init__(),__iter__() 方法返回一个特殊的迭代器对象， 这个迭代器对象实现了 __next__() 方法并通过 StopIteration 异常标识迭代的完成。__next__() 方法（Python 2 里是 next()）会返回下一个迭代器对象。'''# StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 __next__() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。class MyNumbers: def __iter__(self): self.a = 1 return self def __next__(self): if self.a &lt;= 20: x = self.a self.a += 1 return x else: raise StopIterationmyclass = MyNumbers()myiter = iter(myclass)for x in myiter: print(x)# 使用了 yield 的函数被称为生成器（generator）。# 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。## 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。## 调用一个生成器函数，返回的是一个迭代器对象。import sysdef fibonacci(n): # 生成器函数 - 斐波那契 a, b, counter = 0, 1, 0 while True: if (counter &gt; n): return yield a a, b = b, a + b counter += 1f = fibonacci(10) # f 是一个迭代器，由生成器返回生成while True: try: print(next(f), end=&quot; &quot;) except StopIteration: sys.exit() 时间 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&quot;&quot;&quot;时间&quot;&quot;&quot;# Python 提供了一个 time 和 calendar 模块可以用于格式化日期和时间。# 时间间隔是以秒为单位的浮点小数。# 每个时间戳都以自从 1970 年 1 月 1 日午夜（历元）经过了多长时间来表示。import time # 引入time模块ticks = time.time()print (&quot;当前时间戳为:&quot;, ticks)# 时间元组# 很多Python函数用一个元组装起来的9组数字处理时间:## 序号 字段 值# 0 4位数年 2008# 1 月 1 到 12# 2 日 1到31# 3 小时 0到23# 4 分钟 0到59# 5 秒 0到61 (60或61 是闰秒)# 6 一周的第几日 0到6 (0是周一)# 7 一年的第几日 1到366 (儒略历)# 8 夏令时 -1, 0, 1, -1是决定是否为夏令时的旗帜# 上述也就是struct_time元组。这种结构具有如下属性：# 序号 属性 值# 0 tm_year 2008# 1 tm_mon 1 到 12# 2 tm_mday 1 到 31# 3 tm_hour 0 到 23# 4 tm_min 0 到 59# 5 tm_sec 0 到 61 (60或61 是闰秒)# 6 tm_wday 0到6 (0是周一)# 7 tm_yday 一年中的第几天，1 到 366# 8 tm_isdst 是否为夏令时，值有：1(夏令时)、0(不是夏令时)、-1(未知)，默认 -1# 获取当前时间localtime = time.asctime( time.localtime(time.time()) )print (&quot;本地时间为 :&quot;, localtime)# 格式化# %y 两位数的年份表示（00-99）# %Y 四位数的年份表示（000-9999）# %m 月份（01-12）# %d 月内中的一天（0-31）# %H 24小时制小时数（0-23）# %I 12小时制小时数（01-12）# %M 分钟数（00=59）# %S 秒（00-59）# %a 本地简化星期名称# %A 本地完整星期名称# %b 本地简化的月份名称# %B 本地完整的月份名称# %c 本地相应的日期表示和时间表示# %j 年内的一天（001-366）# %p 本地A.M.或P.M.的等价符# %U 一年中的星期数（00-53）星期天为星期的开始# %w 星期（0-6），星期天为星期的开始# %W 一年中的星期数（00-53）星期一为星期的开始# %x 本地相应的日期表示# %X 本地相应的时间表示# %Z 当前时区的名称# %% %号本身print(time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime()))# 格式化成Sat Mar 28 22:24:24 2016形式print(time.strftime(&quot;%a %b %d %H:%M:%S %Y&quot;, time.localtime()))# 将格式字符串转换为时间戳a = &quot;Sat Mar 28 22:24:24 2016&quot;print(time.mktime(time.strptime(a, &quot;%a %b %d %H:%M:%S %Y&quot;)))# 获取某月日历import calendarcal = calendar.month(2016, 1)print (&quot;以下输出2016年1月份的日历:&quot;)print (cal) JSON 123456789101112131415161718192021222324252627282930313233343536373839404142434445&quot;&quot;&quot;JSON&quot;&quot;&quot;# json.dumps(): ==编码==# dict object# list, tuple array# str string# int, float, int- &amp; float-derived Enums number# True true# False false# None null# json.loads(): ==解码==# object dict# array list# string str# number (int) int# number (real) float# true True# false False# null Noneimport json# Python 字典类型转换为 JSON 对象data = { 'no': 1, 'name': 'Runoob', 'url': 'http://www.runoob.com'}json_str = json.dumps(data)print(&quot;Python 原始数据：&quot;, repr(data))print(&quot;JSON 对象：&quot;, json_str)# 将 JSON 对象转换为 Python 字典data2 = json.loads(json_str)print (&quot;data2['name']: &quot;, data2['name'])print (&quot;data2['url']: &quot;, data2['url'])# 文件处理# 写入 JSON 数据with open('data.json', 'w') as f: json.dump(data, f)# 读取数据with open('data.json', 'r') as f: data = json.load(f) 标准库概览 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102&quot;&quot;&quot;标准库概览&quot;&quot;&quot;# 操作系统接口-----------------------------import osos.getcwd() # 返回当前的工作目录os.chdir('/server/accesslogs') # 修改当前的工作目录os.system('mkdir today') # 执行系统命令 mkdirimport shutilshutil.copyfile('data.db', 'archive.db')shutil.move('/build/executables', 'installdir')# 文件通配符 ---------------------------------------------# 用于从目录通配符搜索中生成文件列表import globglob.glob('*.py')# 命令行参数------------------------------------import sysprint(sys.argv)# 错误输出重定向和程序终止-------------------------------# sys 还有 stdin，stdout 和 stderr 属性，即使在 stdout 被重定向时，后者也可以用于显示警告和错误信息。sys.stderr.write('Warning, log file not found starting a new one\\n')# 字符串正则匹配-----------------------------------------------import rere.findall(r'\\bf[a-z]*', 'which foot or hand fell fastest')re.sub(r'(\\b[a-z]+) \\1', r'\\1', 'cat in the the hat')# 数学-----------------------------------------------import mathmath.cos(math.pi / 4)math.log(1024, 2)import randomrandom.choice(['apple', 'pear', 'banana'])random.sample(range(100), 10) # sampling without replacementrandom.random() # random floatrandom.randrange(6)# 互联网-----------------------------------------------from urllib.request import urlopenfor line in urlopen('http://tycho.usno.navy.mil/cgi-bin/timer.pl'): line = line.decode('utf-8') # Decoding the binary data to text. if 'EST' in line or 'EDT' in line: # look for Eastern Time print(line)import smtplibserver = smtplib.SMTP('localhost')server.sendmail('soothsayer@example.org', 'jcaesar@example.org',&quot;&quot;&quot;To: jcaesar@example.org...From: soothsayer@example.org...... Beware the Ides of March.... &quot;&quot;&quot;)server.quit()# 日期和时间-----------------------------------------------from datetime import datenow = date.today()print(now)now.strftime(&quot;%m-%d-%y. %d %b %Y is a %A on the %d day of %B.&quot;)# dates support calendar arithmeticbirthday = date(1964, 7, 31)age = now - birthdayage.days# 数据压缩import zlibs = b'witch which has which witches wrist watch'len(s)t = zlib.compress(s)len(t)zlib.decompress(t)zlib.crc32(s)# 性能度量from timeit import TimerTimer('t=a; a=b; b=t', 'a=1; b=2').timeit()Timer('a,b = b,a', 'a=1; b=2').timeit()# 测试模块def average(values): &quot;&quot;&quot;Computes the arithmetic mean of a list of numbers. &gt;&gt;&gt; print(average([20, 30, 70])) 40.0 &quot;&quot;&quot; return sum(values) / len(values)import doctestdoctest.testmod() # 自动验证嵌入测试# unittest模块不像 doctest模块那么容易使用，不过它可以在一个独立的文件里提供一个更全面的测试集:import unittestclass TestStatisticalFunctions(unittest.TestCase): def test_average(self): self.assertEqual(average([20, 30, 70]), 40.0) self.assertEqual(round(average([1, 5, 7]), 1), 4.3) self.assertRaises(ZeroDivisionError, average, []) self.assertRaises(TypeError, average, 20, 30, 70)unittest.main() # Calling from the command line invokes all tests OOP 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129&quot;&quot;&quot;OOP&quot;&quot;&quot;# ===类===# class ClassName:# &lt;statement-1&gt;# .# .# &lt;statement-N&gt;# ===类对象===# 属性引用和实例化class MyClass: &quot;&quot;&quot;一个简单的类实例&quot;&quot;&quot; i = 12345 def f(self): return 'hello world'# ===实例化类===x = MyClass()# ===访问类的属性和方法===print(&quot;MyClass 类的属性 i 为：&quot;, x.i)print(&quot;MyClass 类的方法 f 输出为：&quot;, x.f())# 类有一个名为 __init__() 的特殊方法（构造方法），该方法在类实例化时会自动调用，像下面这样：# __init__() 方法可以有参数，参数通过 __init__() 传递到类的实例化操作上，self代表类的实例，而非类def __init__(self): self.data = []class Test: def prt(self): print(self) print(self.__class__)t = Test()t.prt()# ===方法===# def定义方法,与一般函数定义不同，类方法必须包含self参数且作为第一个参数，self代表类的实例# 类定义class people: # 定义基本属性 name = '' age = 0 # 定义私有属性,私有属性在类外部无法直接进行访问 __weight = 0 # 定义构造方法 def __init__(self, n, a, w): self.name = n self.age = a self.__weight = w def speak(self): print(&quot;%s 说: 我 %d 岁。&quot; % (self.name, self.age))# 实例化类p = people('runoob', 10, 30)p.speak()# ===继承===# 子类（派生类 DerivedClassName）会继承父类（基类 BaseClassName）的属性和方法。# class DerivedClassName(BaseClassName):# &lt;statement-1&gt;# .# .# .# &lt;statement-N&gt;# ===多继承===# class DerivedClassName(Base1, Base2, Base3):# &lt;statement-1&gt;# .# .# .# &lt;statement-N&gt;# 若是父类中有相同的方法名，而在子类使用时未指定，python从左至右搜索 即方法在子类中未找到时，从左到右查找父类中是否包含方法# ===方法重写===class Parent: # 定义父类 def myMethod(self): print('调用父类方法')class Child(Parent): # 定义子类 def myMethod(self): print('调用子类方法')c = Child() # 子类实例c.myMethod() # 子类调用重写方法super(Child, c).myMethod() # 用子类对象调用父类已被覆盖的方法# ===类属性与方法===# 类的私有属性# __private_attrs：两个下划线开头，声明该属性为私有，不能在类的外部被使用或直接访问。在类内部的方法中使用时 self.__private_attrs。## 类的方法# 在类的内部，使用 def 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 self，且为第一个参数，self 代表的是类的实例。# self 的名字并不是规定死的，也可以使用 this，但是最好还是按照约定使用 self。## 类的私有方法# __private_method：两个下划线开头，声明该方法为私有方法，只能在类的内部调用 ，不能在类的外部调用。self.__private_methods。# ==重载==class Vector: def __init__(self, a, b): self.a = a self.b = b def __str__(self): return 'Vector (%d, %d)' % (self.a, self.b) def __add__(self, other): return Vector(self.a + other.a, self.b + other.b)v1 = Vector(2, 10)v2 = Vector(5, -2)print(v1 + v2) 函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859'''函数'''# 你可以定义一个由自己想要功能的函数，以下是简单的规则：## 函数代码块以 def 关键词开头，后接函数标识符名称和圆括号 ()。# 任何传入参数和自变量必须放在圆括号中间，圆括号之间可以用于定义参数。# 函数的第一行语句可以选择性地使用文档字符串—用于存放函数说明。# 函数内容以冒号 : 起始，并且缩进。# return [表达式] 结束函数，选择性地返回一个值给调用方，不带表达式的 return 相当于返回 None。def max(a, b): if a &gt; b: return a else: return b# python 函数的参数传递：# 不可变类型：类似 C++ 的值传递，如整数、字符串、元组。如 fun(a)，传递的只是 a 的值，没有影响 a 对象本身。如果在 fun(a) 内部修改 a 的值，则是新生成一个 a 的对象。# 可变类型：类似 C++ 的引用传递，如 列表，字典。如 fun(la)，则是将 la 真正的传过去，修改后 fun 外部的 la 也会受影响# python 中一切都是对象，严格意义我们不能说值传递还是引用传递，我们应该说传不可变对象和传可变对象。# 可通过id()函数查看对象内存地址# 参数# 以下是调用函数时可使用的正式参数类型：# 必需参数【调用时的数量必须和声明时的一样】 def printme( str ):# 关键字参数【允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值】def printinfo( name, age ):# 默认参数【如果没有传递参数，则会使用默认参数】def printinfo( name, age = 35 ):# 不定长参数 【加了星号 * 的参数会以元组(tuple)的形式导入，存放所有未命名的变量参数，没有指定参数，它就是一个空元组。我们也可以不向函数传递未命名的变量，加了两个星号 ** 的参数会以字典的形式导入，如果单独出现星号 * 后的参数必须用关键字传入】def functionname([formal_args,] *var_args_tuple ):'''匿名函数'''# lambda [arg1 [,arg2,.....argn]]:expression# 可写函数说明sum = lambda arg1, arg2: arg1 + arg2# 调用sum函数print(&quot;相加后的值为 : &quot;, sum(10, 20))print(&quot;相加后的值为 : &quot;, sum(20, 20))'''强制位置参数'''# 在以下的例子中，形参 a 和 b 必须使用指定位置参数，c 或 d 可以是位置形参或关键字形参，而 e 或 f 要求为关键字形参:def f(a, b, /, c, d, *, e, f): print(a, b, c, d, e, f)# 以下使用方法是正确的:f(10, 20, 30, d=40, e=50, f=60)# 以下使用方法会发生错误:f(10, b=20, c=30, d=40, e=50, f=60) # b 不能使用关键字参数的形式f(10, 20, 30, 40, 50, f=60) # e 必须使用关键字参数的形式 文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119&quot;&quot;&quot;文件&quot;&quot;&quot;# 打开文件返回文件对象# file: 必需，文件路径（相对或者绝对路径）。# mode: 可选，文件打开模式# buffering: 设置缓冲# encoding: 一般使用utf8# errors: 报错级别# newline: 区分换行符# closefd: 传入的file参数类型# opener: 设置自定义开启器，开启器的返回值必须是一个打开的文件描述符。# mode 参数有：# 模式 描述# t 文本模式 (默认)。# x 写模式，新建一个文件，如果该文件已存在则会报错。# b 二进制模式。# + 打开一个文件进行更新(可读可写)。# U 通用换行模式（Python 3 不支持）。# r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。# rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。# r+ 打开一个文件用于读写。文件指针将会放在文件的开头。# rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。# w 打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。# wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。# w+ 打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。# wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。# a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。# ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。# a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。# ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。file = open('filetest.txt', mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)# file 对象常用的函数：# file.close() 关闭文件。关闭后文件不能再进行读写操作。# file.flush() 刷新文件内部缓冲，直接把内部缓冲区的数据立刻写入文件, 而不是被动的等待输出缓冲区写入。# file.fileno() 返回一个整型的文件描述符(file descriptor FD 整型), 可以用在如os模块的read方法等一些底层操作上。# file.isatty() 如果文件连接到一个终端设备返回 True，否则返回 False。# file.next() Python 3 中的 File 对象不支持 next() 方法。 返回文件下一行。# file.read([size]) 从文件读取指定的字节数，如果未给定或为负则读取所有。# file.readline([size]) 读取整行，包括 &quot;\\n&quot; 字符。# file.readlines([sizeint]) 读取所有行并返回列表，若给定sizeint&gt;0，返回总和大约为sizeint字节的行, 实际读取值可能比 sizeint 较大, 因为需要填充缓冲区。# file.seek(offset[, whence]) 移动文件读取指针到指定位置# file.tell() 返回文件当前位置。# file.truncate([size]) 从文件的首行首字符开始截断，截断文件为 size 个字符，无 size 表示从当前位置截断；截断之后后面的所有字符被删除，其中 windows 系统下的换行代表2个字符大小。# file.write(str) 将字符串写入文件，返回的是写入的字符长度。# file.writelines(sequence) 向文件写入一个序列字符串列表，如果需要换行则要自己加入每行的换行符。&quot;&quot;&quot;文件和目录&quot;&quot;&quot;# os 模块提供了非常丰富的方法用来处理文件和目录。常用的方法如下表所示：## 序号 方法及描述# os.access(path, mode) 检验权限模式# os.chdir(path) 改变当前工作目录# os.chflags(path, flags) 设置路径的标记为数字标记。# os.chmod(path, mode) 更改权限# os.chown(path, uid, gid) 更改文件所有者# os.chroot(path) 改变当前进程的根目录# os.close(fd) 关闭文件描述符 fd# os.closerange(fd_low, fd_high) 关闭所有文件描述符，从 fd_low (包含) 到 fd_high (不包含), 错误会忽略# os.dup(fd) 复制文件描述符 fd# os.dup2(fd, fd2) 将一个文件描述符 fd 复制到另一个 fd2# os.fchdir(fd) 通过文件描述符改变当前工作目录# os.fchmod(fd, mode) 改变一个文件的访问权限，该文件由参数fd指定，参数mode是Unix下的文件访问权限。# os.fchown(fd, uid, gid) 修改一个文件的所有权，这个函数修改一个文件的用户ID和用户组ID，该文件由文件描述符fd指定。# os.fdatasync(fd) 强制将文件写入磁盘，该文件由文件描述符fd指定，但是不强制更新文件的状态信息。# os.fdopen(fd[, mode[, bufsize]]) 通过文件描述符 fd 创建一个文件对象，并返回这个文件对象# os.fpathconf(fd, name) 返回一个打开的文件的系统配置信息。name为检索的系统配置的值，它也许是一个定义系统值的字符串，这些名字在很多标准中指定（POSIX.1, Unix 95, Unix 98, 和其它）。# os.fstat(fd) 返回文件描述符fd的状态，像stat()。# os.fstatvfs(fd) 返回包含文件描述符fd的文件的文件系统的信息，Python 3.3 相等于 statvfs()。# os.fsync(fd) 强制将文件描述符为fd的文件写入硬盘。# os.ftruncate(fd, length) 裁剪文件描述符fd对应的文件, 所以它最大不能超过文件大小。# os.getcwd() 返回当前工作目录# os.getcwdb() 返回一个当前工作目录的Unicode对象# os.isatty(fd) 如果文件描述符fd是打开的，同时与tty(-like)设备相连，则返回true, 否则False。# os.lchflags(path, flags) 设置路径的标记为数字标记，类似 chflags()，但是没有软链接# os.lchmod(path, mode) 修改连接文件权限# os.lchown(path, uid, gid) 更改文件所有者，类似 chown，但是不追踪链接。# os.link(src, dst) 创建硬链接，名为参数 dst，指向参数 src# os.listdir(path) 返回path指定的文件夹包含的文件或文件夹的名字的列表。# os.lseek(fd, pos, how) 设置文件描述符 fd当前位置为pos, how方式修改: SEEK_SET 或者 0 设置从文件开始的计算的pos; SEEK_CUR或者 1 则从当前位置计算; os.SEEK_END或者2则从文件尾部开始. 在unix，Windows中有效# os.lstat(path) 像stat(),但是没有软链接# os.major(device) 从原始的设备号中提取设备major号码 (使用stat中的st_dev或者st_rdev field)。# os.makedev(major, minor) 以major和minor设备号组成一个原始设备号# os.makedirs(path[, mode]) 递归文件夹创建函数。像mkdir(), 但创建的所有intermediate-level文件夹需要包含子文件夹。# os.minor(device) 从原始的设备号中提取设备minor号码 (使用stat中的st_dev或者st_rdev field )。# os.mkdir(path[, mode]) 以数字mode的mode创建一个名为path的文件夹.默认的 mode 是 0777 (八进制)。# os.mkfifo(path[, mode]) 创建命名管道，mode 为数字，默认为 0666 (八进制)# os.mknod(filename[, mode=0600, device]) 创建一个名为filename文件系统节点（文件，设备特别文件或者命名pipe）。# os.open(file, flags[, mode]) 打开一个文件，并且设置需要的打开选项，mode参数是可选的# os.openpty() 打开一个新的伪终端对。返回 pty 和 tty的文件描述符。# os.pathconf(path, name) 返回相关文件的系统配置信息。# os.pipe() 创建一个管道. 返回一对文件描述符(r, w) 分别为读和写# os.popen(command[, mode[, bufsize]]) 从一个 command 打开一个管道# os.read(fd, n) 从文件描述符 fd 中读取最多 n 个字节，返回包含读取字节的字符串，文件描述符 fd对应文件已达到结尾, 返回一个空字符串。# os.readlink(path) 返回软链接所指向的文件# os.remove(path) 删除路径为path的文件。如果path 是一个文件夹，将抛出OSError; 查看下面的rmdir()删除一个 directory。# os.removedirs(path) 递归删除目录。# os.rename(src, dst) 重命名文件或目录，从 src 到 dst# os.renames(old, new) 递归地对目录进行更名，也可以对文件进行更名。# os.rmdir(path) 删除path指定的空目录，如果目录非空，则抛出一个OSError异常。# os.stat(path) 获取path指定的路径的信息，功能等同于C API中的stat()系统调用。# os.stat_float_times([newvalue]) 决定stat_result是否以float对象显示时间戳# os.statvfs(path) 获取指定路径的文件系统统计信息# os.symlink(src, dst) 创建一个软链接# os.tcgetpgrp(fd) 返回与终端fd（一个由os.open()返回的打开的文件描述符）关联的进程组# os.tcsetpgrp(fd, pg) 设置与终端fd（一个由os.open()返回的打开的文件描述符）关联的进程组为pg。# os.tempnam([dir[, prefix]]) Python3 中已删除。返回唯一的路径名用于创建临时文件。# os.tmpfile() Python3 中已删除。返回一个打开的模式为(w+b)的文件对象 .这文件对象没有文件夹入口，没有文件描述符，将会自动删除。# os.tmpnam() Python3 中已删除。为创建一个临时文件返回一个唯一的路径# os.ttyname(fd) 返回一个字符串，它表示与文件描述符fd 关联的终端设备。如果fd 没有与终端设备关联，则引发一个异常。# os.unlink(path) 删除文件路径# os.utime(path, times) 返回指定的path文件的访问和修改的时间。# os.walk(top[, topdown=True[, onerror=None[, followlinks=False]]]) 输出在文件夹中的文件名通过在树中游走，向上或者向下。# os.write(fd, str) 写入字符串到文件描述符 fd中. 返回实际写入的字符串长度# os.path 模块 获取文件的属性信息。# os.pardir() 获取当前目录的父目录，以字符串形式显示目录名。 语法错误和异常 1234567891011121314151617181920212223242526&quot;&quot;&quot;语法错误和异常&quot;&quot;&quot;# 语法错误 SyntaxError# 异常 ZeroDivisionError，NameError 和 TypeError# 异常处理# ---try/except---# 一个except子句可以同时处理多个异常，这些异常将被放在一个括号里成为一个元组，例如:# except (RuntimeError, TypeError, NameError):while True: try: x = int(input(&quot;请输入一个数字: &quot;)) break except ValueError: print(&quot;您输入的不是数字，请再次尝试输入！&quot;)# ----try/except...else---else 子句将在 try 子句没有发生任何异常的时候执行# ---try-finally----# 抛出异常 raise [Exception [, args [, traceback]]]x = 10if x &gt; 5: raise Exception('x 不能大于 5。x 的值为: {}'.format(x))# 用户自定义异常 通过创建一个新的异常类来拥有自己的异常。异常类继承自 Exception 类，可以直接继承，或者间接继承# with 语句就可以保证诸如文件之类的对象在使用完之后一定会正确的执行他的清理方法with open(&quot;myfile.txt&quot;) as f: for line in f: print(line, end=&quot;&quot;) Mysql 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import mysql.connector# python -m pip install mysql-connector 安装连接驱动# python -m pip install mysql-connector-python# pip uninstall mysql-connector 卸载mydb = mysql.connector.connect( host=&quot;localhost&quot;, # 数据库主机地址 user=&quot;root&quot;, # 数据库用户名 passwd=&quot;root&quot; # 数据库密码 # auth_plugin='mysql_native_password' # database=&quot;runoob_db&quot; #有则直接连接数据库)print(mydb)# 创建数据库mycursor = mydb.cursor()mycursor.execute(&quot;CREATE DATABASE runoob_db&quot;)# 输出所有数据库列表mycursor.execute(&quot;SHOW DATABASES&quot;)for x in mycursor: print(x)# 创建表mycursor.execute(&quot;CREATE TABLE sites (name VARCHAR(255), url VARCHAR(255))&quot;)# mycursor.execute(sql语句)# 增sql = &quot;INSERT INTO sites (name, url) VALUES (%s, %s)&quot;val = (&quot;RUNOOB&quot;, &quot;https://www.runoob.com&quot;)mycursor.execute(sql, val)mydb.commit() # 数据表内容有更新，必须使用到该语句print(mycursor.rowcount, &quot;记录插入成功。&quot;)# 批量增sql = &quot;INSERT INTO sites (name, url) VALUES (%s, %s)&quot;val = [ ('Google', 'https://www.google.com'), ('Github', 'https://www.github.com'), ('Taobao', 'https://www.taobao.com'), ('stackoverflow', 'https://www.stackoverflow.com/')]mycursor.executemany(sql, val)mydb.commit() # 数据表内容有更新，必须使用到该语句print(mycursor.rowcount, &quot;记录插入成功, ID:&quot;, mycursor.lastrowid)# 查mycursor.execute(&quot;SELECT * FROM sites&quot;)myresult = mycursor.fetchall() # fetchall() 获取所有记录myresult = mycursor.fetchone() #获取一条for x in myresult: print(x)# 防sql注入sql = &quot;SELECT * FROM sites WHERE name = %s&quot;na = (&quot;RUNOOB&quot;,)mycursor.execute(sql, na)myresult = mycursor.fetchall()for x in myresult: print(x)#删sql = &quot;DELETE FROM sites WHERE name = 'stackoverflow'&quot;mycursor.execute(sql)mydb.commit()print(mycursor.rowcount, &quot; 条记录删除&quot;)# 改sql = &quot;UPDATE sites SET name = 'ZH' WHERE name = 'Zhihu'&quot;mycursor.execute(sql)mydb.commit()print(mycursor.rowcount, &quot; 条记录被修改&quot;) 网络编程 123456789101112131415161718192021222324252627282930313233343536373839&quot;&quot;&quot;网络编程&quot;&quot;&quot;# 低级别的网络服务支持基本的 Socket，它提供了标准的 BSD Sockets API，可以访问底层操作系统 Socket 接口的全部方法。# 高级别的网络服务模块 SocketServer， 它提供了服务器中心类，可以简化网络服务器的开发。# socket()# socket.socket([family[, type[, proto]]])# family: 套接字家族可以使 AF_UNIX 或者 AF_INET。# type:套接字类型可以根据是面向连接的还是非连接分为SOCK_STREAM或SOCK_DGRAM。# protocol: 一般不填默认为 0。# Socket 对象(内建)方法# 函数 描述# 服务器端套接字-----------# s.bind() 绑定地址（host,port）到套接字， 在 AF_INET下，以元组（host,port）的形式表示地址。# s.listen() 开始 TCP 监听。backlog 指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为 1，大部分应用程序设为 5 就可以了。# s.accept() 被动接受TCP客户端连接,(阻塞式)等待连接的到来# 客户端套接字-----------# s.connect() 主动初始化TCP服务器连接，。一般address的格式为元组（hostname,port），如果连接出错，返回socket.error错误。# s.connect_ex() connect()函数的扩展版本,出错时返回出错码,而不是抛出异常# 公共用途的套接字函数----------# s.recv() 接收 TCP 数据，数据以字符串形式返回，bufsize 指定要接收的最大数据量。flag 提供有关消息的其他信息，通常可以忽略。# s.send() 发送 TCP 数据，将 string 中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于 string 的字节大小。# s.sendall() 完整发送 TCP 数据。将 string 中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回 None，失败则抛出异常。# s.recvfrom() 接收 UDP 数据，与 recv() 类似，但返回值是（data,address）。其中 data 是包含接收数据的字符串，address 是发送数据的套接字地址。# s.sendto() 发送 UDP 数据，将数据发送到套接字，address 是形式为（ipaddr，port）的元组，指定远程地址。返回值是发送的字节数。# s.close() 关闭套接字# s.getpeername() 返回连接套接字的远程地址。返回值通常是元组（ipaddr,port）。# s.getsockname() 返回套接字自己的地址。通常是一个元组(ipaddr,port)# s.setsockopt(level,optname,value) 设置给定套接字选项的值。# s.getsockopt(level,optname[.buflen]) 返回套接字选项的值。# s.settimeout(timeout) 设置套接字操作的超时期，timeout是一个浮点数，单位是秒。值为None表示没有超时期。一般，超时期应该在刚创建套接字时设置，因为它们可能用于连接的操作（如connect()）# s.gettimeout() 返回当前超时期的值，单位是秒，如果没有设置超时期，则返回None。# s.fileno() 返回套接字的文件描述符。# s.setblocking(flag) 如果flag为0，则将套接字设为非阻塞模式，否则将套接字设为阻塞模式（默认值）。非阻塞模式下，如果调用recv()没有发现任何数据，或send()调用无法立即发送数据，那么将引起socket.error异常。# s.makefile() 创建一个与该套接字相关连的文件 123456789101112131415161718192021import socketimport sys# 创建 socket 对象s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 获取本地主机名host = socket.gethostname()# 设置端口号port = 9999# 连接服务，指定主机和端口s.connect((host, port))# 接收小于 1024 字节的数据msg = s.recv(1024)s.close()print (msg.decode('utf-8')) 123456789101112131415161718192021222324252627import socketimport sys# 创建 socket 对象serversocket = socket.socket( socket.AF_INET, socket.SOCK_STREAM)# 获取本地主机名host = socket.gethostname()port = 9999# 绑定端口号serversocket.bind((host, port))# 设置最大连接数，超过后排队serversocket.listen(5)while True: # 建立客户端连接 clientsocket, addr = serversocket.accept() print(&quot;连接地址: %s&quot; % str(addr)) msg = '欢迎访问菜鸟教程！' + &quot;\\r\\n&quot; clientsocket.send(msg.encode('utf-8')) clientsocket.close() SMTP 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101&quot;&quot;&quot;SMTP&quot;&quot;&quot;# SMTP（Simple Mail Transfer Protocol）即简单邮件传输协议,它是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。# python的smtplib提供了一种很方便的途径发送电子邮件。它对smtp协议进行了简单的封装。# Python创建 SMTP 对象语法如下：# import smtplib# smtpObj = smtplib.SMTP( [host [, port [, local_hostname]]] )# 参数说明：# host: SMTP 服务器主机。 你可以指定主机的ip地址或者域名如:runoob.com，这个是可选参数。# port: 如果你提供了 host 参数, 你需要指定 SMTP 服务使用的端口号，一般情况下SMTP端口号为25。# local_hostname: 如果SMTP在你的本机上，你只需要指定服务器地址为 localhost 即可。# Python SMTP对象使用sendmail方法发送邮件，语法如下：# SMTP.sendmail(from_addr, to_addrs, msg[, mail_options, rcpt_options]# 参数说明：# from_addr: 邮件发送者地址。# to_addrs: 字符串列表，邮件发送地址。# msg: 发送消息# 这里要注意一下第三个参数，msg是字符串，表示邮件。我们知道邮件一般由标题，发信人，收件人，邮件内容，附件等构成，发送邮件的时候，要注意msg的格式。这个格式就是smtp协议中定义的格式。import smtplibfrom email.mime.image import MIMEImagefrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.header import Headermy_sender='714416426@qq.com' # 发件人邮箱账号my_pass = '11111111' # 发件人邮箱密码my_user='714416426@qq.com' # 收件人邮箱账号，我这边发送给自己sender = 'from@runoob.com'receivers = ['714416426@qq.com'] # 接收邮件，可设置为你的QQ邮箱或者其他邮箱msgRoot = MIMEMultipart('related')msgRoot['From'] = Header(&quot;菜鸟教程&quot;, 'utf-8')msgRoot['To'] = Header(&quot;测试&quot;, 'utf-8')subject = 'Python SMTP 邮件测试'msgRoot['Subject'] = Header(subject, 'utf-8')# 发送html内容mail_msg = &quot;&quot;&quot;&lt;p&gt;Python 邮件发送测试...&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://www.runoob.com&quot;&gt;这是一个链接&lt;/a&gt;&lt;/p&gt;&quot;&quot;&quot;message = MIMEText(mail_msg, 'html', 'utf-8')# 三个参数：第一个为文本内容，第二个 plain 设置文本格式，第三个 utf-8 设置编码message = MIMEText('Python 邮件发送测试...', 'plain', 'utf-8')message['From'] = Header(&quot;菜鸟教程&quot;, 'utf-8') # 发送者message['To'] = Header(&quot;测试&quot;, 'utf-8') # 接收者subject = 'Python SMTP 邮件测试'message['Subject'] = Header(subject, 'utf-8')# 发送带附件内容# # 构造附件1，传送当前目录下的 test.txt 文件# att1 = MIMEText(open('test.txt', 'rb').read(), 'base64', 'utf-8')# att1[&quot;Content-Type&quot;] = 'application/octet-stream'# # 这里的filename可以任意写，写什么名字，邮件中显示什么名字# att1[&quot;Content-Disposition&quot;] = 'attachment; filename=&quot;test.txt&quot;'# message.attach(att1)## # 构造附件2，传送当前目录下的 runoob.txt 文件# att2 = MIMEText(open('runoob.txt', 'rb').read(), 'base64', 'utf-8')# att2[&quot;Content-Type&quot;] = 'application/octet-stream'# att2[&quot;Content-Disposition&quot;] = 'attachment; filename=&quot;runoob.txt&quot;'# message.attach(att2)# 文本中添加图片# msgAlternative = MIMEMultipart('alternative')# msgRoot.attach(msgAlternative)# mail_msg = &quot;&quot;&quot;# &lt;p&gt;Python 邮件发送测试...&lt;/p&gt;# &lt;p&gt;&lt;a href=&quot;http://www.runoob.com&quot;&gt;菜鸟教程链接&lt;/a&gt;&lt;/p&gt;# &lt;p&gt;图片演示：&lt;/p&gt;# &lt;p&gt;&lt;img src=&quot;cid:image1&quot;&gt;&lt;/p&gt;# &quot;&quot;&quot;# msgAlternative.attach(MIMEText(mail_msg, 'html', 'utf-8'))## # 指定图片为当前目录# fp = open('test.png', 'rb')# msgImage = MIMEImage(fp.read())# fp.close()## # 定义图片 ID，在 HTML 文本中引用# msgImage.add_header('Content-ID', '&lt;image1&gt;')# msgRoot.attach(msgImage)try: smtpObj = smtplib.SMTP('localhost') smtpObj.sendmail(my_sender, receivers, message.as_string()) print(&quot;邮件发送成功&quot;)except smtplib.SMTPException: print(&quot;Error: 无法发送邮件&quot;) 多线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101&quot;&quot;&quot;多线程：函数或者用类来包装线程对象&quot;&quot;&quot;# 函数式：调用thread模块中的start_new_thread()函数来产生新线程。语法如下:# thread.start_new_thread ( function, args[, kwargs] )# 参数说明:# function - 线程函数。# args - 传递给线程函数的参数,他必须是个tuple类型。# kwargs - 可选参数。# 两个模块# _thread# threading(推荐使用)import _threadimport time# 为线程定义一个函数def print_time( threadName, delay): count = 0 while count &lt; 5: time.sleep(delay) count += 1 print (&quot;%s: %s&quot; % ( threadName, time.ctime(time.time()) ))# 创建两个线程try: _thread.start_new_thread( print_time, (&quot;Thread-1&quot;, 2, ) ) _thread.start_new_thread( print_time, (&quot;Thread-2&quot;, 4, ) )except: print (&quot;Error: 无法启动线程&quot;)while 1: pass# _thread 提供了低级别的、原始的线程以及一个简单的锁，它相比于 threading 模块的功能还是比较有限的。## threading 模块除了包含 _thread 模块中的所有方法外，还提供的其他方法：## threading.currentThread(): 返回当前的线程变量。# threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。# threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。# 除了使用方法外，线程模块同样提供了Thread类来处理线程，Thread类提供了以下方法:## run(): 用以表示线程活动的方法。# start():启动线程活动。# join([time]): 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。# isAlive(): 返回线程是否活动的。# getName(): 返回线程名。# setName(): 设置线程名。import threadingexitFlag = 0class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (&quot;开始线程：&quot; + self.name) print_time(self.name, self.counter, 5) print (&quot;退出线程：&quot; + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (&quot;%s: %s&quot; % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, &quot;Thread-1&quot;, 1)thread2 = myThread(2, &quot;Thread-2&quot;, 2)# 开启新线程thread1.start()thread2.start()thread1.join()thread2.join()print (&quot;退出主线程&quot;)# 线程同步# 使用 Thread 对象的 Lock 和 Rlock 可以实现简单的线程同步，这两个对象都有 acquire 方法和 release 方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到 acquire 和 release 方法之间# 线程优先级队列（ Queue）# Python 的 Queue 模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列 PriorityQueue。# 这些队列都实现了锁原语，能够在多线程中直接使用，可以使用队列来实现线程间的同步。# Queue 模块中的常用方法:# Queue.qsize() 返回队列的大小# Queue.empty() 如果队列为空，返回True,反之False# Queue.full() 如果队列满了，返回True,反之False# Queue.full 与 maxsize 大小对应# Queue.get([block[, timeout]])获取队列，timeout等待时间# Queue.get_nowait() 相当Queue.get(False)# Queue.put(item) 写入队列，timeout等待时间# Queue.put_nowait(item) 相当Queue.put(item, False)# Queue.task_done() 在完成一项工作之后，Queue.task_done()函数向任务已经完成的队列发送一个信号# Queue.join() 实际上意味着等到队列为空，再执行别的操作 urllib 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&quot;&quot;&quot;urllib 库用于操作网页 URL，并对网页的内容进行抓取处理。&quot;&quot;&quot;# urllib.request - 打开和读取 URL。# urllib.error - 包含 urllib.request 抛出的异常。# urllib.parse - 解析 URL。# urllib.robotparser - 解析 robots.txt 文件# urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)# url：url 地址。# data：发送到服务器的其他数据对象，默认为 None。# timeout：设置访问超时时间。# cafile 和 capath：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到。# cadefault：已经被弃用。# context：ssl.SSLContext类型，用来指定 SSL 设置。from urllib.request import urlopenmyURL = urlopen(&quot;https://www.runoob.com/&quot;)print(myURL.read())print(myURL.read(600))print(myURL.readline())lines = myURL.readlines()for line in lines: print(line)print(myURL.getcode())f = open(&quot;runoob_urllib_test.html&quot;, &quot;wb&quot;)content = myURL.read() # 读取网页内容f.write(content)f.close()import urllib.requestencode_url = urllib.request.quote(&quot;https://www.runoob.com/&quot;) # 编码print(encode_url)unencode_url = urllib.request.unquote(encode_url) # 解码print(unencode_url)# 模拟头部信息# class urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)# url：url 地址。# data：发送到服务器的其他数据对象，默认为 None。# headers：HTTP 请求的头部信息，字典格式。# origin_req_host：请求的主机地址，IP 或域名。# unverifiable：很少用整个参数，用于设置网页是否需要验证，默认是False。。# method：请求方法， 如 GET、POST、DELETE、PUT等。import urllib.parseurl = 'https://www.runoob.com/?s=' # 菜鸟教程搜索页面keyword = 'Python 教程'key_code = urllib.request.quote(keyword) # 对请求进行编码url_all = url+key_codeheader = { 'User-Agent':'Mozilla/5.0 (X11; Fedora; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'} #头部信息request = urllib.request.Request(url_all,headers=header)reponse = urllib.request.urlopen(request).read()fh = open(&quot;./urllib_test_runoob_search.html&quot;,&quot;wb&quot;) # 将文件写入到当前目录中fh.write(reponse)fh.close() XML解析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143&quot;&quot;&quot;XML解析&quot;&quot;&quot;# SAX 是一种基于事件驱动的API。# 利用 SAX 解析 XML 文档牵涉到两个部分: 解析器和事件处理器。# 解析器负责读取 XML 文档，并向事件处理器发送事件，如元素开始跟元素结束事件。# 而事件处理器则负责对事件作出响应，对传递的 XML 数据进行处理。# 1、对大型文件进行处理；# 2、只需要文件的部分内容，或者只需从文件中得到特定信息。# 3、想建立自己的对象模型的时候。# 在 Python 中使用 sax 方式处理 xml 要先引入 xml.sax 中的 parse 函数，还有 xml.sax.handler 中的 ContentHandler。# ContentHandler 类方法介绍# characters(content) 方法# 调用时机：# 从行开始，遇到标签之前，存在字符，content 的值为这些字符串。# 从一个标签，遇到下一个标签之前， 存在字符，content 的值为这些字符串。# 从一个标签，遇到行结束符之前，存在字符，content 的值为这些字符串。# 标签可以是开始标签，也可以是结束标签。# startDocument() 方法# 文档启动的时候调用。# endDocument() 方法# 解析器到达文档结尾时调用。# startElement(name, attrs) 方法# 遇到XML开始标签时调用，name 是标签的名字，attrs 是标签的属性值字典。# endElement(name) 方法# 遇到XML结束标签时调用。# make_parser 方法# 以下方法创建一个新的解析器对象并返回。# xml.sax.make_parser( [parser_list] )# 参数说明:# parser_list - 可选参数，解析器列表# parser 方法# 以下方法创建一个 SAX 解析器并解析xml文档：# xml.sax.parse( xmlfile, contenthandler[, errorhandler])# 参数说明:# xmlfile - xml文件名# contenthandler - 必须是一个 ContentHandler 的对象# errorhandler - 如果指定该参数，errorhandler 必须是一个 SAX ErrorHandler 对象# parseString 方法# parseString 方法创建一个 XML 解析器并解析 xml 字符串：# xml.sax.parseString(xmlstring, contenthandler[, errorhandler])# 参数说明:# xmlstring - xml字符串# contenthandler - 必须是一个 ContentHandler 的对象# errorhandler - 如果指定该参数，errorhandler 必须是一个 SAX ErrorHandler对象import xml.sax# from xml.dom.minidom import parse# import xml.dom.minidom# 使用xml.dom解析xml# 文件对象模型（Document Object Model，简称DOM），是W3C组织推荐的处理可扩展置标语言的标准编程接口。# 一个 DOM 的解析器在解析一个 XML 文档时，一次性读取整个文档，把文档中所有元素保存在内存中的一个树结构里，之后你可以利用DOM 提供的不同的函数来读取或修改文档的内容和结构，也可以把修改过的内容写入xml文件。# python中用xml.dom.minidom来解析xml文件# 使用minidom解析器打开 XML 文档# DOMTree = xml.dom.minidom.parse(&quot;movies.xml&quot;)# collection = DOMTree.documentElement# if collection.hasAttribute(&quot;shelf&quot;):# print (&quot;Root element : %s&quot; % collection.getAttribute(&quot;shelf&quot;))## # 在集合中获取所有电影# movies = collection.getElementsByTagName(&quot;movie&quot;)## # 打印每部电影的详细信息# for movie in movies:# print (&quot;*****Movie*****&quot;)# if movie.hasAttribute(&quot;title&quot;):# print (&quot;Title: %s&quot; % movie.getAttribute(&quot;title&quot;))## type = movie.getElementsByTagName('type')[0]# print (&quot;Type: %s&quot; % type.childNodes[0].data)# format = movie.getElementsByTagName('format')[0]# print (&quot;Format: %s&quot; % format.childNodes[0].data)# rating = movie.getElementsByTagName('rating')[0]# print (&quot;Rating: %s&quot; % rating.childNodes[0].data)# description = movie.getElementsByTagName('description')[0]# print (&quot;Description: %s&quot; % description.childNodes[0].data)class MovieHandler(xml.sax.ContentHandler): def __init__(self): self.CurrentData = &quot;&quot; self.type = &quot;&quot; self.format = &quot;&quot; self.year = &quot;&quot; self.rating = &quot;&quot; self.stars = &quot;&quot; self.description = &quot;&quot; # 元素开始调用 def startElement(self, tag, attributes): self.CurrentData = tag if tag == &quot;movie&quot;: print(&quot;*****Movie*****&quot;) title = attributes[&quot;title&quot;] print(&quot;Title:&quot;, title) # 元素结束调用 def endElement(self, tag): if self.CurrentData == &quot;type&quot;: print(&quot;Type:&quot;, self.type) elif self.CurrentData == &quot;format&quot;: print(&quot;Format:&quot;, self.format) elif self.CurrentData == &quot;year&quot;: print(&quot;Year:&quot;, self.year) elif self.CurrentData == &quot;rating&quot;: print(&quot;Rating:&quot;, self.rating) elif self.CurrentData == &quot;stars&quot;: print(&quot;Stars:&quot;, self.stars) elif self.CurrentData == &quot;description&quot;: print(&quot;Description:&quot;, self.description) self.CurrentData = &quot;&quot; # 读取字符时调用 def characters(self, content): if self.CurrentData == &quot;type&quot;: self.type = content elif self.CurrentData == &quot;format&quot;: self.format = content elif self.CurrentData == &quot;year&quot;: self.year = content elif self.CurrentData == &quot;rating&quot;: self.rating = content elif self.CurrentData == &quot;stars&quot;: self.stars = content elif self.CurrentData == &quot;description&quot;: self.description = contentif (__name__ == &quot;__main__&quot;): # 创建一个 XMLReader parser = xml.sax.make_parser() # 关闭命名空间 parser.setFeature(xml.sax.handler.feature_namespaces, 0) # 重写 ContextHandler Handler = MovieHandler() parser.setContentHandler(Handler) parser.parse(&quot;movies.xml&quot;) 应用领域 Web and Internet Development Database Access Desktop GUIs Scientific &amp; Numeric Education Network Programming Software &amp; Game Development 爬虫 WEB开发 图形处理 深度学习 数据分析","link":"/2021/07/06/Draft/2021/Python3%E5%AD%A6%E4%B9%A0/"},{"title":"魑魅先生 | Redis","text":"工具 命令查询 常用 数据类型 String Hash List Set ZSet Geospatial Hyperloglog Bitmap 特点 字符串，整数或浮点数 包含键（string ）值对的无序散列表 链表上的节点字符串元素 各不相同的字符串元素 带分数的有序集合 地理位置 基数统计不占内存记录网站UV Bitmap 位图，数据结构！二进制位记录，0 和 1 两个状态 增 set hset lpush，rpush sadd zadd geoadd pfadd setbit 取 get hget （取单个） lrange取区间值lpop左取rpop 右取 smembers 取所有 zscore单取 zrange 范围取 zrevrange 升序取zrangebyscore 所有降序取zrevrangebyscore 所有升序取 geoposgeodist（两点距离）georadius（点附近点，可数量限制） 删 del hdel srem zrem 取旧改新 getset 自增 incr （可指定 HINCRBY增加指定步长 自减 decr （可指定 追加 append 长度 strlen hlen llen zcard pfcount（不重复数量） bitcount(计算状态数量) 批量同时设置一个或多个 key-value 对 mset hmset 返回所有一个或多个给定 key 的值 mget hmget 获取对象中所有的键值对 hgetall （取所有） 判断元素是否存在 hexists sismember 获取字段名 hkeys 获取字段值 hvals 集合运算 sunion 并集，sinter 交集，sdiff 交差 pfmerge(合并) 应用场景 Nosql由来 单机mysql mysql+缓存+垂直拆分 主从读写分离 分表分库+水平拆分+mysql集群 现在用户社交网络数据成倍增长，sql难以支撑 简介 Redis（Remote Dictionary Server）远程字典服务 免费开源的，C语言编写，提供多种语言使用，支持网络，可持久化，遵守 BSD 协议，是一个高性能的 key-value 数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis 优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 Redis与其他key-value存储有什么不同？ Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 redis的应用场景有哪些 1、会话高速缓存（最常用） 2、消息队列，比如支付 3、活动排行榜或计数 4、发布、订阅消息（消息通知） 5、商品列表、评论列表、计时器、计数器 6、地图信息分析 7、内存存储、持久化（rdb，aof） REmote DIctionary Server（远程字典服务器），开源，C语言编写 NoSQL（Not Only SQL）非关系型数据库 不需要固定模式，无需多于操作就可以横向操作 3V+3高 大数据时代3V（描述问题） 海量Volume 多样Variety 实时Velocity 互联网需求3高（对程序要求） 高并发 高可扩 高性能 经典应用 阿里巴巴 四大分类 KV键值对 文档型数据库 列存储数据库 图关系数据库（图结构） CAP C：Consistency（强一致性） A:Availability（可用性） P：Partition tolerance（分区容错性） 三进二（C必实现） CA 单点集群，满足一致性 CP AP BASE 基本可用（Basically Available） 软状态（Soft state） 最终一致性（Eventually consistent） 分布式与集群 子主题 1 ACID关系型数据库 Redis 安装 windows 企业里面几乎不用windows开发Redis https://github.com/tporadowski/redis/releases redis-server.exe redis.windows.conf 另启一个 cmd 窗口，原来的不要关闭，不然就无法访问服务端了（可直接设置为服务自启动） redis-cli.exe -h 127.0.0.1 -p 6379 set myKey abc get myKey Linux 下载 == 解压（opt） == 基本环境安装【yum install gcc-c++】== make == make install == redis默认安装路径/usr/local/bin == 拷贝redis的conf文件使用拷贝配置文件启动 == daemonize改为yes改为后台启动 == 启动服务redis-server redisconfig/redis.conf == 客户端连接 redis-cli -p 6379 == ping 测试连接 === 查看redis进程是否开启 ps -ef|grep redis == shutdown关闭服务 redis-benchmark性能测试 可选参数： 测试：100个并发连接 100000请求 redis-benchmark -h localhost -p 6379 -c 100 -n 100000 基础知识 redis默认有16个数据库 默认使用的是第0个 可以使用 select 进行切换数据库！select 3 DBSIZE # 查看DB大小！ keys * # 查看数据库所有的key 清除当前数据库 flushdb 清除全部数据库的内容 FLUSHALL Redis 为什么单线程还这么快？ 1、误区1：高性能的服务器一定是多线程的？ 2、误区2：多线程（CPU上下文会切换！）一定比单线程效率高！ 先去CPU&gt;内存&gt;硬盘的速度要有所了解！ 核心：redis 是将所有的数据全部放在内存中的，所以说使用单线程去操作效率就是最高的，多线程 （CPU上下文会切换：耗时的操作！！！），对于内存系统来说，如果没有上下文切换效率就是最高 的！多次读写都是在一个CPU上的，在内存情况下，这个就是最佳的方案！ Redis 配置 Redis 的配置文件位于 Redis 安装目录下，文件名为 redis.conf(Windows 名为 redis.windows.conf)。 你可以通过 CONFIG 命令查看或设置配置项。 CONFIG GET CONFIG_SETTING_NAME CONFIG GET loglevel CONFIG GET * 编辑配置 可以通过修改 redis.conf 文件或使用 CONFIG set 命令来修改配置。 CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE CONFIG SET loglevel &quot;notice&quot; 参数说明 redis.conf 配置项说明如下： https://www.runoob.com/redis/redis-conf.html Redis 数据类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748127.0.0.1:6379&gt; keys * # 查看所有的key(empty list or set)127.0.0.1:6379&gt; set name kuangshen # set keyOK127.0.0.1:6379&gt; keys *1) &quot;name&quot;127.0.0.1:6379&gt; set age 1OK127.0.0.1:6379&gt; keys *1) &quot;age&quot;2) &quot;name&quot;127.0.0.1:6379&gt; EXISTS name # 判断当前的key是否存在(integer) 1127.0.0.1:6379&gt; EXISTS name1(integer) 0127.0.0.1:6379&gt; move name 1 # 移除当前的key(integer) 1127.0.0.1:6379&gt; keys *1) &quot;age&quot;127.0.0.1:6379&gt; set name qinjiangOK127.0.0.1:6379&gt; keys *1) &quot;age&quot;2) &quot;name&quot;127.0.0.1:6379&gt; clear127.0.0.1:6379&gt; keys *1) &quot;age&quot;2) &quot;name&quot;127.0.0.1:6379&gt; get name&quot;qinjiang&quot;127.0.0.1:6379&gt; EXPIRE name 10 # 设置key的过期时间，单位是秒(integer) 1127.0.0.1:6379&gt; ttl name # 查看当前key的剩余时间(integer) 4127.0.0.1:6379&gt; ttl name(integer) 3127.0.0.1:6379&gt; ttl name(integer) 2127.0.0.1:6379&gt; ttl name(integer) 1127.0.0.1:6379&gt; ttl name(integer) -2127.0.0.1:6379&gt; get name(nil)127.0.0.1:6379&gt; type name # 查看当前key的一个类型！string127.0.0.1:6379&gt; type agestring String（字符串） string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。 string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。 string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。 SET runoob &quot;菜鸟教程&quot; GET runoob 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132##########################################################################127.0.0.1:6379&gt; set key1 v1 # 设置值OK127.0.0.1:6379&gt; get key1 # 获得值&quot;v1&quot;127.0.0.1:6379&gt; keys * # 获得所有的key1) &quot;key1&quot;127.0.0.1:6379&gt; EXISTS key1 # 判断某一个key是否存在(integer) 1127.0.0.1:6379&gt; APPEND key1 &quot;hello&quot; # 追加字符串，如果当前key不存在，就相当于setkey(integer) 7127.0.0.1:6379&gt; get key1&quot;v1hello&quot;127.0.0.1:6379&gt; STRLEN key1 # 获取字符串的长度！(integer) 7127.0.0.1:6379&gt; APPEND key1 &quot;,kaungshen&quot;(integer) 17127.0.0.1:6379&gt; STRLEN key1(integer) 17127.0.0.1:6379&gt; get key1&quot;v1hello,kaungshen&quot;########################################################################### i++# 步长 i+=127.0.0.1:6379&gt; set views 0 # 初始浏览量为0OK127.0.0.1:6379&gt; get views&quot;0&quot;127.0.0.1:6379&gt; incr views # 自增1 浏览量变为1(integer) 1127.0.0.1:6379&gt; incr views(integer) 2127.0.0.1:6379&gt; get views&quot;2&quot;127.0.0.1:6379&gt; decr views # 自减1 浏览量-1(integer) 1127.0.0.1:6379&gt; decr views(integer) 0127.0.0.1:6379&gt; decr views(integer) -1127.0.0.1:6379&gt; get views&quot;-1&quot;127.0.0.1:6379&gt; INCRBY views 10 # 可以设置步长，指定增量！(integer) 9127.0.0.1:6379&gt; INCRBY views 10(integer) 19127.0.0.1:6379&gt; DECRBY views 5(integer) 14########################################################################### 字符串范围 range127.0.0.1:6379&gt; set key1 &quot;hello,kuangshen&quot; # 设置 key1 的值OK127.0.0.1:6379&gt; get key1&quot;hello,kuangshen&quot;127.0.0.1:6379&gt; GETRANGE key1 0 3 # 截取字符串 [0,3]&quot;hell&quot;127.0.0.1:6379&gt; GETRANGE key1 0 -1 # 获取全部的字符串 和 get key是一样的&quot;hello,kuangshen&quot;# 替换！127.0.0.1:6379&gt; set key2 abcdefgOK127.0.0.1:6379&gt; get key2&quot;abcdefg&quot;127.0.0.1:6379&gt; SETRANGE key2 1 xx # 替换指定位置开始的字符串！(integer) 7127.0.0.1:6379&gt; get key2&quot;axxdefg&quot;########################################################################### setex (set with expire) # 设置过期时间# setnx (set if not exist) # 不存在在设置 （在分布式锁中会常常使用！）127.0.0.1:6379&gt; setex key3 30 &quot;hello&quot; # 设置key3 的值为 hello,30秒后过期OK127.0.0.1:6379&gt; ttl key3(integer) 26127.0.0.1:6379&gt; get key3&quot;hello&quot;127.0.0.1:6379&gt; setnx mykey &quot;redis&quot; # 如果mykey 不存在，创建mykey(integer) 1127.0.0.1:6379&gt; keys *1) &quot;key2&quot;2) &quot;mykey&quot;3) &quot;key1&quot;127.0.0.1:6379&gt; ttl key3(integer) -2127.0.0.1:6379&gt; setnx mykey &quot;MongoDB&quot; # 如果mykey存在，创建失败！(integer) 0127.0.0.1:6379&gt; get mykey&quot;redis&quot;##########################################################################msetmget127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3 # 同时设置多个值OK127.0.0.1:6379&gt; keys *1) &quot;k1&quot;2) &quot;k2&quot;3) &quot;k3&quot;127.0.0.1:6379&gt; mget k1 k2 k3 # 同时获取多个值1) &quot;v1&quot;2) &quot;v2&quot;3) &quot;v3&quot;127.0.0.1:6379&gt; msetnx k1 v1 k4 v4 # msetnx 是一个原子性的操作，要么一起成功，要么一起失败！(integer) 0127.0.0.1:6379&gt; get k4(nil)# 对象set user:1 {name:zhangsan,age:3} # 设置一个user:1 对象 值为 json字符来保存一个对象！# 这里的key是一个巧妙的设计： user:{id}:{filed} , 如此设计在Redis中是完全OK了！127.0.0.1:6379&gt; mset user:1:name zhangsan user:1:age 2OK127.0.0.1:6379&gt; mget user:1:name user:1:age1) &quot;zhangsan&quot;2) &quot;2&quot;##########################################################################getset # 先get然后在set127.0.0.1:6379&gt; getset db redis # 如果不存在值，则返回 nil(nil)127.0.0.1:6379&gt; get db&quot;redis127.0.0.1:6379&gt; getset db mongodb # 如果存在值，获取原来的值，并设置新的值&quot;redis&quot;127.0.0.1:6379&gt; get db&quot;mongodb&quot; 数据结构是相同的！ String类似的使用场景：value除了是我们的字符串还可以是我们的数字！ 计数器 统计多单位的数量 粉丝数 对象缓存存储！ Hash（哈希） Redis hash 是一个键值(key=&gt;value)对集合。 Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 - DEL runoob 用于删除前面测试用过的 key，不然会报错：(error) WRONGTYPE Operation against a key holding the wrong kind of value - HMSET 设置了两个 field=&gt;value 对, HGET 获取对应 field 对应的 value。 每个 hash 可以存储 232 -1 键值对（40多亿）。 HMSET runoob field1 &quot;Hello&quot; field2 &quot;World&quot; HGET runoob field1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Map集合，key-map! 时候这个值是一个map集合！ 本质和String类型没有太大区别，还是一个简单的key-vlaue！set myhash field kuangshen5) &quot;d&quot;##########################################################################127.0.0.1:6379&gt; hset myhash field1 kuangshen # set一个具体 key-vlaue(integer) 1127.0.0.1:6379&gt; hget myhash field1 # 获取一个字段值&quot;kuangshen&quot;127.0.0.1:6379&gt; hmset myhash field1 hello field2 world # set多个 key-vlaueOK127.0.0.1:6379&gt; hmget myhash field1 field2 # 获取多个字段值1) &quot;hello&quot;2) &quot;world&quot;127.0.0.1:6379&gt; hgetall myhash # 获取全部的数据，1) &quot;field1&quot;2) &quot;hello&quot;3) &quot;field2&quot;4) &quot;world&quot;127.0.0.1:6379&gt; hdel myhash field1 # 删除hash指定key字段！对应的value值也就消失了！(integer) 1127.0.0.1:6379&gt; hgetall myhash1) &quot;field2&quot;2) &quot;world&quot;##########################################################################hlen127.0.0.1:6379&gt; hmset myhash field1 hello field2 worldOK127.0.0.1:6379&gt; HGETALL myhash1) &quot;field2&quot;2) &quot;world&quot;3) &quot;field1&quot;4) &quot;hello&quot;127.0.0.1:6379&gt; hlen myhash # 获取hash表的字段数量！(integer) 2##########################################################################127.0.0.1:6379&gt; HEXISTS myhash field1 # 判断hash中指定字段是否存在！(integer) 1127.0.0.1:6379&gt; HEXISTS myhash field3(integer) 0########################################################################### 只获得所有field# 只获得所有value127.0.0.1:6379&gt; hkeys myhash # 只获得所有field1) &quot;field2&quot;2) &quot;field1&quot;hash变更的数据 user name age,尤其是是用户信息之类的，经常变动的信息！ hash 更适合于对象的存储，String更加适合字符串存储！ List（列表） Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。 lpush runoob redis lpush runoob mongodb lrange runoob 0 10 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180基本的数据类型，列表127.0.0.1:6379&gt; msetnx k1 v1 k4 v4 # msetnx 是一个原子性的操作，要么一起成功，要么一起失败！(integer) 0127.0.0.1:6379&gt; get k4(nil)# 对象set user:1 {name:zhangsan,age:3} # 设置一个user:1 对象 值为 json字符来保存一个对象！# 这里的key是一个巧妙的设计： user:{id}:{filed} , 如此设计在Redis中是完全OK了！127.0.0.1:6379&gt; mset user:1:name zhangsan user:1:age 2OK127.0.0.1:6379&gt; mget user:1:name user:1:age1) &quot;zhangsan&quot;2) &quot;2&quot;##########################################################################getset # 先get然后在set127.0.0.1:6379&gt; getset db redis # 如果不存在值，则返回 nil(nil)127.0.0.1:6379&gt; get db&quot;redis127.0.0.1:6379&gt; getset db mongodb # 如果存在值，获取原来的值，并设置新的值&quot;redis&quot;127.0.0.1:6379&gt; get db&quot;mongodb&quot;在redis里面，我们可以把list玩成 ，栈、队列、阻塞队列！所有的list命令都是用l开头的，Redis不区分大小命令##########################################################################127.0.0.1:6379&gt; LPUSH list one # 将一个值或者多个值，插入到列表头部 （左）(integer) 1127.0.0.1:6379&gt; LPUSH list two(integer) 2127.0.0.1:6379&gt; LPUSH list three(integer) 3127.0.0.1:6379&gt; LRANGE list 0 -1 # 获取list中值！1) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;127.0.0.1:6379&gt; LRANGE list 0 1 # 通过区间获取具体的值！1) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; Rpush list righr # 将一个值或者多个值，插入到列表位部 （右）(integer) 4127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;4) &quot;righr&quot;##########################################################################LPOPRPOP127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;4) &quot;righr&quot;127.0.0.1:6379&gt; Lpop list # 移除list的第一个元素&quot;three&quot;127.0.0.1:6379&gt; Rpop list # 移除list的最后一个元素&quot;righr&quot;127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;2) &quot;one&quot;##########################################################################Lindex127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;2) &quot;one&quot;127.0.0.1:6379&gt; lindex list 1 # 通过下标获得 list 中的某一个值！&quot;one&quot;127.0.0.1:6379&gt; lindex list 0&quot;two&quot;##########################################################################Llen127.0.0.1:6379&gt; Lpush list one(integer) 1127.0.0.1:6379&gt; Lpush list two(integer) 2127.0.0.1:6379&gt; Lpush list three(integer) 3127.0.0.1:6379&gt; Llen list # 返回列表的长度(integer) 3##########################################################################移除指定的值！取关 uidLrem127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;three&quot;3) &quot;two&quot;4) &quot;one&quot;127.0.0.1:6379&gt; lrem list 1 one # 移除list集合中指定个数的value，精确匹配(integer) 1127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;three&quot;3) &quot;two&quot;127.0.0.1:6379&gt; lrem list 1 three(integer) 1127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; Lpush list three(integer) 3127.0.0.1:6379&gt; lrem list 2 three(integer) 2127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;##########################################################################trim 修剪。； list 截断!127.0.0.1:6379&gt; keys *(empty list or set)127.0.0.1:6379&gt; Rpush mylist &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; Rpush mylist &quot;hello1&quot;(integer) 2127.0.0.1:6379&gt; Rpush mylist &quot;hello2&quot;(integer) 3127.0.0.1:6379&gt; Rpush mylist &quot;hello3&quot;(integer) 4127.0.0.1:6379&gt; ltrim mylist 1 2 # 通过下标截取指定的长度，这个list已经被改变了，截断了只剩下截取的元素！OK127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello1&quot;2) &quot;hello2&quot;##########################################################################rpoplpush # 移除列表的最后一个元素，将他移动到新的列表中！127.0.0.1:6379&gt; rpush mylist &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush mylist &quot;hello1&quot;(integer) 2127.0.0.1:6379&gt; rpush mylist &quot;hello2&quot;(integer) 3127.0.0.1:6379&gt; rpoplpush mylist myotherlist # 移除列表的最后一个元素，将他移动到新的列表中！&quot;hello2&quot;127.0.0.1:6379&gt; lrange mylist 0 -1 # 查看原来的列表1) &quot;hello&quot;2) &quot;hello1&quot;127.0.0.1:6379&gt; lrange myotherlist 0 -1 # 查看目标列表中，确实存在改值！1) &quot;hello2&quot;##########################################################################lset 将列表中指定下标的值替换为另外一个值，更新操作127.0.0.1:6379&gt; EXISTS list # 判断这个列表是否存在(integer) 0127.0.0.1:6379&gt; lset list 0 item # 如果不存在列表我们去更新就会报错(error) ERR no such key127.0.0.1:6379&gt; lpush list value1(integer) 1127.0.0.1:6379&gt; LRANGE list 0 01) &quot;value1&quot;127.0.0.1:6379&gt; lset list 0 item # 如果存在，更新当前下标的值OK127.0.0.1:6379&gt; LRANGE list 0 01) &quot;item&quot;127.0.0.1:6379&gt; lset list 1 other # 如果不存在，则会报错！(error) ERR index out of range##########################################################################linsert # 将某个具体的value插入到列把你中某个元素的前面或者后面！127.0.0.1:6379&gt; Rpush mylist &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; Rpush mylist &quot;world&quot;(integer) 2127.0.0.1:6379&gt; LINSERT mylist before &quot;world&quot; &quot;other&quot;(integer) 3127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello&quot;2) &quot;other&quot;3) &quot;world&quot;127.0.0.1:6379&gt; LINSERT mylist after world new(integer) 4127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello&quot;2) &quot;other&quot;3) &quot;world&quot;4) &quot;new&quot;小结他实际上是一个链表，before Node after ， left，right 都可以插入值如果key 不存在，创建新的链表如果key存在，新增内容 Set（集合） Redis 的 Set 是 string 类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 sadd 命令 添加一个 string 元素到 key 对应的 set 集合中，成功返回 1，如果元素已经在集合中返回 0。 sadd key member 集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。 sadd runoob redis smembers runoob 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101set中的值是不能重读的！##########################################################################127.0.0.1:6379&gt; sadd myset &quot;hello&quot; # set集合中添加匀速(integer) 1127.0.0.1:6379&gt; sadd myset &quot;kuangshen&quot;(integer) 1127.0.0.1:6379&gt; sadd myset &quot;lovekuangshen&quot;(integer) 1127.0.0.1:6379&gt; SMEMBERS myset # 查看指定set的所有值1) &quot;hello&quot;2) &quot;lovekuangshen&quot;3) &quot;kuangshen&quot;127.0.0.1:6379&gt; SISMEMBER myset hello # 判断某一个值是不是在set集合中！(integer) 1127.0.0.1:6379&gt; SISMEMBER myset world(integer) 0##########################################################################127.0.0.1:6379&gt; scard myset # 获取set集合中的内容元素个数！(integer) 4##########################################################################rem127.0.0.1:6379&gt; srem myset hello # 移除set集合中的指定元素(integer) 1127.0.0.1:6379&gt; scard myset(integer) 3127.0.0.1:6379&gt; SMEMBERS myset1) &quot;lovekuangshen2&quot;2) &quot;lovekuangshen&quot;3) &quot;kuangshen&quot;##########################################################################set 无序不重复集合。抽随机！127.0.0.1:6379&gt; SMEMBERS myset1) &quot;lovekuangshen2&quot;2) &quot;lovekuangshen&quot;3) &quot;kuangshen&quot;127.0.0.1:6379&gt; SRANDMEMBER myset # 随机抽选出一个元素&quot;kuangshen&quot;127.0.0.1:6379&gt; SRANDMEMBER myset&quot;kuangshen&quot;127.0.0.1:6379&gt; SRANDMEMBER myset&quot;kuangshen&quot;127.0.0.1:6379&gt; SRANDMEMBER myset&quot;kuangshen&quot;127.0.0.1:6379&gt; SRANDMEMBER myset 2 # 随机抽选出指定个数的元素1) &quot;lovekuangshen&quot;2) &quot;lovekuangshen2&quot;127.0.0.1:6379&gt; SRANDMEMBER myset 21) &quot;lovekuangshen&quot;2) &quot;lovekuangshen2&quot;127.0.0.1:6379&gt; SRANDMEMBER myset # 随机抽选出一个元素&quot;lovekuangshen2&quot;##########################################################################删除定的key，随机删除key！127.0.0.1:6379&gt; SMEMBERS myset1) &quot;lovekuangshen2&quot;2) &quot;lovekuangshen&quot;3) &quot;kuangshen&quot;127.0.0.1:6379&gt; spop myset # 随机删除一些set集合中的元素！&quot;lovekuangshen2&quot;127.0.0.1:6379&gt; spop myset&quot;lovekuangshen&quot;127.0.0.1:6379&gt; SMEMBERS myset1) &quot;kuangshen&quot;##########################################################################将一个指定的值，移动到另外一个set集合！127.0.0.1:6379&gt; sadd myset &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; sadd myset &quot;world&quot;(integer) 1127.0.0.1:6379&gt; sadd myset &quot;kuangshen&quot;(integer) 1127.0.0.1:6379&gt; sadd myset2 &quot;set2&quot;(integer) 1127.0.0.1:6379&gt; smove myset myset2 &quot;kuangshen&quot; # 将一个指定的值，移动到另外一个set集合！(integer) 1127.0.0.1:6379&gt; SMEMBERS myset1) &quot;world&quot;2) &quot;hello&quot;127.0.0.1:6379&gt; SMEMBERS myset21) &quot;kuangshen&quot;2) &quot;set2&quot;##########################################################################微博，B站，共同关注！(并集)数字集合类：- 差集 SDIFF- 交集- 并集127.0.0.1:6379&gt; SDIFF key1 key2 # 差集1) &quot;b&quot;2) &quot;a&quot;127.0.0.1:6379&gt; SINTER key1 key2 # 交集 共同好友就可以这样实现1) &quot;c&quot;127.0.0.1:6379&gt; SUNION key1 key2 # 并集1) &quot;b&quot;2) &quot;c&quot;3) &quot;e&quot;4) &quot;a&quot;微博，A用户将所有关注的人放在一个set集合中！将它的粉丝也放在一个集合中！共同关注，共同爱好，二度好友，推荐好友！（六度分割理论） ZSet(有序集合) Redis zset (sorted set：有序集合)和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 zadd 命令 添加元素到集合，元素在集合中存在则更新对应score zadd key score member zadd runoob 0 redis ZRANGEBYSCORE runoob 0 1000 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879在set的基础上，增加了一个值，set k1 v1 zset k1 score1 v1127.0.0.1:6379&gt; hvals myhash # 只获得所有value1) &quot;world&quot;2) &quot;hello&quot;##########################################################################incr decr127.0.0.1:6379&gt; hset myhash field3 5 #指定增量！(integer) 1127.0.0.1:6379&gt; HINCRBY myhash field3 1(integer) 6127.0.0.1:6379&gt; HINCRBY myhash field3 -1(integer) 5127.0.0.1:6379&gt; hsetnx myhash field4 hello # 如果不存在则可以设置(integer) 1127.0.0.1:6379&gt; hsetnx myhash field4 world # 如果存在则不能设置(integer) 0127.0.0.1:6379&gt; zadd myset 1 one # 添加一个值(integer) 1127.0.0.1:6379&gt; zadd myset 2 two 3 three # 添加多个值(integer) 2127.0.0.1:6379&gt; ZRANGE myset 0 -11) &quot;one&quot;2) &quot;two&quot;3) &quot;three&quot;##########################################################################排序如何实现127.0.0.1:6379&gt; zadd salary 2500 xiaohong # 添加三个用户(integer) 1127.0.0.1:6379&gt; zadd salary 5000 zhangsan(integer) 1127.0.0.1:6379&gt; zadd salary 500 kaungshen(integer) 1# ZRANGEBYSCORE key min max127.0.0.1:6379&gt; ZRANGEBYSCORE salary -inf +inf # 显示全部的用户 从小到大！1) &quot;kaungshen&quot;2) &quot;xiaohong&quot;3) &quot;zhangsan&quot;127.0.0.1:6379&gt; ZREVRANGE salary 0 -1 # 从大到进行排序！1) &quot;zhangsan&quot;2) &quot;kaungshen&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE salary -inf +inf withscores # 显示全部的用户并且附带成绩1) &quot;kaungshen&quot;2) &quot;500&quot;3) &quot;xiaohong&quot;4) &quot;2500&quot;5) &quot;zhangsan&quot;6) &quot;5000&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE salary -inf 2500 withscores # 显示工资小于2500员工的升序排序！1) &quot;kaungshen&quot;2) &quot;500&quot;3) &quot;xiaohong&quot;4) &quot;2500&quot;########################################################################### 移除rem中的元素127.0.0.1:6379&gt; zrange salary 0 -11) &quot;kaungshen&quot;2) &quot;xiaohong&quot;3) &quot;zhangsan&quot;127.0.0.1:6379&gt; zrem salary xiaohong # 移除有序集合中的指定元素(integer) 1127.0.0.1:6379&gt; zrange salary 0 -11) &quot;kaungshen&quot;2) &quot;zhangsan&quot;127.0.0.1:6379&gt; zcard salary # 获取有序集合中的个数(integer) 2##########################################################################127.0.0.1:6379&gt; zadd myset 1 hello(integer) 1127.0.0.1:6379&gt; zadd myset 2 world 3 kuangshen(integer) 2127.0.0.1:6379&gt; zcount myset 1 3 # 获取指定区间的成员数量！(integer) 3127.0.0.1:6379&gt; zcount myset 1 2(integer) 2案例思路：set 排序 存储班级成绩表，工资表排序！普通消息，1， 重要消息 2，带权重进行判断！排行榜应用实现，取Top N 测试！ Geospatial 地理位置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119朋友的定位，附近的人，打车距离计算？Redis 的 Geo 在Redis3.2 版本就推出了！ 这个功能可以推算地理位置的信息，两地之间的距离，方圆几里的人！可以查询一些测试数据：http://www.jsons.cn/lngcodeinfo/0706D99C19A781A3/只有 六个命令：4) &quot;2500&quot;5) &quot;zhangsan&quot;6) &quot;5000&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE salary -inf 2500 withscores # 显示工资小于2500员工的升序排序！1) &quot;kaungshen&quot;2) &quot;500&quot;3) &quot;xiaohong&quot;4) &quot;2500&quot;########################################################################### 移除rem中的元素127.0.0.1:6379&gt; zrange salary 0 -11) &quot;kaungshen&quot;2) &quot;xiaohong&quot;3) &quot;zhangsan&quot;127.0.0.1:6379&gt; zrem salary xiaohong # 移除有序集合中的指定元素(integer) 1127.0.0.1:6379&gt; zrange salary 0 -11) &quot;kaungshen&quot;2) &quot;zhangsan&quot;127.0.0.1:6379&gt; zcard salary # 获取有序集合中的个数(integer) 2##########################################################################127.0.0.1:6379&gt; zadd myset 1 hello(integer) 1127.0.0.1:6379&gt; zadd myset 2 world 3 kuangshen(integer) 2127.0.0.1:6379&gt; zcount myset 1 3 # 获取指定区间的成员数量！(integer) 3127.0.0.1:6379&gt; zcount myset 1 2(integer) 2官方文档：https://www.redis.net.cn/order/3685.htmlgetaddgetpos获得当前定位：一定是一个坐标值！GEODIST# getadd 添加地理位置# 规则：两级无法直接添加，我们一般会下载城市数据，直接通过java程序一次性导入！# 有效的经度从-180度到180度。# 有效的纬度从-85.05112878度到85.05112878度。# 当坐标位置超出上述指定范围时，该命令将会返回一个错误。# 127.0.0.1:6379&gt; geoadd china:city 39.90 116.40 beijin(error) ERR invalid longitude,latitude pair 39.900000,116.400000# 参数 key 值（）127.0.0.1:6379&gt; geoadd china:city 116.40 39.90 beijing(integer) 1127.0.0.1:6379&gt; geoadd china:city 121.47 31.23 shanghai(integer) 1127.0.0.1:6379&gt; geoadd china:city 106.50 29.53 chongqi 114.05 22.52 shengzhen(integer) 2127.0.0.1:6379&gt; geoadd china:city 120.16 30.24 hangzhou 108.96 34.26 xian(integer) 2127.0.0.1:6379&gt; GEOPOS china:city beijing # 获取指定的城市的经度和纬度！1) 1) &quot;116.39999896287918091&quot;2) &quot;39.90000009167092543&quot;127.0.0.1:6379&gt; GEOPOS china:city beijing chongqi1) 1) &quot;116.39999896287918091&quot;2) &quot;39.90000009167092543&quot;2) 1) &quot;106.49999767541885376&quot;2) &quot;29.52999957900659211&quot;两人之间的距离！单位：m 表示单位为米。km 表示单位为千米。mi 表示单位为英里。ft 表示单位为英尺。georadius 以给定的经纬度为中心， 找出某一半径内的元素我附近的人？ （获得所有附近的人的地址，定位！）通过半径来查询！获得指定数量的人，200所有数据应该都录入：china:city ，才会让结果更加请求！127.0.0.1:6379&gt; GEODIST china:city beijing shanghai km # 查看上海到北京的直线距离&quot;1067.3788&quot;127.0.0.1:6379&gt; GEODIST china:city beijing chongqi km # 查看重庆到北京的直线距离&quot;1464.0708&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 1000 km # 以110，30 这个经纬度为中心，寻找方圆1000km内的城市1) &quot;chongqi&quot;2) &quot;xian&quot;3) &quot;shengzhen&quot;4) &quot;hangzhou&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km1) &quot;chongqi&quot;2) &quot;xian&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withdist # 显示到中间距离的位置1) 1) &quot;chongqi&quot;2) &quot;341.9374&quot;2) 1) &quot;xian&quot;2) &quot;483.8340&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withcoord # 显示他人的定位信息1) 1) &quot;chongqi&quot;2) 1) &quot;106.49999767541885376&quot;2) &quot;29.52999957900659211&quot;2) 1) &quot;xian&quot;2) 1) &quot;108.96000176668167114&quot;2) &quot;34.25999964418929977&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withdist withcoord count 1 #筛选出指定的结果！1) 1) &quot;chongqi&quot;2) &quot;341.9374&quot;3) 1) &quot;106.49999767541885376&quot;2) &quot;29.52999957900659211&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withdist withcoord count 21) 1) &quot;chongqi&quot;2) &quot;341.9374&quot;3) 1) &quot;106.49999767541885376&quot;2) &quot;29.52999957900659211&quot;2) 1) &quot;xian&quot;2) &quot;483.8340&quot;3) 1) &quot;108.96000176668167114&quot;2) &quot;34.25999964418929977&quot;GEORADIUSBYMEMBERGEOHASH 命令 - 返回一个或多个位置元素的 Geohash 表示该命令将返回11个字符的Geohash字符串!GEO 底层的实现原理其实就是 Zset！我们可以使用Zset命令来操作geo！ Hyperloglog 什么是基数？ A B 基数（不重复的元素） = 5，可以接受误差！ 简介 Redis 2.8.9 版本就更新了 Hyperloglog 数据结构！ Redis Hyperloglog 基数统计的算法！ 优点：占用的内存是固定，2^64 不同的元素的技术，只需要废 12KB内存！如果要从内存角度来比较的 话 Hyperloglog 首选！ 网页的 UV （一个人访问一个网站多次，但是还是算作一个人！） 传统的方式， set 保存用户的id，然后就可以统计 set 中的元素数量作为标准判断 ! 这个方式如果保存大量的用户id，就会比较麻烦！我们的目的是为了计数，而不是保存用户id； 0.81% 错误率！ 统计UV任务，可以忽略不计的！ 测试使用 1234567891011121314127.0.0.1:6379&gt; PFadd mykey a b c d e f g h i j # 创建第一组元素 mykey(integer) 1127.0.0.1:6379&gt; PFCOUNT mykey # 统计 mykey 元素的基数数量(integer) 10127.0.0.1:6379&gt; PFadd mykey2 i j z x c v b n m # 创建第二组元素 mykey2(integer) 1127.0.0.1:6379&gt; PFCOUNT mykey2(integer) 9127.0.0.1:6379&gt; PFMERGE mykey3 mykey mykey2 # 合并两组 mykey mykey2 =&gt; mykey3 并集OK127.0.0.1:6379&gt; PFCOUNT mykey3 # 看并集的数量！(integer) 15如果允许容错，那么一定可以使用 Hyperloglog ！如果不允许容错，就使用 set 或者自己的数据类型即可！ Bitmap 位存储 统计用户信息，活跃，不活跃！ 登录 、 未登录！ 打卡，365打卡！ 两个状态的，都可以使用 Bitmaps！ Bitmap 位图，数据结构！ 都是操作二进制位来进行记录，就只有0 和 1 两个状态！ 365 天 = 365 bit 1字节 = 8bit 46 个字节左右！ Redis 命令 Redis 命令 语法 Redis 客户端的基本语法为： $ redis-cli - 以下实例讲解了如何启动 redis 客户端： 启动 redis 服务器，打开终端并输入命令 redis-cli，该命令会连接本地的 redis 服务。 $ redis-cli redis 127.0.0.1:6379&gt; redis 127.0.0.1:6379&gt; PING PONG 在以上实例中我们连接到本地的 redis 服务并执行 PING 命令，该命令用于检测 redis 服务是否启动。 在远程服务上执行命令 $ redis-cli -h host -p port -a password Redis keys 命令大全 https://redis.io/commands Redis HyperLogLog Redis 在 2.8.9 版本添加了 HyperLogLog 结构。 Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 什么是基数? 比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。 PFADD runoobkey &quot;redis&quot; PFCOUNT runoobkey Redis 发布订阅 Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。 Redis 客户端可以订阅任意数量的频道。 订阅/发布消息图： 第一个：消息发送者， 第二个：频道 第三个：消息订阅者！ 下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的 关系： 当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户 端： 命令 这些命令被广泛用于构建即时通信应用，比如网络聊天室(chatroom)和实时广播、实时提醒等 123456789101112131415161718192021测试订阅端：127.0.0.1:6379&gt; SUBSCRIBE kuangshenshuo # 订阅一个频道 kuangshenshuoReading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;kuangshenshuo&quot;3) (integer) 1# 等待读取推送的信息1) &quot;message&quot; # 消息2) &quot;kuangshenshuo&quot; # 那个频道的消息3) &quot;hello,kuangshen&quot; # 消息的具体内容1) &quot;message&quot;2) &quot;kuangshenshuo&quot;3) &quot;hello,redis&quot;发送端：127.0.0.1:6379&gt; PUBLISH kuangshenshuo &quot;hello,kuangshen&quot; # 发布者发布消息到频道！(integer) 1127.0.0.1:6379&gt; PUBLISH kuangshenshuo &quot;hello,redis&quot; # 发布者发布消息到频道！(integer) 1127.0.0.1:6379&gt; 原理 Redis是使用C实现的，通过分析 Redis 源码里的 pubsub.c 文件，了解发布和订阅机制的底层实现，借此加深对 Redis 的理解。 Redis 通过 PUBLISH 、SUBSCRIBE 和 PSUBSCRIBE 等命令实现发布和订阅功能。 微信： 通过 SUBSCRIBE 命令订阅某频道后，redis-server 里维护了一个字典，字典的键就是一个个 频道！， 而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。SUBSCRIBE 命令的关键， 就是将客户端添加到给定 channel 的订阅链表中。 通过 PUBLISH 命令向订阅者发送消息，redis-server 会使用给定的频道作为键，在它所维护的 channel 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。Pub/Sub 从字面上理解就是发布（Publish）与订阅（Subscribe），在Redis中，你可以设定对某一个 key值进行消息发布及消息订阅，当一个key值上进行了消息发布后，所有订阅它的客户端都会收到相应 的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。 使用场景： 1、实时消息系统！ 2、事实聊天！（频道当做聊天室，将信息回显给所有人即可！） 3、订阅，关注系统都是可以的！ 稍微复杂的场景我们就会使用 消息中间件 MQ （） SUBSCRIBE runoobChat PUBLISH runoobChat &quot;Redis PUBLISH test&quot; 重新开启个 redis 客户端在同一个频道 runoobChat 发布两次消息，订阅者就能接收到消息。 Redis 事务(不回滚，批量执行作用) Redis 事务可以一次执行多个命令， 并且带有以下三个重要的保证： 批量操作在发送 EXEC 命令前被放入队列缓存。 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行,代码错误，所有命令都不会执行。 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。DISCARD放弃事物，所有不执行 一个事务从开始到执行会经历以下三个阶段： 开始事务。 命令入队。 执行事务。 MULTI 开始一个事务 将多个命令入队到事务中 SET book-name &quot;Mastering C++ in 21 days&quot; GET book-name SADD tag &quot;C++&quot; &quot;Programming&quot; &quot;Mastering Series&quot; SMEMBERS tag EXEC/DISCARD 单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。 事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。 悲观锁： 很悲观，认为什么时候都会出问题，无论做什么都会加锁！ 乐观锁： 很乐观，认为什么时候都不会出问题，所以不会上锁！ 更新数据的时候去判断一下，在此期间是否有人修改过这个数据， 获取version 更新的时候比较 version Redis测监视测试 正常执行成功！ 测试多线程修改值 , 使用watch 可以当做redis的乐观锁操作！ 123456789101112131415127.0.0.1:6379&gt; set money 100OK127.0.0.1:6379&gt; set out 0OK127.0.0.1:6379&gt; watch money # 监视 money 对象OK127.0.0.1:6379&gt; multi # 事务正常结束，数据期间没有发生变动，这个时候就正常执行成功！OK127.0.0.1:6379&gt; DECRBY money 20QUEUED127.0.0.1:6379&gt; INCRBY out 20QUEUED127.0.0.1:6379&gt; exec1) (integer) 802) (integer) 20 测试多线程修改值 , 使用watch 可以当做redis的乐观锁操作！ 1234567891011127.0.0.1:6379&gt; watch money # 监视 moneyOK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; DECRBY money 10QUEUED127.0.0.1:6379&gt; INCRBY out 10QUEUED127.0.0.1:6379&gt; exec # 执行之前，另外一个线程，修改了我们的值，这个时候，就会导致事务执行失败！(nil) Redis 脚本 Redis 脚本使用 Lua 解释器来执行脚本。 Redis 2.6 版本通过内嵌支持 Lua 环境。执行脚本的常用命令为 EVAL。 EVAL script numkeys key [key ...] arg [arg ...] EVAL &quot;return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}&quot; 2 key1 key2 first second Redis 连接 Redis 连接命令主要是用于连接 redis 服务。 客户端如何通过密码验证连接到 redis 服务，并检测服务是否在运行： AUTH &quot;password&quot; PING 1 AUTH password 验证密码是否正确 2 ECHO message 打印字符串 3 PING 查看服务是否运行 4 QUIT 关闭当前连接 5 SELECT index 切换到指定的数据库 Redis服务器 Redis服务器命令主要是用于管理redis服务 Redis GEO Redis GEO 主要用于存储地理位置信息，并对存储的信息进行操作，该功能在 Redis 3.2 版本新增。 Redis GEO 操作方法有： geoadd：添加地理位置的坐标。 geopos：获取地理位置的坐标。 geodist：计算两个位置之间的距离。 georadius：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。 georadiusbymember：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。 geohash：返回一个或多个位置对象的 geohash 值。 geoadd geoadd 用于存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。 geoadd 语法格式如下： GEOADD key longitude latitude member [longitude latitude member ...] - GEOADD Sicily 13.361389 38.115556 &quot;Palermo&quot; 15.087269 37.502669 &quot;Catania&quot; - GEODIST Sicily Palermo Catania - geodist 用于返回两个给定位置之间的距离。 geodist 语法格式如下： GEODIST key member1 member2 [m|km|ft|mi] member1 member2 为两个地理位置。 最后一个距离单位参数说明： m ：米，默认单位。 km ：千米。 mi ：英里。 ft ：英尺。 - GEORADIUS Sicily 15 37 100 km - georadius 以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。 georadiusbymember 和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 georadiusbymember 的中心点是由给定的位置元素决定的， 而不是使用经度和纬度来决定中心点。 georadius 与 georadiusbymember 语法格式如下： GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key] GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key] 参数说明： m ：米，默认单位。 km ：千米。 mi ：英里。 ft ：英尺。 WITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。 WITHCOORD: 将位置元素的经度和维度也一并返回。 WITHHASH: 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。 COUNT 限定返回的记录数。 ASC: 查找结果根据距离从近到远排序。 DESC: 查找结果根据从远到近排序。 - GEOPOS Sicily Palermo Catania NonExisting - geopos 用于从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。 geopos 语法格式如下： GEOPOS key member [member ...] - GEOHASH Sicily Palermo Catania - geohash Redis GEO 使用 geohash 来保存地理位置的坐标。 geohash 用于获取一个或多个位置元素的 geohash 值。 geohash 语法格式如下： GEOHASH key member [member ...] Redis Stream Redis Stream 是 Redis 5.0 版本新增加的数据结构。 Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pub/sub) 来实现消息队列的功能，但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。 简单来说发布订阅 (pub/sub) 可以分发消息，但无法记录历史消息。 而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。 Redis Stream 的结构如下所示，它有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容： - 子主题 1 - 每个 Stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用 xadd 指令追加消息时自动创建。 上图解析： Consumer Group ：消费组，使用 XGROUP CREATE 命令创建，一个消费组有多个消费者(Consumer)。 last_delivered_id ：游标，每个消费组会有个游标 last_delivered_id，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动。 pending_ids ：消费者(Consumer)的状态变量，作用是维护消费者的未确认的 id。 pending_ids 记录了当前已经被客户端读取的消息，但是还没有 ack (Acknowledge character：确认字符）。 - 消息队列相关命令： XADD - 添加消息到末尾 XTRIM - 对流进行修剪，限制长度 XDEL - 删除消息 XLEN - 获取流包含的元素数量，即消息长度 XRANGE - 获取消息列表，会自动过滤已经删除的消息 XREVRANGE - 反向获取消息列表，ID 从大到小 XREAD - 以阻塞或非阻塞方式获取消息列表 消费者组相关命令： XGROUP CREATE - 创建消费者组 XREADGROUP GROUP - 读取消费者组中的消息 XACK - 将消息标记为&quot;已处理&quot; XGROUP SETID - 为消费者组设置新的最后递送消息ID XGROUP DELCONSUMER - 删除消费者 XGROUP DESTROY - 删除消费者组 XPENDING - 显示待处理消息的相关信息 XCLAIM - 转移消息的归属权 XINFO - 查看流和消费者组的相关信息； XINFO GROUPS - 打印消费者组的信息； XINFO STREAM - 打印流信息 XADD 使用 XADD 向队列添加消息，如果指定的队列不存在，则创建一个队列，XADD 语法格式： XADD key ID field value [field value ...] key ：队列名称，如果不存在就创建 ID ：消息 id，我们使用 * 表示由 redis 生成，可以自定义，但是要自己保证递增性。 field value ： 记录。 - XADD mystream * name Sara surname OConnor - XADD mystream * field1 value1 field2 value2 field3 value3 - XLEN mystream - XRANGE mystream - + XTRIM 使用 XTRIM 对流进行修剪，限制长度， 语法格式： XTRIM key MAXLEN [~] count key ：队列名称 MAXLEN ：长度 count ：数量 - XADD mystream * field1 A field2 B field3 C field4 D - XTRIM mystream MAXLEN 2 - XRANGE mystream - + XDEL 使用 XDEL 删除消息，语法格式： XDEL key ID [ID ...] key：队列名称 ID ：消息 ID 使用 XDEL 删除消息，语法格式： XLEN 使用 XLEN 获取流包含的元素数量，即消息长度，语法格式： XLEN key key：队列名称 - XADD mystream * item 1 - XLEN mystream XRANGE 使用 XRANGE 获取消息列表，会自动过滤已经删除的消息 ，语法格式： XRANGE key start end [COUNT count] key ：队列名 start ：开始值， - 表示最小值 end ：结束值， + 表示最大值 count ：数量 - XADD writers * name Ngozi surname Adichie - XLEN writers - XRANGE writers - + COUNT 2 XREVRANGE 使用 XREVRANGE 获取消息列表，会自动过滤已经删除的消息 ，语法格式： XREVRANGE key end start [COUNT count] key ：队列名 end ：结束值， + 表示最大值 start ：开始值， - 表示最小值 count ：数量 - XADD writers * name Virginia surname Woolf - XLEN writers - XREVRANGE writers + - COUNT 1 XREAD 使用 XREAD 以阻塞或非阻塞方式获取消息列表 ，语法格式： XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] id [id ...] count ：数量 milliseconds ：可选，阻塞毫秒数，没有设置就是非阻塞模式 key ：队列名 id ：消息 ID - # 从 Stream 头部读取两条消息 XREAD COUNT 2 STREAMS mystream writers 0-0 0-0 XGROUP CREATE 使用 XGROUP CREATE 创建消费者组，语法格式： XGROUP [CREATE key groupname id-or-$] [SETID key groupname id-or-$] [DESTROY key groupname] [DELCONSUMER key groupname consumername] key ：队列名称，如果不存在就创建 groupname ：组名。 $ ： 表示从尾部开始消费，只接受新消息，当前 Stream 消息会全部忽略。 从头开始消费: XGROUP CREATE mystream consumer-group-name 0-0 从尾部开始消费: XGROUP CREATE mystream consumer-group-name $ XREADGROUP GROUP 使用 XREADGROUP GROUP 读取消费组中的消息，语法格式： XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] ID [ID ...] group ：消费组名 consumer ：消费者名。 count ： 读取数量。 milliseconds ： 阻塞毫秒数。 key ： 队列名。 ID ： 消息 ID。 XREADGROUP GROUP consumer-group-name consumer-name COUNT 1 STREAMS mystream &gt; Redis 高级教程 Redis主从复制 概念 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点 (master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。 Master以写为主，Slave 以读为主。 默认情况下，每台Redis服务器都是主节点； 且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 主从复制的作用主要包括： 1、数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 2、故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务 的冗余。 3、负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 （即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写 少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 4、高可用（集群）基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复 制是Redis高可用的基础。 一般来说，要将Redis运用于工程项目中，只使用一台Redis是万万不能的（宕机），原因如下： 1、从结构上，单个Redis服务器会发生单点故障，并且一台服务器需要处理所有的请求负载，压力较 大； 2、从容量上，单个Redis服务器内存容量有限，就算一台Redis服务器内存容量为256G，也不能将所有 内存用作Redis存储内存，一般来说，单台Redis最大使用内存不应该超过20G。 电商网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是&quot;多读少写&quot;。 对于这种场景，我们可以使如下这种架构： 主从复制，读写分离！ 80% 的情况下都是在进行读操作！减缓服务器的压力！架构中经常使用！ 一主 二从！ 只要在公司中，主从复制就是必须要使用的，因为在真实的项目中不可能单机使用Redis！ 环境配置 只配置从库，不用配置主库！ 123456789101112127.0.0.1:6379&gt; info replication # 查看当前库的信息# Replicationrole:master # 角色 masterconnected_slaves:0 # 没有从机master_replid:b63c90e6c501143759cb0e7f450bd1eb0c70882amaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 复制3个配置文件，然后修改对应的信息 1、端口 2、pid 名字 3、log文件名字 4、dump.rdb 名字 修改完毕之后，启动我们的3个redis服务器，可以通过进程信息查看！ 一主二从 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152默认情况下，每台Redis服务器都是主节点； 我们一般情况下只用配置从机就好了！认老大！ 一主 （79）二从（80，81）127.0.0.1:6379&gt; info replication # 查看当前库的信息# Replicationrole:master # 角色 masterconnected_slaves:0 # 没有从机master_replid:b63c90e6c501143759cb0e7f450bd1eb0c70882amaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0127.0.0.1:6380&gt; SLAVEOF 127.0.0.1 6379 # SLAVEOF host 6379 找谁当自己的老大！OK127.0.0.1:6380&gt; info replication# Replicationrole:slave # 当前角色是从机master_host:127.0.0.1 # 可以的看到主机的信息master_port:6379master_link_status:upmaster_last_io_seconds_ago:3master_sync_in_progress:0slave_repl_offset:14slave_priority:100slave_read_only:1connected_slaves:0master_replid:a81be8dd257636b2d3e7a9f595e69d73ff03774emaster_replid2:0000000000000000000000000000000000000000master_repl_offset:14second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:14# 在主机中查看！127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1 # 多了从机的配置slave0:ip=127.0.0.1,port=6380,state=online,offset=42,lag=1 # 多了从机的配置master_replid:a81be8dd257636b2d3e7a9f595e69d73ff03774emaster_replid2:0000000000000000000000000000000000000000master_repl_offset:42second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:42如果两个都配置完了，就是有两个从机的真实的从主配置应该在配置文件中配置，这样的话是永久的，我们这里使用的是命令，暂时的！ 细节 主机可以写，从机不能写只能读！主机中的所有信息和数据，都会自动被从机保存！ 测试：主机断开连接，从机依旧连接到主机的，但是没有写操作，这个时候，主机如果回来了，从机依 旧可以直接获取到主机写的信息！ 如果是使用命令行，来配置的主从，这个时候如果重启了，就会变回主机！只要变为从机，立马就会从 主机中获取值！ 复制原理 Slave 启动成功连接到 master 后会发送一个sync同步命令 Master 接到命令，启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行 完毕之后，master将传送整个数据文件到slave，并完成一次完全同步。 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：Master 继续将新的所有收集到的修改命令依次传给slave，完成同步 但是只要是重新连接master，一次完全同步（全量复制）将被自动执行！ 我们的数据一定可以在从机中 看到！ 层层链路 上一个M链接下一个 S！这时候也可以完成我们的主从复制！如果没有老大了，这个时候能不能选择一个老大出来呢？ 手动！谋朝篡位 如果主机断开了连接，我们可以使用 SLAVEOF no one 让自己变成主机！其他的节点就可以手动连 接到最新的这个主节点（手动）！如果这个时候老大修复了，那就重新连接！ 哨兵模式 概述 （自动选举老大的模式） 主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工 干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑 哨兵模式。Redis从2.8开始正式提供了Sentinel（哨兵） 架构来解决这个问题。 谋朝篡位的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。 哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独 立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。 这里的哨兵有两个作用 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服 务器，修改配置文件，让它们切换主机。 然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。 各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认 为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一 定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover[故障转移]操作。 切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为 客观下线。 测试 我们目前的状态是 一主二从！ 1、配置哨兵配置文件 sentinel.conf 12# sentinel monitor 被监控的名称 host port 1sentinel monitor myredis 127.0.0.1 6379 1 后面的这个数字1，代表主机挂了，slave投票看让谁接替成为主机，票数最多的，就会成为主机！ 2、启动哨兵！ 123456789101112131415161718192021222324252627282930313233[root@kuangshen bin]# redis-sentinel kconfig/sentinel.conf26607:X 31 Mar 2020 21:13:10.027 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo26607:X 31 Mar 2020 21:13:10.027 # Redis version=5.0.8, bits=64,commit=00000000, modified=0, pid=26607, just started26607:X 31 Mar 2020 21:13:10.027 # Configuration loaded_.__.-``__ ''-.__.-`` `. `_. ''-._ Redis 5.0.8 (00000000/0) 64 bit.-`` .-```. ```\\/ _.,_ ''-._( ' , .-` | `, ) Running in sentinel mode|`-._`-...-` __...-.``-._|'` _.-'| Port: 26379| `-._ `._ / _.-' | PID: 26607`-._ `-._ `-./ _.-' _.-'|`-._`-._ `-.__.-' _.-'_.-'|| `-._`-._ _.-'_.-' | http://redis.io`-._ `-._`-.__.-'_.-' _.-'|`-._`-._ `-.__.-' _.-'_.-'|| `-._`-._ _.-'_.-' |`-._ `-._`-.__.-'_.-' _.-'`-._ `-.__.-' _.-'`-._ _.-'`-.__.-'26607:X 31 Mar 2020 21:13:10.029 # WARNING: The TCP backlog setting of 511cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower valueof 128.26607:X 31 Mar 2020 21:13:10.031 # Sentinel ID is4c780da7e22d2aebe3bc20c333746f202ce7299626607:X 31 Mar 2020 21:13:10.031 # +monitor master myredis 127.0.0.1 6379 quorum126607:X 31 Mar 2020 21:13:10.031 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @myredis 127.0.0.1 637926607:X 31 Mar 2020 21:13:10.033 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @myredis 127.0.0.1 6379 如果Master 节点断开了，这个时候就会从从机中随机选择一个服务器！ （这里面有一个投票算法！） 哨兵模式 优点： 1、哨兵集群，基于主从复制模式，所有的主从配置优点，它全有 2、 主从可以切换，故障可以转移，系统的可用性就会更好 3、哨兵模式就是主从模式的升级，手动到自动，更加健壮！ 缺点： 1、Redis 不好啊在线扩容的，集群容量一旦到达上限，在线扩容就十分麻烦！ 2、实现哨兵模式的配置其实是很麻烦的，里面有很多选择！ 哨兵模式的全部配置！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# Example sentinel.conf# 哨兵sentinel实例运行的端口 默认26379port 26379# 哨兵sentinel的工作目录dir /tmp# 哨兵sentinel监控的redis主节点的 ip port# master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符&quot;.-_&quot;组成。# quorum 配置多少个sentinel哨兵统一认为master主节点失联 那么这时客观上认为主节点失联了# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;sentinel monitor mymaster 127.0.0.1 6379 2# 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提供密码# 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster MySUPER--secret-0123passw0rd# 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;sentinel down-after-milliseconds mymaster 30000# 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行 同步，这个数字越小，完成failover所需的时间就越长，但是如果这个数字越大，就意味着越 多的slave因为replication而不可用。可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态。# sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;sentinel parallel-syncs mymaster 1# 故障转移的超时时间 failover-timeout 可以用在以下这些方面：#1. 同一个sentinel对同一个master两次failover之间的间隔时间。#2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。#3.当想要取消一个正在进行的failover所需要的时间。#4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了# 默认三分钟# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;sentinel failover-timeout mymaster 180000# SCRIPTS EXECUTION#配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。#对于脚本的运行结果有以下规则：#若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10#若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。#如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。#一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。#通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，一个是事件的类型，一个是事件的描述。如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。#通知脚本# shell编程# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;sentinel notification-script mymaster /var/redis/notify.sh# 客户端重新配置主节点参数脚本# 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。# 以下参数将会在调用脚本时传给脚本:# &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;# 目前&lt;state&gt;总是“failover”,# &lt;role&gt;是“leader”或者“observer”中的一个。# 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的# 这个脚本应该是通用的，能被多次调用，不是针对性的。# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;sentinel client-reconfig-script mymaster /var/redis/reconfig.sh # 一般都是由运维来配置！ Redis缓存穿透和雪崩 服务的高可用问题！ 在这里我们不会详细的区分析解决方案的底层！ Redis缓存的使用，极大的提升了应用程序的性能和效率，特别是数据查询方面。但同时，它也带来了一 些问题。其中，最要害的问题，就是数据的一致性问题，从严格意义上讲，这个问题无解。如果对数据 的一致性要求很高，那么就不能使用缓存。 另外的一些典型问题就是，缓存穿透、缓存雪崩和缓存击穿。目前，业界也都有比较流行的解决方案。 缓存穿透（查不到） 概念 缓存穿透的概念很简单，用户想要查询一个数据，发现redis内存数据库没有，也就是缓存没有命中，于 是向持久层数据库查询。发现也没有，于是本次查询失败。当用户很多的时候，缓存都没有命中（秒 杀！），于是都去请求了持久层数据库。这会给持久层数据库造成很大的压力，这时候就相当于出现了 缓存穿透。 解决方案 布隆过滤器 布隆过滤器是一种数据结构，对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则 丢弃，从而避免了对底层存储系统的查询压力； 缓存空对象 当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间，之后再访问这个数 据将会从缓存中获取，保护了后端数据源； 但是这种方法会存在两个问题： 1、如果空值能够被缓存起来，这就意味着缓存需要更多的空间存储更多的键，因为这当中可能会有很多 的空值的键； 2、即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于 需要保持一致性的业务会有影响。 缓存击穿（量太大，缓存过期！） 概述 这里需要注意和缓存击穿的区别，缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中 对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一 个屏障上凿开了一个洞。 当某个key在过期的瞬间，有大量的请求并发访问，这类数据一般是热点数据，由于缓存过期，会同时访 问数据库来查询最新数据，并且回写缓存，会导使数据库瞬间压力过大。 解决方案 设置热点数据永不过期 从缓存层面来看，没有设置过期时间，所以不会出现热点 key 过期后产生的问题。 加互斥锁 分布式锁：使用分布式锁，保证对于每个key同时只有一个线程去查询后端服务，其他线程没有获得分布 式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考 验很大。 缓存雪崩 概念 缓存雪崩，是指在某一个时间段，缓存集中过期失效。Redis 宕机！ 产生雪崩的原因之一，比如在写本文的时候，马上就要到双十二零点，很快就会迎来一波抢购，这波商 品时间比较集中的放入了缓存，假设缓存一个小时。那么到了凌晨一点钟的时候，这批商品的缓存就都 过期了。而对这批商品的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波 峰。于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。 其实集中过期，倒不是非常致命，比较致命的缓存雪崩，是缓存服务器某个节点宕机或断网。因为自然 形成的缓存雪崩，一定是在某个时间段集中创建缓存，这个时候，数据库也是可以顶住压力的。无非就 是对数据库产生周期性的压力而已。而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知 的，很有可能瞬间就把数据库压垮。 解决方案 redis高可用 这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续 工作，其实就是搭建的集群。（异地多活！） 限流降级（在SpringCloud讲解过！） 这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对 某个key只允许一个线程查询数据和写缓存，其他线程等待。 数据预热 数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数 据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让 缓存失效的时间点尽量均匀。 Redis持久化 面试和工作，持久化都是重点！ Redis 是内存数据库，如果不将内存中的数据库状态保存到磁盘，那么一旦服务器进程退出，服务器中 的数据库状态也会消失。所以 Redis 提供了持久化功能！ RDB （Redis DataBase） 什么是RDB 在主从复制中，rdb就是备用了！从机上面！ 在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。 Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程 都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的。 这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。我们默认的就是 RDB，一般情况下不需要修改这个配置！ 有时候在生产环境我们会将这个文件进行备份！ rdb保存的文件是dump.rdb 都是在我们的配置文件中快照中进行配置的！ 触发机制 1、save的规则满足的情况下，会自动触发rdb规则 2、执行 flushall 命令，也会触发我们的rdb规则！ 3、退出redis，也会产生 rdb 文件！ 备份就自动生成一个 dump.rdb 如何恢复rdb文件 1、只需要将rdb文件放在我们redis启动目录就可以，redis启动的时候会自动检查dump.rdb 恢复其中 的数据！ 2、查看需要存在的位置 几乎就他自己默认的配置就够用了，但是我们还是需要去学习！ 优点： 1、适合大规模的数据恢复！ 2、对数据的完整性要不高！ 缺点： 1、需要一定的时间间隔进程操作！如果redis意外宕机了，这个最后一次修改数据就没有的了！ 2、fork进程的时候，会占用一定的内容空间！！ AOF（Append Only File） 将我们的所有命令都记录下来，history，恢复的时候就把这个文件全部在执行一遍！ 是什么 127.0.0.1:6379&gt; config get dir 1) &quot;dir&quot; 2) &quot;/usr/local/bin&quot; # 如果在这个目录下存在 dump.rdb 文件，启动就会自动恢复其中的数据 以日志的形式来记录每个写操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件 但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件 的内容将写指令从前到后执行一次以完成数据的恢复工作 Aof保存的是 appendonly.aof 文件 默认是不开启的，我们需要手动进行配置！我们只需要将 appendonly 改为yes就开启了 aof！ 重启，redis 就可以生效了！ 如果这个 aof 文件有错位，这时候 redis 是启动不起来的吗，我们需要修复这个aof文件 redis 给我们提供了一个工具 redis-check-aof --fix aof 默认就是文件的无限追加，文件会越来越大！ 如果 aof 文件大于 64m，太大了！ fork一个新的进程来将我们的文件进行重写！ 优点和缺点！ 1234567appendonly no # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分所有的情况下，rdb完全够用！appendfilename &quot;appendonly.aof&quot; # 持久化的文件的名字# appendfsync always # 每次修改都会 sync。消耗性能appendfsync everysec # 每秒执行一次 sync，可能会丢失这1s的数据！# appendfsync no # 不执行 sync，这个时候操作系统自己同步数据，速度最快！# rewrite 重写， 优点： 1、每一次修改都同步，文件的完整会更加好！ 2、每秒同步一次，可能会丢失一秒的数据 3、从不同步，效率最高的！ 缺点： 1、相对于数据文件来说，aof远远大于 rdb，修复的速度也比 rdb慢！ 2、Aof 运行效率也要比 rdb 慢，所以我们redis默认的配置就是rdb持久化！ 扩展： 1、RDB 持久化方式能够在指定的时间间隔内对你的数据进行快照存储 2、AOF 持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始 的数据，AOF命令以Redis 协议追加保存每次写的操作到文件末尾，Redis还能对AOF文件进行后台重 写，使得AOF文件的体积不至于过大。 3、只做缓存，如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化 4、同时开启两种持久化方式 在这种情况下，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF 文件保存的数据集要比RDB文件保存的数据集要完整。 RDB 的数据不实时，同时使用两者时服务器重启也只会找AOF文件，那要不要只使用AOF呢？作者 建议不要，因为RDB更适合用于备份数据库（AOF在不断变化不好备份），快速重启，而且不会有 AOF可能潜在的Bug，留着作为一个万一的手段。 5、性能建议 因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够 了，只保留 save 900 1 这条规则。 如果Enable AOF ，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自 己的AOF文件就可以了，代价一是带来了持续的IO，二是AOF rewrite 的最后将 rewrite 过程中产 生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite 的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上，默认超过原大小100%大小重 写可以改到适当的数值。 如果不Enable AOF ，仅靠 Master-Slave Repllcation 实现高可用性也可以，能省掉一大笔IO，也 减少了rewrite时带来的系统波动。代价是如果Master/Slave 同时倒掉，会丢失十几分钟的数据， 启动脚本也要比较两个 Master/Slave 中的 RDB文件，载入较新的那个，微博就是这种架构。 命令 1234567891011121314151617181920测试订阅端：127.0.0.1:6379&gt; SUBSCRIBE kuangshenshuo # 订阅一个频道 kuangshenshuoReading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;kuangshenshuo&quot;3) (integer) 1# 等待读取推送的信息1) &quot;message&quot; # 消息2) &quot;kuangshenshuo&quot; # 那个频道的消息3) &quot;hello,kuangshen&quot; # 消息的具体内容1) &quot;message&quot;2) &quot;kuangshenshuo&quot;3) &quot;hello,redis&quot;发送端：127.0.0.1:6379&gt; PUBLISH kuangshenshuo &quot;hello,kuangshen&quot; # 发布者发布消息到频道！(integer) 1127.0.0.1:6379&gt; PUBLISH kuangshenshuo &quot;hello,redis&quot; # 发布者发布消息到频道！(integer) 1127.0.0.1:6379&gt; 原理 Redis是使用C实现的，通过分析 Redis 源码里的 pubsub.c 文件，了解发布和订阅机制的底层实现，借此加深对 Redis 的理解。 Redis 通过 PUBLISH 、SUBSCRIBE 和 PSUBSCRIBE 等命令实现发布和订阅功能。 微信： 通过 SUBSCRIBE 命令订阅某频道后，redis-server 里维护了一个字典，字典的键就是一个个 频道！， 而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。SUBSCRIBE 命令的关键， 就是将客户端添加到给定 channel 的订阅链表中。 Pub/Sub 从字面上理解就是发布（Publish）与订阅（Subscribe），在Redis中，你可以设定对某一个 key值进行消息发布及消息订阅，当一个key值上进行了消息发布后，所有订阅它的客户端都会收到相应 的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。 使用场景： 1、实时消息系统！ 2、事实聊天！（频道当做聊天室，将信息回显给所有人即可！） 3、订阅，关注系统都是可以的！ 稍微复杂的场景我们就会使用 消息中间件 MQ （） Redis 数据备份与恢复 SAVE 该命令将在 redis 安装目录中创建dump.rdb文件。 如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令 CONFIG GET dir 以上命令 CONFIG GET dir 输出的 redis 安装目录为 /usr/local/redis/bin。 Bgsave 创建 redis 备份文件也可以使用命令 BGSAVE，该命令在后台执行。 实例 127.0.0.1:6379&gt; BGSAVE Background saving started Redis 安全 通过 redis 的配置文件设置密码参数，这样客户端连接到 redis 服务就需要密码验证，这样可以让你的 redis 服务更安全。 查看是否设置了密码验证： CONFIG get requirepass默认情况下 requirepass 参数是空的，这就意味着你无需通过密码验证就可以连接到 redis 服务。 CONFIG set requirepass &quot;runoob&quot; AUTH &quot;runoob&quot; SET mykey &quot;Test value&quot; GET mykey Redis 性能测试 Redis 性能测试是通过同时执行多个命令实现的。 redis-benchmark [option] [option value] 注意：该命令是在 redis 的目录下执行的，而不是 redis 客户端的内部指令 以下实例同时执行 10000 个请求来检测性能： redis-benchmark -n 10000 -q - redis 性能测试工具可选参数如下所示： 序号 选项 描述 默认值 1 -h 指定服务器主机名 127.0.0.1 2 -p 指定服务器端口 6379 3 -s 指定服务器 socket 4 -c 指定并发连接数 50 5 -n 指定请求数 10000 6 -d 以字节的形式指定 SET/GET 值的数据大小 2 7 -k 1=keep alive 0=reconnect 1 8 -r SET/GET/INCR 使用随机 key, SADD 使用随机值 9 -P 通过管道传输 请求 1 10 -q 强制退出 redis。仅显示 query/sec 值 11 --csv 以 CSV 格式输出 12 -l 生成循环，永久执行测试 13 -t 仅运行以逗号分隔的测试命令列表。 14 -I Idle 模式。仅打开 N 个 idle 连接并等待。 - redis-benchmark -h 127.0.0.1 -p 6379 -t set,lpush -n 10000 -q Redis 客户端连接 Redis 通过监听一个 TCP 端口或者 Unix socket 的方式来接收来自客户端的连接，当一个连接建立后，Redis 内部会进行以下一些操作： 首先，客户端 socket 会被设置为非阻塞模式，因为 Redis 在网络事件处理上采用的是非阻塞多路复用模型。 然后为这个 socket 设置 TCP_NODELAY 属性，禁用 Nagle 算法 然后创建一个可读的文件事件用于监听这个客户端 socket 的数据发送 最大连接数 在 Redis2.4 中，最大连接数是被直接硬编码在代码里面的，而在2.6版本中这个值变成可配置的。 maxclients 的默认值是 10000，你也可以在 redis.conf 中对这个值进行修改。 config get maxclients - redis-server --maxclients 100000 - S.N. 命令 描述 1 CLIENT LIST 返回连接到 redis 服务的客户端列表 2 CLIENT SETNAME 设置当前连接的名称 3 CLIENT GETNAME 获取通过 CLIENT SETNAME 命令设置的服务名称 4 CLIENT PAUSE 挂起客户端连接，指定挂起的时间以毫秒计 5 CLIENT KILL 关闭客户端连接 Redis管道技术 Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。这意味着通常情况下一个请求会遵循以下步骤： 客户端向服务端发送一个查询请求，并监听套接字返回，通常以一对模式，等待服务端响应。 服务端处理命令，可以结果返回给客户端。 Redis管道技术可以在服务端未响应时，客户端可以继续向服务端发送请求，并最终一次性读取所有服务端的响应。 查看redis管道，只需要启动redis实例并输入以下命令： $（echo -en“ PING \\ r \\ n SET runoobkey redis \\ r \\ nGET runoobkey \\ r \\ nINCR访问者\\ r \\ nINCR访问者\\ r \\ nINCR访问者\\ r \\ n”；睡眠10）| 数控本地主机6379（echo - zh - cn “ PING \\ r \\ n SET redoobkey redis \\ r \\ nGET runoobkey \\ r \\ nINCR访问者\\ r \\ nINCR访问者\\ r \\ nINCR访问者\\ r \\ n” ；睡眠10 ）| 数控本地主机6379 - 以上实例中我们通过使用PING命令查看redis服务是否可用，之后我们设置了runoobkey的变量redis，然后我们获取runoobkey的值并使其访客自增3次。 在返回的结果中我们可以看到这些命令一次性向redis服务提交，并最终一次性读取所有服务端的响应 管道技术的优势 管道技术最显着的优势是提高了redis服务的性能。 Redis 分区 分区是分割数据到多个Redis实例的处理过程，因此每个实例只保存key的一个子集。 分区的优势 通过利用多台计算机内存的和值，允许我们构造更大的数据库。 通过多核和多台计算机，允许我们扩展计算能力；通过多台计算机和网络适配器，允许我们扩展网络带宽。 分区的不足 redis的一些特性在分区方面表现的不是很好： 涉及多个key的操作通常是不被支持的。举例来说，当两个set映射到不同的redis实例上时，你就不能对这两个set执行交集操作。 涉及多个key的redis事务不能使用。 当使用分区时，数据处理较为复杂，比如你需要处理多个rdb/aof文件，并且从多个实例和主机备份持久化文件。 增加或删除容量也比较复杂。redis集群大多数支持在运行时增加、删除节点的透明数据平衡的能力，但是类似于客户端分区、代理等其他系统则不支持这项特性。然而，一种叫做presharding的技术对此是有帮助的。 分区类型 Redis 有两种类型分区。 假设有4个Redis实例 R0，R1，R2，R3，和类似user:1，user:2这样的表示用户的多个key，对既定的key有多种不同方式来选择这个key存放在哪个实例中。也就是说，有不同的系统来映射某个key到某个Redis服务。 范围分区 最简单的分区方式是按范围分区，就是映射一定范围的对象到特定的Redis实例。 比如，ID从0到10000的用户会保存到实例R0，ID从10001到 20000的用户会保存到R1，以此类推。 这种方式是可行的，并且在实际中使用，不足就是要有一个区间范围到实例的映射表。这个表要被管理，同时还需要各 种对象的映射表，通常对Redis来说并非是好的方法。 哈希分区 另外一种分区方法是hash分区。这对任何key都适用，也无需是object_name:这种形式，像下面描述的一样简单： 用一个hash函数将key转换为一个数字，比如使用crc32 hash函数。对key foobar执行crc32(foobar)会输出类似93024922的整数。 对这个整数取模，将其转化为0-3之间的数字，就可以将这个整数映射到4个Redis实例中的一个了。93024922 % 4 = 2，就是说key foobar应该被存到R2实例中。注意：取模操作是取除的余数，通常在多种编程语言中用%操作符实现。 Java 使用 Redis jedis 安装 开始在 Java 中使用 Redis 前， 我们需要确保已经安装了 redis 服务及 Java redis 驱动，且你的机器上能正常使用 Java。 Java的安装配置可以参考我们的 Java 开发环境配置 接下来让我们安装 Java redis 驱动： 首先你需要下载驱动包 下载 jedis.jar，确保下载最新驱动包。 在你的 classpath 中包含该驱动包。 maven jedis 连接到 redis 服务 12345678910111213- import redis.clients.jedis.Jedis;public class RedisJava { public static void main(String[] args) { //连接本地的 Redis 服务 Jedis jedis = new Jedis(&quot;localhost&quot;); // 如果 Redis 服务设置来密码，需要下面这行，没有就不需要 // jedis.auth(&quot;123456&quot;); System.out.println(&quot;连接成功&quot;); //查看服务是否运行 System.out.println(&quot;服务正在运行: &quot;+jedis.ping()); }} Redis Java String(字符串) 实例 12345678910111213- import redis.clients.jedis.Jedis;public class RedisStringJava { public static void main(String[] args) { //连接本地的 Redis 服务 Jedis jedis = new Jedis(&quot;localhost&quot;); System.out.println(&quot;连接成功&quot;); //设置 redis 字符串数据 jedis.set(&quot;runoobkey&quot;, &quot;www.runoob.com&quot;); // 获取存储的数据并输出 System.out.println(&quot;redis 存储的字符串为: &quot;+ jedis.get(&quot;runoobkey&quot;)); }} Redis Java List(列表) 实例 12345678910111213141516171819- import java.util.List; import redis.clients.jedis.Jedis;public class RedisListJava { public static void main(String[] args) { //连接本地的 Redis 服务 Jedis jedis = new Jedis(&quot;localhost&quot;); System.out.println(&quot;连接成功&quot;); //存储数据到列表中 jedis.lpush(&quot;site-list&quot;, &quot;Runoob&quot;); jedis.lpush(&quot;site-list&quot;, &quot;Google&quot;); jedis.lpush(&quot;site-list&quot;, &quot;Taobao&quot;); // 获取存储的数据并输出 List&lt;String&gt; list = jedis.lrange(&quot;site-list&quot;, 0 ,2); for(int i=0; i&lt;list.size(); i++) { System.out.println(&quot;列表项为: &quot;+list.get(i)); } }} Redis Java Keys 实例 1234567891011121314151617 - import java.util.Iterator; import java.util.Set; import redis.clients.jedis.Jedis;public class RedisKeyJava { public static void main(String[] args) { //连接本地的 Redis 服务 Jedis jedis = new Jedis(&quot;localhost&quot;); System.out.println(&quot;连接成功&quot;); // 获取数据并输出 Set&lt;String&gt; keys = jedis.keys(&quot;*&quot;); Iterator&lt;String&gt; it=keys.iterator() ; while(it.hasNext()){ String key = it.next(); System.out.println(key); }}} Jedis事务 12345678910111213141516171819202122232425public static void main(String[] args) {Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);jedis.flushDB();JSONObject jsonObject = new JSONObject();jsonObject.put(&quot;hello&quot;,&quot;world&quot;);jsonObject.put(&quot;name&quot;,&quot;kuangshen&quot;);// 开启事务Transaction multi = jedis.multi();String result = jsonObject.toJSONString();// jedis.watch(result)try {multi.set(&quot;user1&quot;,result);multi.set(&quot;user2&quot;,result);int i = 1/0 ; // 代码抛出异常事务，执行失败！multi.exec(); // 执行事务！} catch (Exception e) {multi.discard(); // 放弃事务e.printStackTrace();} finally {System.out.println(jedis.get(&quot;user1&quot;));System.out.println(jedis.get(&quot;user2&quot;));jedis.close(); // 关闭连接}} SpringBoot整合Redis SpringBoot 操作数据：spring-data jpa jdbc mongodb redis！ SpringData 也是和 SpringBoot 齐名的项目！ 说明： 在 SpringBoot2.x 之后，原来使用的jedis 被替换为了 lettuce? jedis : 采用的直连，多个线程操作的话，是不安全的，如果想要避免不安全的，使用 jedis pool 连接池！ 更像 BIO 模式 lettuce : 采用netty，实例可以再多个线程中进行共享，不存在线程不安全的情况！可以减少线程数据了，更像 NIO 模式 源码分析： 12345678910111213141516171819202122@Bean@ConditionalOnMissingBean(name = &quot;redisTemplate&quot;) // 我们可以自己定义一个redisTemplate来替换这个默认的！public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactoryredisConnectionFactory)throws UnknownHostException {// 默认的 RedisTemplate 没有过多的设置，redis 对象都是需要序列化！// 两个泛型都是 Object, Object 的类型，我们后使用需要强制转换 &lt;String, Object&gt;RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();template.setConnectionFactory(redisConnectionFactory);return template;}@Bean@ConditionalOnMissingBean // 由于 String 是redis中最常使用的类型，所以说单独提出来了一个bean！public StringRedisTemplate stringRedisTemplate(RedisConnectionFactoryredisConnectionFactory)throws UnknownHostException {StringRedisTemplate template = new StringRedisTemplate();template.setConnectionFactory(redisConnectionFactory);return template;} 1234567891011121314151617181920212223242526272829303132333435361、导入依赖&lt;!-- 操作redis --&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;2、配置连接# 配置redisspring.redis.host=127.0.0.1spring.redis.port=63793、测试！@SpringBootTestclass Redis02SpringbootApplicationTests {@Autowiredprivate RedisTemplate redisTemplate;@Testvoid contextLoads() {// redisTemplate 操作不同的数据类型，api和我们的指令是一样的// opsForValue 操作字符串 类似String// opsForList 操作List 类似List// opsForSet// opsForHash// opsForZSet// opsForGeo// opsForHyperLogLog// 除了进本的操作，我们常用的方法都可以直接通过redisTemplate操作，比如事务，和基本的CRUD// 获取redis的连接对象// RedisConnection connection =redisTemplate.getConnectionFactory().getConnection();// connection.flushDb();// connection.flushAll();redisTemplate.opsForValue().set(&quot;mykey&quot;,&quot;关注狂神说公众号&quot;);System.out.println(redisTemplate.opsForValue().get(&quot;mykey&quot;));}} 应用场景","link":"/2021/03/01/Draft/2021/Redis/"},{"title":"魑魅先生 | 设计模式","text":"学习目的：增加系统的健壮性，易修改性和可扩展性，阅读源码的通用工具，通用问题的工具箱，程序员的通用语言 学习方法:视频引入，博客弥补，书籍细化，代码实践 学习资源：大话设计模式书籍，bili视频，博客1,博客2 学习目标程度：了解即可 实际运用 JDK SSM Springboot 设计模式原则 开闭原则 ：对修改关闭，对扩展开放 由Bertrand Meyer提出的开闭原则（Open Closed Principle）是指，软件应该对扩展开放， 而对修改关闭。这里的意思是在增加新功能的时候，能不改代码就尽量不要改， 如果只增加代码就完成了新功能，那是最好的。一个类从头到尾都是自己写的可以更改，别人的要符合开闭原则 依赖倒转原则 ：针对接口和抽象编程 上层（调用别的方法的）不能依赖于下层（方法被调用的），他们都应该依赖于抽象 合成复用原则 ：多用组合少用继承 继承（实线空箭头） 依赖 关联（实线箭头）：组合（实心菱形加箭头）（鸟和翅膀）；聚合（空心菱形加箭头）（雁和雁群） 迪米特原则（最少知道原则） ：实体之间尽量少的相互作用 个对象应对其它对象尽可能少的了解，和朋友（类中字段，方法参数，方法返回值，方法实例出来的对象）通信 里式代换原则 ：基类可以出现的地方子类也可以出现。 里氏替换原则是Barbara Liskov提出的，这是一种面向对象的设计原则， 即如果我们调用一个父类的方法可以成功，那么替换成子类调用也应该完全可以运行。 重写时子类限制等级不能更高，错误不能抛出更多 单一职责原则 ：每个方法，类，框架只负责一件事 接口隔离原则 ：使用多个专门的接口比一个总接口好 ---分--- 学习设计模式，关键是学习设计思想，不能简单地生搬硬套， 也不能为了使用设计模式而过度设计，要合理平衡设计的复杂度和灵活性， 并意识到设计模式也并不是万能的。 算法更像是菜谱： 提供达成目标的明确步骤。 而模式更像是蓝图： 你可以看到最终的结果和模式的功能， 但需要自己确定实现步骤。 意图 部分简单描述问题和解决方案。 动机 部分将进一步解释问题并说明模式会如何提供解决方案。 结构 部分展示模式的每个部分和它们之间的关系。 在不同语言中的实现 提供流行编程语言的代码， 让读者更好地理解模式背后的思想。 设计原则 一句话归纳 目的 开闭原则 对扩展开放，对修改关闭 降低维护带来的新风险 依赖倒置原则 高层不应该依赖低层，要面向接口编程 更利于代码结构的升级扩展 单一职责原则 一个类只干一件事，实现类要单一 便于理解，提高代码的可读性 接口隔离原则 一个接口只干一件事，接口要精简单一 功能解耦，高聚合、低耦合 迪米特法则 不该知道的不要知道，一个类应该保持对其它对象最少的了解，降低耦合度 只和朋友交流，不和陌生人说话，减少代码臃肿 里氏替换原则 不要破坏继承体系，子类重写方法功能发生改变，不应该影响父类方法的含义 防止继承泛滥 合成复用原则 尽量使用组合或者聚合关系实现代码复用，少使用继承 降低代码耦合 学习进度 设计原则 开闭原则 里氏替换原则 依赖倒置原则 单一职责原则 接口隔离原则 迪米特法则 合成复用原则 行为模式 职责链模式（Chain of Responsibility）😎😎😎😎😎 命令模式（Command） 迭代器模式（Iterator） 调停者（中介者）模式（Mediator） 备忘录模式（Memento） 观察者模式（Observer） 状态模式（State） 策略模式（Strategy） 模板方法模式（Template Method） 访问者模式（Visitor） 解释器模式（Interpreter） 结构型模式 适配器模式（Adapter） 桥接模式（Bridge） 组合模式（Composite） 装饰模式（Decorator） 外观模式（Facade） 享元模式（Flyweight） 代理模式（Proxy） 创建型模式 简单工厂模式（Simple Factory） 工厂方法模式（Factory Method） 抽象工厂模式（Abstract Factory） 创建者（生成器）模式（Builder） 原型模式（Prototype） 单例模式（Singleton） 进阶学习 总归纳复习 设计模式简述 模式之间的关系 Refactoringguru.cn 创建型模式 这类模式提供创建对象的机制， 能够提升已有代码的灵活性和可复用性。 工厂方法Factory Method抽象工厂Abstract Factory生成器Builder原型Prototype单例Singleton 结构型模式 这类模式介绍如何将对象和类组装成较大的结构， 并同时保持结构的灵活和高效。 适配器Adapter桥接Bridge组合Composite装饰Decorator外观Facade享元Flyweight代理Proxy 行为模式 这类模式负责对象间的高效沟通和职责委派。 责任链Chain of Responsibility命令Command迭代器Iterator中介者Mediator备忘录Memento观察者Observer状态State策略Strategy模板方法Template Method访问者Visitor 创建型模式 创建型模式的主要关注点是“怎样创建对象？”，它的主要特点是“将对象的创建与使用分离”。这样可以降低系统的耦合度，使用者不需要关注对象的创建细节，对象的创建由相关的工厂来完成。就像我们去商场购买商品时，不需要知道商品是怎么生产出来一样，因为它们由专门的厂商生产。 单例（Singleton）模式：某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例，其拓展是有限多例模式。 原型（Prototype）模式：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。 工厂方法（FactoryMethod）模式：定义一个用于创建产品的接口，由子类决定生产什么产品。 抽象工厂（AbstractFactory）模式：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。 建造者（Builder）模式：将一个复杂对象分解成多个相对简单的部分，然后根据不同需要分别创建它们，最后构建成该复杂对象。 结构型模式 结构型模式描述如何将类或对象按某种布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者釆用组合或聚合来组合对象。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象结构型模式比类结构型模式具有更大的灵活性。 代理（Proxy）模式：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。 适配器（Adapter）模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。 桥接（Bridge）模式：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现的，从而降低了抽象和实现这两个可变维度的耦合度。 装饰（Decorator）模式：动态地给对象增加一些职责，即增加其额外的功能。 外观（Facade）模式：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。 享元（Flyweight）模式：运用共享技术来有效地支持大量细粒度对象的复用。 组合（Composite）模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。 行为型模式 行为型模式用于描述程序在运行时复杂的流程控制，即描述多个类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，它涉及算法与对象间职责的分配。行为型模式分为类行为模式和对象行为模式，前者采用继承机制来在类间分派行为，后者采用组合或聚合在对象间分配行为。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象行为模式比类行为模式具有更大的灵活性。 模板方法（Template Method）模式：定义一个操作中的算法骨架，将算法的一些步骤延迟到子类中，使得子类在可以不改变该算法结构的情况下重定义该算法的某些特定步骤。 策略（Strategy）模式：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。 命令（Command）模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。 职责链（Chain of Responsibility）模式：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。 状态（State）模式：允许一个对象在其内部状态发生改变时改变其行为能力。 观察者（Observer）模式：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。 中介者（Mediator）模式：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。 迭代器（Iterator）模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。 访问者（Visitor）模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。 备忘录（Memento）模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。 解释器（Interpreter）模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。 UML 工具：processon 方法和属性的访问权限 - private # protected + public ~ package private 关系 概览 继承 | 泛化【继承并特殊】 12【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。例如：老虎是动物的一种，即有老虎的特性也有动物的共性。【箭头指向】：带三角箭头的实线，箭头指向父类 实现【接口全实现】 123【实现关系】：是一种类与接口的关系，表示类是接口所有特征和行为的实现【箭头指向】：带三角箭头的虚线，箭头指向接口 关联【我知你些属】 1234【关联关系】：是一种拥有的关系,它使一个类知道另一个类的属性和方法；如：老师与学生，丈夫与妻子关联可以是双向的，也可以是单向的。双向的关联可以有两个箭头或者没有箭头，单向的关联有一个箭头。【代码体现】：成员变量【箭头及指向】：带普通箭头的实心线，指向被拥有者 聚合【一团分几个】 1234【聚合关系】：是整体与部分的关系，且部分可以离开整体而单独存在。如车和轮胎是整体和部分的关系.聚合关系是关联关系的一种，是强的关联关系；关联和聚合在语法上无法区分，必须考察具体的逻辑关系。【代码体现】：成员变量【箭头及指向】：带空心菱形的实心线，菱形指向整体 组合【一个切几个】 123【组合关系】：是整体与部分的关系，但部分不能离开整体而单独存在。没有公司就不存在部门 组合关系是关联关系的一种，是比聚合关系还要强的关系，它要求普通的聚合关系中代表整体的对象负责代表部分的对象的生命周期【代码体现】：成员变量【箭头及指向】：带实心菱形的实线，菱形指向整体 依赖【我要用你的】 12345【依赖关系】：是一种使用的关系,所以要尽量不使用双向的互相依赖。【代码表现】：局部变量、方法的参数或者对静态方法的调用【箭头及指向】：带箭头的虚线，指向被使用者 各种关系的强弱顺序： 泛化= 实现&gt; 组合&gt; 聚合&gt; 关联&gt; 依赖 设计模式重点详解 Mybatis（ 1、Builder模式5、组合模式9、迭代器模式2、工厂模式3、单例模式4、代理6、模板方法模式7、适配器模式8、装饰者模式） Spring（1.简单工厂2.工厂方法3.单例模式4.适配器模式5.装饰器模式6.代理模式7.观察者模式8.策略模式9.模版方法模式） 创建型模式 《单例模式Singleton》 特点： 单例类只有一个实例对象； 该单例对象必须由单例类自行创建； 单例类对外提供一个访问该单例的全局访问点。 优点： 单例模式可以保证内存里只有一个实例，减少了内存的开销。 可以避免对资源的多重占用。 单例模式设置全局访问点，可以优化和共享资源的访问。 缺点： 单例模式一般没有接口，扩展困难。如果要扩展，则除了修改原来的代码，没有第二种途径，违背开闭原则。 在并发测试中，单例模式不利于代码调试。在调试过程中，如果单例中的代码没有执行完，也不能模拟生成一个新的对象。 单例模式的功能代码通常写在一个类中，如果功能设计不合理，则很容易违背单一职责原则。 单例模式的应用场景： 需要频繁创建的一些类，使用单例可以降低系统的内存压力，减少 GC。 某类只要求生成一个对象的时候，如一个班中的班长、每个人的身份证号等。 某些类创建实例时占用资源较多，或实例化耗时较长，且经常使用。 某类需要频繁实例化，而创建的对象又频繁被销毁的时候，如多线程的线程池、网络连接池等。 频繁访问数据库或文件的对象。 对于一些控制硬件级别的操作，或者从系统上来讲应当是单一控制逻辑的操作，如果有多个实例，则系统会完全乱套。 当对象需要被共享的场合。由于单例模式只允许创建一个对象，共享该对象可以节省内存，并加快对象访问速度。如 Web 中的配置对象、数据库的连接池等。 分类JAVA实现： 懒汉式：类加载时没有生成单例，只有当第一次调用 getlnstance 方法时才去创建这个单例 ​ 如果编写的是多线程程序，则不要删除上例代码中的关键字 volatile 和 synchronized，否则将存在线程非安全的问题。如果不删除这两个关键字就能保证线程安全，但是每次访问时都要同步，会影响性能，且消耗更多的资源，这是懒汉式单例的缺点。 123456789101112public class LazySingleton { private static volatile LazySingleton instance = null; //保证 instance 在所有线程中同步 private LazySingleton() { } //private 避免类在外部被实例化 public static synchronized LazySingleton getInstance() { //getInstance 方法前加同步 if (instance == null) { instance = new LazySingleton(); } return instance; }} 饿汉式：类一旦加载就创建一个单例，保证在调用 getInstance 方法之前单例已经存在了。 12345678public class HungrySingleton { private static final HungrySingleton instance = new HungrySingleton(); private HungrySingleton() { } public static HungrySingleton getInstance() { return instance; }} ​ 饿汉式单例在类创建的同时就已经创建好一个静态的对象供系统使用，以后不再改变，所以是线程安全的，可以直接用于多线程而不会出现问题。 《原型模式Prototype》 特点： 用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或相似的新对象。 原型实例指定了要创建的对象的种类。用这种方式创建对象非常高效，根本无须知道对象创建的细节。 优点： Java自带的原型模式基于内存二进制流的复制，在性能上比直接 new 一个对象更加优良。 深克隆方式保存对象的状态，使用原型模式将对象复制一份，并将其状态保存起来，简化创建对象过程，以便在需要的时候使用（例如恢复到历史某一状态），可辅助实现撤销操作。 缺点： 需要为每一个类都配置一个 clone 方法 clone 方法位于类的内部，当对已有类进行改造的时候，需要修改代码，违背了开闭原则。 当实现深克隆时，需要编写较为复杂的代码，而且当对象之间存在多重嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦。因此，深克隆、浅克隆需要运用得当。 角色： 抽象原型类：规定了具体原型对象必须实现的接口。 具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象。 访问类：使用具体原型类中的 clone() 方法来复制新的对象。 浅克隆：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。 深克隆：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。 原型模式的应用场景： 对象之间相同或相似，即只是个别的几个属性不同的时候。 创建对象成本较大，例如初始化时间长，占用CPU太多，或者占用网络资源太多等，需要优化资源。 创建一个对象需要繁琐的数据准备或访问权限等，需要提高性能或者提高安全性。 系统中大量使用该类对象，且各个调用者都需要给它的属性重新赋值。 JAVA实现： 浅克隆：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。 深克隆：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.util.*;interface Shape extends Cloneable { public Object clone(); //拷贝 public void countArea(); //计算面积}class Circle implements Shape { public Object clone() { Circle w = null; try { w = (Circle) super.clone(); } catch (CloneNotSupportedException e) { System.out.println(&quot;拷贝圆失败!&quot;); } return w; } public void countArea() { int r = 0; System.out.print(&quot;这是一个圆，请输入圆的半径：&quot;); Scanner input = new Scanner(System.in); r = input.nextInt(); System.out.println(&quot;该圆的面积=&quot; + 3.1415 * r * r + &quot;\\n&quot;); }}class Square implements Shape { public Object clone() { Square b = null; try { b = (Square) super.clone(); } catch (CloneNotSupportedException e) { System.out.println(&quot;拷贝正方形失败!&quot;); } return b; } public void countArea() { int a = 0; System.out.print(&quot;这是一个正方形，请输入它的边长：&quot;); Scanner input = new Scanner(System.in); a = input.nextInt(); System.out.println(&quot;该正方形的面积=&quot; + a * a + &quot;\\n&quot;); }}class ProtoTypeManager { private HashMap&lt;String, Shape&gt; ht = new HashMap&lt;String, Shape&gt;(); public ProtoTypeManager() { ht.put(&quot;Circle&quot;, new Circle()); ht.put(&quot;Square&quot;, new Square()); } public void addshape(String key, Shape obj) { ht.put(key, obj); } public Shape getShape(String key) { Shape temp = ht.get(key); return (Shape) temp.clone(); }}public class ProtoTypeShape { public static void main(String[] args) { ProtoTypeManager pm = new ProtoTypeManager(); Shape obj1 = (Circle) pm.getShape(&quot;Circle&quot;); obj1.countArea(); Shape obj2 = (Shape) pm.getShape(&quot;Square&quot;); obj2.countArea(); }} 《简单工厂模式Simple Factory Pattern》 特点： 定义一个创建产品对象的工厂接口，将产品对象的实际创建工作推迟到具体子工厂类当中。这满足创建型模式中所要求的“创建与使用相分离”的特点 需要生成复杂对象的地方，都可以尝试考虑使用工厂模式。复杂对象指的是类的构造函数参数过多等对类的构造有影响的情况，因为类的构造过于复杂，如果直接在其他业务类内使用，则两者的耦合过重，后续业务更改，就需要在任何引用该类的源代码内进行更改，光是查找所有依赖就很消耗时间了，更别说要一个一个修改了。 优点： 工厂类包含必要的逻辑判断，可以决定在什么时候创建哪一个产品的实例。客户端可以免除直接创建产品对象的职责，很方便的创建出相应的产品。工厂和产品的职责区分明确。 客户端无需知道所创建具体产品的类名，只需知道参数即可。 也可以引入配置文件，在不修改客户端代码的情况下更换和添加新的具体产品类。 缺点： 简单工厂模式的工厂类单一，负责所有产品的创建，职责过重，一旦异常，整个系统将受影响。且工厂类代码会非常臃肿，违背高聚合原则。 使用简单工厂模式会增加系统中类的个数（引入新的工厂类），增加系统的复杂度和理解难度 系统扩展困难，一旦增加新产品不得不修改工厂逻辑，在产品类型较多时，可能造成逻辑过于复杂 简单工厂模式使用了 static 工厂方法，造成工厂角色无法形成基于继承的等级结构。 角色： 简单工厂（SimpleFactory）：是简单工厂模式的核心，负责实现创建所有实例的内部逻辑。工厂类的创建产品类的方法可以被外界直接调用，创建所需的产品对象。 抽象产品（Product）：是简单工厂创建的所有对象的父类，负责描述所有实例共有的公共接口。 具体产品（ConcreteProduct）：是简单工厂模式的创建目标。 简单工厂模式的应用场景： 生成复杂对象 JAVA实现 123456789101112131415161718192021222324252627282930313233343536public class Client { public static void main(String[] args) { } //抽象产品 public interface Product { void show(); } //具体产品：ProductA static class ConcreteProduct1 implements Product { public void show() { System.out.println(&quot;具体产品1显示...&quot;); } } //具体产品：ProductB static class ConcreteProduct2 implements Product { public void show() { System.out.println(&quot;具体产品2显示...&quot;); } } final class Const { static final int PRODUCT_A = 0; static final int PRODUCT_B = 1; static final int PRODUCT_C = 2; } static class SimpleFactory { public static Product makeProduct(int kind) { switch (kind) { case Const.PRODUCT_A: return new ConcreteProduct1(); case Const.PRODUCT_B: return new ConcreteProduct2(); } return null; } }} 《工厂模式Factory Pattern》 特点： 可以使系统在不修改原来代码的情况下引进新的产品，即满足开闭原则。 优点： 用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程。 灵活性增强，对于新产品的创建，只需多写一个相应的工厂类。 典型的解耦框架。高层模块只需要知道产品的抽象类，无须关心其他实现类，满足迪米特法则、依赖倒置原则和里氏替换原则。 缺点： 类的个数容易过多，增加复杂度 增加了系统的抽象性和理解难度 抽象产品只能生产一种产品，此弊端可使用抽象工厂模式解决。 角色： 抽象工厂（Abstract Factory）：提供了创建产品的接口，调用者通过它访问具体工厂的工厂方法 newProduct() 来创建产品。 具体工厂（ConcreteFactory）：主要是实现抽象工厂中的抽象方法，完成具体产品的创建。 抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能。 具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应。 工厂模式的应用场景： 客户只知道创建产品的工厂名，而不知道具体的产品名。如 TCL 电视工厂、海信电视工厂等。 创建对象的任务由多个具体子工厂中的某一个完成，而抽象工厂只提供创建产品的接口。 客户不关心创建产品的细节，只关心产品的品牌 JAVA实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package FactoryMethod;public class AbstractFactoryTest { public static void main(String[] args) { try { Product a; AbstractFactory af; af = (AbstractFactory) ReadXML1.getObject(); a = af.newProduct(); a.show(); } catch (Exception e) { System.out.println(e.getMessage()); } }}//抽象产品：提供了产品的接口interface Product { public void show();}//具体产品1：实现抽象产品中的抽象方法class ConcreteProduct1 implements Product { public void show() { System.out.println(&quot;具体产品1显示...&quot;); }}//具体产品2：实现抽象产品中的抽象方法class ConcreteProduct2 implements Product { public void show() { System.out.println(&quot;具体产品2显示...&quot;); }}//抽象工厂：提供了厂品的生成方法interface AbstractFactory { public Product newProduct();}//具体工厂1：实现了厂品的生成方法class ConcreteFactory1 implements AbstractFactory { public Product newProduct() { System.out.println(&quot;具体工厂1生成--&gt;具体产品1...&quot;); return new ConcreteProduct1(); }}//具体工厂2：实现了厂品的生成方法class ConcreteFactory2 implements AbstractFactory { public Product newProduct() { System.out.println(&quot;具体工厂2生成--&gt;具体产品2...&quot;); return new ConcreteProduct2(); }} 12345678910111213141516171819202122232425262728package FactoryMethod;import javax.xml.parsers.*;import org.w3c.dom.*;import java.io.*;class ReadXML1 { //该方法用于从XML配置文件中提取具体类类名，并返回一个实例对象 public static Object getObject() { try { //创建文档对象 DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = dFactory.newDocumentBuilder(); Document doc; doc = builder.parse(new File(&quot;src/FactoryMethod/config1.xml&quot;)); //获取包含类名的文本节点 NodeList nl = doc.getElementsByTagName(&quot;className&quot;); Node classNode = nl.item(0).getFirstChild(); String cName = &quot;FactoryMethod.&quot; + classNode.getNodeValue(); //System.out.println(&quot;新类名：&quot;+cName); //通过类名生成实例对象并将其返回 Class&lt;?&gt; c = Class.forName(cName); Object obj = c.newInstance(); return obj; } catch (Exception e) { e.printStackTrace(); return null; } }} 《抽象工厂模式Abstract Factory Pattern》 特点： 一种为访问类提供一个创建一组相关或相互依赖对象的接口，且访问类无须指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。 抽象工厂模式是工厂方法模式的升级版本，工厂方法模式只生产一个等级的产品，而抽象工厂模式可生产多个等级的产品。 使用抽象工厂模式一般要满足以下条件。 系统中有多个产品族，每个具体工厂创建同一族但属于不同等级结构的产品。 系统一次只可能消费其中某一族产品，即同族的产品一起使用。 优点： 用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程。 灵活性增强，对于新产品的创建，只需多写一个相应的工厂类。 典型的解耦框架。高层模块只需要知道产品的抽象类，无须关心其他实现类，满足迪米特法则、依赖倒置原则和里氏替换原则。 可以在类的内部对产品族中相关联的多等级产品共同管理，而不必专门引入多个新的类来进行管理。 当需要产品族时，抽象工厂可以保证客户端始终只使用同一个产品的产品组。 抽象工厂增强了程序的可扩展性，当增加一个新的产品族时，不需要修改原代码，满足开闭原则。 缺点： 类的个数容易过多，增加复杂度 增加了系统的抽象性和理解难度 抽象产品只能生产一种产品，此弊端可使用抽象工厂模式解决。 当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改。增加了系统的抽象性和理解难度。 角色： 抽象工厂中方法个数不同，抽象产品的个数也不同 抽象工厂（Abstract Factory）：提供了创建产品的接口，它包含多个创建产品的方法 newProduct()，可以创建多个不同等级的产品。 具体工厂（Concrete Factory）：主要是实现抽象工厂中的多个抽象方法，完成具体产品的创建。 抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能，抽象工厂模式有多个抽象产品。 具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间是多对一的关系。 抽象工厂模式的应用场景： 抽象工厂模式最早的应用是用于创建属于不同操作系统的视窗构件。如 Java 的 AWT 中的 Button 和 Text 等构件在 Windows 和 UNIX 中的本地实现是不同的。 抽象工厂模式通常适用于以下场景： 当需要创建的对象是一系列相互关联或相互依赖的产品族时，如电器工厂中的电视机、洗衣机、空调等。 系统中有多个产品族，但每次只使用其中的某一族产品。如有人只喜欢穿某一个品牌的衣服和鞋。 系统中提供了产品的类库，且所有产品的接口相同，客户端不依赖产品实例的创建细节和内部结构。 JAVA实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package FactoryMethod;public class AbstractFactoryTest { public static void main(String[] args) { try { Product a; AbstractFactory af; af = (AbstractFactory) ReadXML1.getObject(); a = af.newProduct(); a.show(); } catch (Exception e) { System.out.println(e.getMessage()); } }}//抽象产品：提供了产品的接口interface Product { public void show();}//具体产品1：实现抽象产品中的抽象方法class ConcreteProduct1 implements Product { public void show() { System.out.println(&quot;具体产品1显示...&quot;); }}//具体产品2：实现抽象产品中的抽象方法class ConcreteProduct2 implements Product { public void show() { System.out.println(&quot;具体产品2显示...&quot;); }}//抽象工厂：提供了厂品的生成方法interface AbstractFactory { public Product newProduct();}//具体工厂1：实现了厂品的生成方法class ConcreteFactory1 implements AbstractFactory { public Product newProduct() { System.out.println(&quot;具体工厂1生成--&gt;具体产品1...&quot;); return new ConcreteProduct1(); }}//具体工厂2：实现了厂品的生成方法class ConcreteFactory2 implements AbstractFactory { public Product newProduct() { System.out.println(&quot;具体工厂2生成--&gt;具体产品2...&quot;); return new ConcreteProduct2(); }} 12345678910111213141516171819202122232425262728package FactoryMethod;import javax.xml.parsers.*;import org.w3c.dom.*;import java.io.*;class ReadXML1 { //该方法用于从XML配置文件中提取具体类类名，并返回一个实例对象 public static Object getObject() { try { //创建文档对象 DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder builder = dFactory.newDocumentBuilder(); Document doc; doc = builder.parse(new File(&quot;src/FactoryMethod/config1.xml&quot;)); //获取包含类名的文本节点 NodeList nl = doc.getElementsByTagName(&quot;className&quot;); Node classNode = nl.item(0).getFirstChild(); String cName = &quot;FactoryMethod.&quot; + classNode.getNodeValue(); //System.out.println(&quot;新类名：&quot;+cName); //通过类名生成实例对象并将其返回 Class&lt;?&gt; c = Class.forName(cName); Object obj = c.newInstance(); return obj; } catch (Exception e) { e.printStackTrace(); return null; } }} 《建造者模式 Bulider》 特点： 将一个复杂对象的构造与它的表示分离，使同样的构建过程可以创建不同的表示 它是将一个复杂的对象分解为多个简单的对象，然后一步一步构建而成。它将变与不变相分离，即产品的组成部分是不变的，但每一部分是可以灵活选择的。 优点： 封装性好，构建和表示分离。 扩展性好，各个具体的建造者相互独立，有利于系统的解耦。 客户端不必知道产品内部组成的细节，建造者可以对创建过程逐步细化，而不对其它模块产生任何影响，便于控制细节风险。 缺点： 产品的组成部分必须相同，这限制了其使用范围。 如果产品的内部变化复杂，如果产品内部发生变化，则建造者也要同步修改，后期维护成本较大。 角色： 产品角色（Product）：它是包含多个组成部件的复杂对象，由具体建造者来创建其各个零部件。 抽象建造者（Builder）：它是一个包含创建产品各个子部件的抽象方法的接口，通常还包含一个返回复杂产品的方法 getResult()。 具体建造者(Concrete Builder）：实现 Builder 接口，完成复杂产品的各个部件的具体创建方法。 指挥者（Director）：它调用建造者对象中的部件构造与装配方法完成复杂对象的创建，在指挥者中不涉及具体产品的信息。 建造者模式的应用场景： 相同的方法，不同的执行顺序，产生不同的结果。 多个部件或零件，都可以装配到一个对象中，但是产生的结果又不相同。 产品类非常复杂，或者产品类中不同的调用顺序产生不同的作用。 初始化一个对象特别复杂，参数多，而且很多参数都具有默认值。 JAVA实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package pers.lxl.mylearnproject.programbase.designpatterns.creationalpattern.bulider;/**产品角色（Product）：它是包含多个组成部件的复杂对象，由具体建造者来创建其各个零部件。*/class Product { private String partA; private String partB; private String partC; public void setPartA(String partA) { this.partA = partA; } public void setPartB(String partB) { this.partB = partB; } public void setPartC(String partC) { this.partC = partC; } public void show() { System.out.println(partA+' '+partB+' '+partC); }}/**抽象建造者（Builder）：它是一个包含创建产品各个子部件的抽象方法的接口，通常还包含一个返回复杂产品的方法 getResult()。*/abstract class Builder { //创建产品对象 protected Product product = new Product(); public abstract void buildPartA(); public abstract void buildPartB(); public abstract void buildPartC(); //返回产品对象 public Product getResult() { return product; }}/**具体建造者(Concrete Builder）：实现 Builder 接口，完成复杂产品的各个部件的具体创建方法。*/class ConcreteBuilder1 extends Builder { @Override public void buildPartA() { product.setPartA(&quot;建造 PartA&quot;); } @Override public void buildPartB() { product.setPartB(&quot;建造 PartB&quot;); } @Override public void buildPartC() { product.setPartC(&quot;建造 PartC&quot;); }}/**指挥者（Director）：它调用建造者对象中的部件构造与装配方法完成复杂对象的创建，在指挥者中不涉及具体产品的信息。*/class Director { private Builder builder; public Director(Builder builder) { this.builder = builder; } //产品构建与组装方法 public Product construct() { builder.buildPartA(); builder.buildPartB(); builder.buildPartC(); return builder.getResult(); }}public class ConcreteBuilder { public static void main(String[] args) { Builder builder = new ConcreteBuilder1(); Director director = new Director(builder); Product product = director.construct(); product.show(); }} 结构型模式 《代理模式 Proxy 》 特点： 中介 由于某些原因需要给某对象提供一个代理以控制对该对象的访问。这时，访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。 优点： 代理模式在客户端与目标对象之间起到一个中介作用和保护目标对象的作用； 代理对象可以扩展目标对象的功能； 代理模式能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性 缺点：(动态代理方式解决) 代理模式会造成系统设计中类的数量增加 在客户端和目标对象之间增加一个代理对象，会造成请求处理速度变慢； 增加了系统的复杂度； 角色： 抽象主题（Subject）类：通过接口或抽象类声明真实主题和代理对象实现的业务方法。 真实主题（Real Subject）类：实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象。 代理（Proxy）类：提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能。 根据代理的创建时期，代理模式分为静态代理和动态代理。 静态：由程序员创建代理类或特定工具自动生成源代码再对其编译，在程序运行前代理类的 .class 文件就已经存在了。 动态：在程序运行时，运用反射机制动态创建而成 代理模式的应用场景： 远程代理，这种方式通常是为了隐藏目标对象存在于不同地址空间的事实，方便客户端访问。例如，用户申请某些网盘空间时，会在用户的文件系统中建立一个虚拟的硬盘，用户访问虚拟硬盘时实际访问的是网盘空间。 虚拟代理，这种方式通常用于要创建的目标对象开销很大时。例如，下载一幅很大的图像需要很长时间，因某种计算比较复杂而短时间无法完成，这时可以先用小比例的虚拟代理替换真实的对象，消除用户对服务器慢的感觉。 安全代理，这种方式通常用于控制不同种类客户对真实对象的访问权限。 智能指引，主要用于调用目标对象时，代理附加一些额外的处理功能。例如，增加计算真实对象的引用次数的功能，这样当该对象没有被引用时，就可以自动释放它。 延迟加载，指为了提高系统的性能，延迟对目标的加载。例如，Hibernate 中就存在属性的延迟加载和关联表的延时加载。 JAVA实现： 1234567891011121314151617181920212223242526272829303132333435package proxy;public class ProxyTest { public static void main(String[] args) { Proxy proxy = new Proxy(); proxy.Request(); }}//抽象主题interface Subject { void Request();}//真实主题class RealSubject implements Subject { public void Request() { System.out.println(&quot;访问真实主题方法...&quot;); }}//代理class Proxy implements Subject { private RealSubject realSubject; public void Request() { if (realSubject == null) { realSubject = new RealSubject(); } preRequest(); realSubject.Request(); postRequest(); } public void preRequest() { System.out.println(&quot;访问真实主题之前的预处理。&quot;); } public void postRequest() { System.out.println(&quot;访问真实主题之后的后续处理。&quot;); }} 《适配器模式 Adapter 》 特点： 将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。 适配器模式分为类结构型模式和对象结构型模式两种，前者类之间的耦合度比后者高，且要求程序员了解现有组件库中的相关组件的内部结构，所以应用相对较少些。 优点： 客户端通过适配器可以透明地调用目标接口。 复用了现存的类，程序员不需要修改原有代码而重用现有的适配者类。 将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题。 在很多业务场景中符合开闭原则。 缺点： 适配器编写过程需要结合业务场景全面考虑，可能会增加系统的复杂性。 增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱。 角色： 目标（Target）接口：当前系统业务所期待的接口，它可以是抽象类或接口。 适配者（Adaptee）类：它是被访问和适配的现存组件库中的组件接口。 适配器（Adapter）类：它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。 适配器模式的应用场景： 以前开发的系统存在满足新系统功能需求的类，但其接口同新系统的接口不一致。 使用第三方提供的组件，但组件接口定义和自己要求的接口定义不同。 JAVA实现： 对象适配器 1234567891011121314151617181920212223242526package pers.lxl.mylearnproject.programbase.designpatterns.structuralpattern.adapter;//对象适配器类class ObjectAdapter implements Target{ private Adaptee adaptee; public ObjectAdapter(Adaptee adaptee) { this.adaptee=adaptee; } @Override public void request() { adaptee.specificRequest(); }}//客户端代码public class objectAdapterPattern{ public static void main(String[] args) { System.out.println(&quot;对象适配器模式测试：&quot;); Adaptee adaptee = new Adaptee(); Target target = new ObjectAdapter(adaptee); target.request(); }} 类适配器 1234567891011121314151617181920212223242526272829303132333435package pers.lxl.mylearnproject.programbase.designpatterns.structuralpattern.adapter;//目标接口interface Target{ public void request();}//适配者接口class Adaptee{ public void specificRequest() { System.out.println(&quot;适配者中的业务代码被调用！&quot;); }}//类适配器类 extends Adaptee implements Targetclass ClassAdapter extends Adaptee implements Target{ @Override public void request() { specificRequest(); }}//客户端代码public class ClassAdapterPattern{ public static void main(String[] args) { System.out.println(&quot;类适配器模式测试：&quot;); Target target = new ClassAdapter(); target.request(); }} 适配器模式（Adapter）可扩展为双向适配器模式，双向适配器类既可以把适配者接口转换成目标接口，也可以把目标接口转换成适配者接口，其结构图如图所示。 《桥接模式 Bridge》 特点： 将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。 优点： 抽象与实现分离，扩展能力强 符合开闭原则 符合合成复用原则 其实现细节对客户透明 缺点： 由于聚合关系建立在抽象层，要求开发者针对抽象化进行设计与编程，能正确地识别出系统中两个独立变化的维度，这增加了系统的理解与设计难度。 角色： 抽象化（Abstraction）角色：定义抽象类，并包含一个对实现化对象的引用。 扩展抽象化（Refined Abstraction）角色：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。 实现化（Implementor）角色：定义实现化角色的接口，供扩展抽象化角色调用。 具体实现化（Concrete Implementor）角色：给出实现化角色接口的具体实现。 桥接模式的应用场景： 当一个类存在两个独立变化的维度，且这两个维度都需要进行扩展时。 当一个系统不希望使用继承或因为多层次继承导致系统类的个数急剧增加时。 当一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性时。 JAVA实现： 123456789101112131415161718192021222324252627282930313233343536package bridge;public class BridgeTest { public static void main(String[] args) { Implementor imple = new ConcreteImplementorA(); Abstraction abs = new RefinedAbstraction(imple); abs.Operation(); }}//实现化角色interface Implementor { public void OperationImpl();}//具体实现化角色class ConcreteImplementorA implements Implementor { public void OperationImpl() { System.out.println(&quot;具体实现化(Concrete Implementor)角色被访问&quot;); }}//抽象化角色abstract class Abstraction { protected Implementor imple; protected Abstraction(Implementor imple) { this.imple = imple; } public abstract void Operation();}//扩展抽象化角色class RefinedAbstraction extends Abstraction { protected RefinedAbstraction(Implementor imple) { super(imple); } public void Operation() { System.out.println(&quot;扩展抽象化(Refined Abstraction)角色被访问&quot;); imple.OperationImpl(); }} 《装饰器模式 Decorator Pattern》 特点： 不改变现有对象结构的情况下，动态地给该对象增加一些职责（即增加其额外功能）的模式，它属于对象结构型模式。 结构修饰 优点： 装饰器是继承的有力补充，比继承灵活，在不改变原有对象的情况下，动态的给一个对象扩展功能，即插即用 通过使用不用装饰类及这些装饰类的排列组合，可以实现不同效果 装饰器模式完全遵守开闭原则 缺点： 装饰器模式会增加许多子类，过度使用会增加程序得复杂性 角色： 抽象构件（Component）角色：定义一个抽象接口以规范准备接收附加责任的对象。 具体构件（ConcreteComponent）角色：实现抽象构件，通过装饰角色为其添加一些职责。 抽象装饰（Decorator）角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。 具体装饰（ConcreteDecorator）角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。 装饰者模式的应用场景： 当需要给一个现有类添加附加职责，而又不能采用生成子类的方法进行扩充时。例如，该类被隐藏或者该类是终极类或者采用继承方式会产生大量的子类。 当需要通过对现有的一组基本功能进行排列组合而产生非常多的功能时，采用继承关系很难实现，而采用装饰器模式却很好实现。 当对象的功能要求可以动态地添加，也可以再动态地撤销时。 JAVA实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package decorator;public class DecoratorPattern { public static void main(String[] args) { Component p = new ConcreteComponent(); p.operation(); System.out.println(&quot;---------------------------------&quot;); Component d = new ConcreteDecorator(p); d.operation(); }}//抽象构件角色interface Component { public void operation();}//具体构件角色class ConcreteComponent implements Component { public ConcreteComponent() { System.out.println(&quot;创建具体构件角色&quot;); } public void operation() { System.out.println(&quot;调用具体构件角色的方法operation()&quot;); }}//抽象装饰角色class Decorator implements Component { private Component component; public Decorator(Component component) { this.component = component; } public void operation() { component.operation(); }}//具体装饰角色class ConcreteDecorator extends Decorator { public ConcreteDecorator(Component component) { super(component); } public void operation() { super.operation(); addedFunction(); } public void addedFunction() { System.out.println(&quot;为具体构件角色增加额外的功能addedFunction()&quot;); }} 《外观模式 Facade Pattern》 特点： 门面模式，是一种通过为多个复杂的子系统提供一个一致的接口，而使这些子系统更加容易被访问的模式。该模式对外有一个统一接口，外部应用程序不用关心内部子系统的具体细节，这样会大大降低应用程序的复杂度，提高了程序的可维护性。 结构修饰 优点： 降低了子系统与客户端之间的耦合度，使得子系统的变化不会影响调用它的客户类。 对客户屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易。 降低了大型软件系统中的编译依赖性，简化了系统在不同平台之间的移植过程，因为编译一个子系统不会影响其他的子系统，也不会影响外观对象。 缺点： 不能很好地限制客户使用子系统类，很容易带来未知风险。 增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则” 角色： 外观（Facade）角色：为多个子系统对外提供一个共同的接口。 子系统（Sub System）角色：实现系统的部分功能，客户可以通过外观角色访问它。 客户（Client）角色：通过一个外观角色访问各个子系统的功能。 外观 模式的应用场景： 对分层结构系统构建时，使用外观模式定义子系统中每层的入口点可以简化子系统之间的依赖关系。 当一个复杂系统的子系统很多时，外观模式可以为系统设计一个简单的接口供外界访问。 当客户端与多个子系统之间存在很大的联系时，引入外观模式可将它们分离，从而提高子系统的独立性和可移植性。 JAVA实现： 1234567891011121314151617181920212223242526272829303132333435public class FacadePattern { public static void main(String[] args) { Facade f = new Facade(); f.method(); }}//外观角色class Facade { private SubSystem01 obj1 = new SubSystem01(); private SubSystem02 obj2 = new SubSystem02(); private SubSystem03 obj3 = new SubSystem03(); public void method() { obj1.method1(); obj2.method2(); obj3.method3(); }}//子系统角色class SubSystem01 { public void method1() { System.out.println(&quot;子系统01的method1()被调用！&quot;); }}//子系统角色class SubSystem02 { public void method2() { System.out.println(&quot;子系统02的method2()被调用！&quot;); }}//子系统角色class SubSystem03 { public void method3() { System.out.println(&quot;子系统03的method3()被调用！&quot;); }} 《享元模式 Flyweight Pattern》 特点： 运用共享技术来有效地支持大量细粒度对象的复用。它通过共享已经存在的对象来大幅度减少需要创建的对象数量、避免大量相似类的开销，从而提高系统资源的利用率。 优点： 相同对象只要保存一份，这降低了系统中对象的数量，从而降低了系统中细粒度对象给内存带来的压力。 缺点： 为了使对象可以共享，需要将一些不能共享的状态外部化，这将增加程序的复杂性。 读取享元模式的外部状态会使得运行时间稍微变长。 角色： ​ 享元模式的定义提出了两个要求，细粒度和共享对象。因为要求细粒度，所以不可避免地会使对象数量多且性质相近，此时我们就将这些对象的信息分为两个部分：内部状态和外部状态。 ​ 内部状态指对象共享出来的信息，存储在享元信息内部，并且不回随环境的改变而改变； ​ 外部状态指对象得以依赖的一个标记，随环境的改变而改变，不可共享。 比如，连接池中的连接对象，保存在连接对象中的用户名、密码、连接URL等信息，在创建对象的时候就设置好了，不会随环境的改变而改变，这些为内部状态。而当每个连接要被回收利用时，我们需要将它标记为可用状态，这些为外部状态。享元模式的本质是缓存共享对象，降低内存消耗。 抽象享元角色（Flyweight）：是所有的具体享元类的基类，为具体享元规范需要实现的公共接口，非享元的外部状态以参数的形式通过方法传入。 具体享元（Concrete Flyweight）角色：实现抽象享元角色中所规定的接口。 非享元（Unsharable Flyweight)角色：是不可以共享的外部状态，它以参数的形式注入具体享元的相关方法中。 享元工厂（Flyweight Factory）角色：负责创建和管理享元角色。当客户对象请求一个享元对象时，享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。 享元模式的应用场景： 系统中存在大量相同或相似的对象，这些对象耗费大量的内存资源。 大部分的对象可以按照内部状态进行分组，且可将不同部分外部化，这样每一个组只需保存一个内部状态。 由于享元模式需要额外维护一个保存享元的数据结构，所以应当在有足够多的享元实例时才值得使用享元模式。 JAVA实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class FlyweightPattern { public static void main(String[] args) { FlyweightFactory factory = new FlyweightFactory(); Flyweight f01 = factory.getFlyweight(&quot;a&quot;); Flyweight f02 = factory.getFlyweight(&quot;a&quot;); Flyweight f03 = factory.getFlyweight(&quot;a&quot;); Flyweight f11 = factory.getFlyweight(&quot;b&quot;); Flyweight f12 = factory.getFlyweight(&quot;b&quot;); f01.operation(new UnsharedConcreteFlyweight(&quot;第1次调用a。&quot;)); f02.operation(new UnsharedConcreteFlyweight(&quot;第2次调用a。&quot;)); f03.operation(new UnsharedConcreteFlyweight(&quot;第3次调用a。&quot;)); f11.operation(new UnsharedConcreteFlyweight(&quot;第1次调用b。&quot;)); f12.operation(new UnsharedConcreteFlyweight(&quot;第2次调用b。&quot;)); }}//非享元角色class UnsharedConcreteFlyweight { private String info; UnsharedConcreteFlyweight(String info) { this.info = info; } public String getInfo() { return info; } public void setInfo(String info) { this.info = info; }}//抽象享元角色interface Flyweight { public void operation(UnsharedConcreteFlyweight state);}//具体享元角色class ConcreteFlyweight implements Flyweight { private String key; ConcreteFlyweight(String key) { this.key = key; System.out.println(&quot;具体享元&quot; + key + &quot;被创建！&quot;); } public void operation(UnsharedConcreteFlyweight outState) { System.out.print(&quot;具体享元&quot; + key + &quot;被调用，&quot;); System.out.println(&quot;非享元信息是:&quot; + outState.getInfo()); }}//享元工厂角色class FlyweightFactory { private HashMap&lt;String, Flyweight&gt; flyweights = new HashMap&lt;String, Flyweight&gt;(); public Flyweight getFlyweight(String key) { Flyweight flyweight = (Flyweight) flyweights.get(key); if (flyweight != null) { System.out.println(&quot;具体享元&quot; + key + &quot;已经存在，被成功获取！&quot;); } else { flyweight = new ConcreteFlyweight(key); flyweights.put(key, flyweight); } return flyweight; }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import javax.swing.*;import java.awt.*;import java.awt.event.MouseAdapter;import java.awt.event.MouseEvent;import java.util.ArrayList;public class WzqGame { public static void main(String[] args) { new Chessboard(); }}//棋盘class Chessboard extends MouseAdapter { WeiqiFactory wf; JFrame f; Graphics g; JRadioButton wz; JRadioButton bz; private final int x = 50; private final int y = 50; private final int w = 40; //小方格宽度和高度 private final int rw = 400; //棋盘宽度和高度 Chessboard() { wf = new WeiqiFactory(); f = new JFrame(&quot;享元模式在五子棋游戏中的应用&quot;); f.setBounds(100, 100, 500, 550); f.setVisible(true); f.setResizable(false); f.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); JPanel SouthJP = new JPanel(); f.add(&quot;South&quot;, SouthJP); wz = new JRadioButton(&quot;白子&quot;); bz = new JRadioButton(&quot;黑子&quot;, true); ButtonGroup group = new ButtonGroup(); group.add(wz); group.add(bz); SouthJP.add(wz); SouthJP.add(bz); JPanel CenterJP = new JPanel(); CenterJP.setLayout(null); CenterJP.setSize(500, 500); CenterJP.addMouseListener(this); f.add(&quot;Center&quot;, CenterJP); try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } g = CenterJP.getGraphics(); g.setColor(Color.BLUE); g.drawRect(x, y, rw, rw); for (int i = 1; i &lt; 10; i++) { //绘制第i条竖直线 g.drawLine(x + (i * w), y, x + (i * w), y + rw); //绘制第i条水平线 g.drawLine(x, y + (i * w), x + rw, y + (i * w)); } } public void mouseClicked(MouseEvent e) { Point pt = new Point(e.getX() - 15, e.getY() - 15); if (wz.isSelected()) { ChessPieces c1 = wf.getChessPieces(&quot;w&quot;); c1.DownPieces(g, pt); } else if (bz.isSelected()) { ChessPieces c2 = wf.getChessPieces(&quot;b&quot;); c2.DownPieces(g, pt); } }}//抽象享元角色：棋子interface ChessPieces { public void DownPieces(Graphics g, Point pt); //下子}//具体享元角色：白子class WhitePieces implements ChessPieces { public void DownPieces(Graphics g, Point pt) { g.setColor(Color.WHITE); g.fillOval(pt.x, pt.y, 30, 30); }}//具体享元角色：黑子class BlackPieces implements ChessPieces { public void DownPieces(Graphics g, Point pt) { g.setColor(Color.BLACK); g.fillOval(pt.x, pt.y, 30, 30); }}//享元工厂角色class WeiqiFactory { private ArrayList&lt;ChessPieces&gt; qz; public WeiqiFactory() { qz = new ArrayList&lt;ChessPieces&gt;(); ChessPieces w = new WhitePieces(); qz.add(w); ChessPieces b = new BlackPieces(); qz.add(b); } public ChessPieces getChessPieces(String type) { if (type.equalsIgnoreCase(&quot;w&quot;)) { return (ChessPieces) qz.get(0); } else if (type.equalsIgnoreCase(&quot;b&quot;)) { return (ChessPieces) qz.get(1); } else { return null; } }} 《组合模式 Composite Pattern》 特点： 将对象组合成树状的层次结构的模式，用来表示“整体-部分”的关系，使用户对单个对象和组合对象具有一致的访问性 部分-整体 优点： 组合模式使得客户端代码可以一致地处理单个对象和组合对象，无须关心自己处理的是单个对象，还是组合对象，这简化了客户端代码； 更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足“开闭原则”； 缺点： 设计较复杂，客户端需要花更多时间理清类之间的层次关系； 不容易限制容器中的构件； 不容易用继承的方法来增加构件的新功能； 角色： 分类： 透明方式 安全方式 抽象构件（Component）角色：它的主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。（总的抽象类或接口，定义一些通用的方法，比如新增、删除） 树叶构件（Leaf）角色：是组合中的叶节点对象，它没有子节点，用于继承或实现抽象构件。 树枝构件（Composite）角色 / 中间构件：是组合中的分支节点对象，它有子节点，用于继承和实现抽象构件。它的主要作用是存储和管理子部件，通常包含 Add()、Remove()、GetChild() 等方法。 组合模式的应用场景： 在需要表示一个对象整体与部分的层次结构的场合。 要求对用户隐藏组合对象与单个对象的不同，用户可以用统一的接口使用组合结构中的所有对象的场合。 JAVA实现： 安全组合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.util.ArrayList;public class Safe { public static void main(String[] args) { Composite c0 = new Composite(); Composite c1 = new Composite(); Component leaf1 = new Leaf(&quot;1&quot;); Component leaf2 = new Leaf(&quot;2&quot;); Component leaf3 = new Leaf(&quot;3&quot;); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation(); }}//抽象构件interface Component {// public void add(Component c);// public void remove(Component c);// public Component getChild(int i); public void operation();}//树叶构件class Leaf implements Component { private String name; public Leaf(String name) { this.name = name; } public void add(Component c) { } public void remove(Component c) { } public Component getChild(int i) { return null; } @Override public void operation() { System.out.println(&quot;树叶&quot; + name + &quot;：被访问！&quot;); }}//树枝构件class Composite implements Component { private ArrayList&lt;Component&gt; children = new ArrayList&lt;Component&gt;(); public void add(Component c) { children.add(c); } public void remove(Component c) { children.remove(c); } public Component getChild(int i) { return children.get(i); } @Override public void operation() { for (Object obj : children) { ((Component) obj).operation(); } }} 透明组合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.ArrayList;public class transparent { public static void main(String[] args) { Component c0 = new Composite(); Component c1 = new Composite(); Component leaf1 = new Leaf(&quot;1&quot;); Component leaf2 = new Leaf(&quot;2&quot;); Component leaf3 = new Leaf(&quot;3&quot;); c0.add(leaf1); c0.add(c1); c1.add(leaf2); c1.add(leaf3); c0.operation(); }}//抽象构件interface Component { public void add(Component c); public void remove(Component c); public Component getChild(int i); public void operation();}//树叶构件class Leaf implements Component { private String name; public Leaf(String name) { this.name = name; } @Override public void add(Component c) { } @Override public void remove(Component c) { } @Override public Component getChild(int i) { return null; } @Override public void operation() { System.out.println(&quot;树叶&quot; + name + &quot;：被访问！&quot;); }}//树枝构件class Composite implements Component { private ArrayList&lt;Component&gt; children = new ArrayList&lt;Component&gt;(); @Override public void add(Component c) { children.add(c); } @Override public void remove(Component c) { children.remove(c); } @Override public Component getChild(int i) { return children.get(i); } @Override public void operation() { for (Object obj : children) { ((Component) obj).operation(); } }} 行为型模式 《**模板方法模式 **Template method pattern》 特点： 定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。 优点： 它封装了不变部分，扩展可变部分。它把认为是不变部分的算法封装到父类中实现，而把可变部分算法由子类继承实现，便于子类继续扩展。 它在父类中提取了公共的部分代码，便于代码复用。 部分方法是由子类实现的，因此子类可以通过扩展方式增加相应的功能，符合开闭原则。 缺点： 对每个不同的实现都需要定义一个子类，这会导致类的个数增加，系统更加庞大，设计也更加抽象，间接地增加了系统实现的复杂度。 父类中的抽象方法由子类实现，子类执行的结果会影响父类的结果，这导致一种反向的控制结构，它提高了代码阅读的难度。 由于继承关系自身的缺点，如果父类添加新的抽象方法，则所有子类都要改一遍。 角色： 1）抽象类/抽象模板（Abstract Class） 抽象模板类，负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成。这些方法的定义如下。 ① 模板方法：定义了算法的骨架，按某种顺序调用其包含的基本方法。 ② 基本方法：是整个算法中的一个步骤，包含以下几种类型。 抽象方法：在抽象类中声明，由具体子类实现。 具体方法：在抽象类中已经实现，在具体子类中可以继承或重写它。 钩子方法：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。 2）具体子类/具体实现（Concrete Class） 具体实现类，实现抽象类中所定义的抽象方法和钩子方法，它们是一个顶级逻辑的一个组成步骤。 模板方法模式的应用场景： 算法的整体步骤很固定，但其中个别部分易变时，这时候可以使用模板方法模式，将容易变的部分抽象出来，供子类实现。 当多个子类存在公共的行为时，可以将其提取出来并集中到一个公共父类中以避免代码重复。首先，要识别现有代码中的不同之处，并且将不同之处分离为新的操作。最后，用一个调用这些新的操作的模板方法来替换这些不同的代码。 当需要控制子类的扩展时，模板方法只在特定点调用钩子操作，这样就只允许在这些点进行扩展。 JAVA实现： 12345678910111213141516171819202122232425262728293031323334public class TemplateMethodPattern { public static void main(String[] args) { AbstractClass tm = new ConcreteClass(); tm.TemplateMethod(); }}//抽象类abstract class AbstractClass { //模板方法 public void TemplateMethod() { SpecificMethod(); abstractMethod1(); abstractMethod2(); } //具体方法 public void SpecificMethod() { System.out.println(&quot;抽象类中的具体方法被调用...&quot;); } //抽象方法1 public abstract void abstractMethod1(); //抽象方法2 public abstract void abstractMethod2();}//具体子类class ConcreteClass extends AbstractClass { @Override public void abstractMethod1() { System.out.println(&quot;抽象方法1的实现被调用...&quot;); } @Override public void abstractMethod2() { System.out.println(&quot;抽象方法2的实现被调用...&quot;); }} 《**策略模式 **Strategy Pattern》 特点： 该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。 优点： 多重条件语句不易维护，而使用策略模式可以避免使用多重条件语句，如 if...else 语句、switch...case 语句。 策略模式提供了一系列的可供重用的算法族，恰当使用继承可以把算法族的公共代码转移到父类里面，从而避免重复的代码。 策略模式可以提供相同行为的不同实现，客户可以根据不同时间或空间要求选择不同的。 策略模式提供了对开闭原则的完美支持，可以在不修改原代码的情况下，灵活增加新算法。 策略模式把算法的使用放到环境类中，而算法的实现移到具体策略类中，实现了二者的分离。 缺点： 客户端必须理解所有策略算法的区别，以便适时选择恰当的算法类。 策略模式造成很多的策略类，增加维护难度。 角色： 抽象策略（Strategy）类：定义了一个公共接口，各种不同的算法以不同的方式实现这个接口，环境角色使用这个接口调用不同的算法，一般使用接口或抽象类实现。 具体策略（Concrete Strategy）类：实现了抽象策略定义的接口，提供具体的算法实现。 环境（Context）类：持有一个策略类的引用，最终给客户端调用。 策略模式的应用场景： 一个系统需要动态地在几种算法中选择一种时，可将每个算法封装到策略类中。 一个类定义了多种行为，并且这些行为在这个类的操作中以多个条件语句的形式出现，可将每个条件分支移入它们各自的策略类中以代替这些条件语句。 系统中各算法彼此完全独立，且要求对客户隐藏具体算法的实现细节时。 系统要求使用算法的客户不应该知道其操作的数据时，可使用策略模式来隐藏与算法相关的数据结构。 多个类只区别在表现行为不同，可以使用策略模式，在运行时动态选择具体要执行的行为。 JAVA实现： 1234567891011121314151617181920212223242526272829303132333435363738394041public class StrategyPattern { public static void main(String[] args) { Context c = new Context(); Strategy s = new ConcreteStrategyA(); c.setStrategy(s); c.strategyMethod(); System.out.println(&quot;-----------------&quot;); s = new ConcreteStrategyB(); c.setStrategy(s); c.strategyMethod(); }}//抽象策略类interface Strategy { public void strategyMethod(); //策略方法}//具体策略类Aclass ConcreteStrategyA implements Strategy { public void strategyMethod() { System.out.println(&quot;具体策略A的策略方法被访问！&quot;); }}//具体策略类Bclass ConcreteStrategyB implements Strategy { public void strategyMethod() { System.out.println(&quot;具体策略B的策略方法被访问！&quot;); }}//环境类class Context { private Strategy strategy; public Strategy getStrategy() { return strategy; } public void setStrategy(Strategy strategy) { this.strategy = strategy; } public void strategyMethod() { strategy.strategyMethod(); }} 《**命令模式 **Command Pattern》 特点： 将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。 优点： 通过引入中间件（抽象接口）降低系统的耦合度。 扩展性良好，增加或删除命令非常方便。采用命令模式增加与删除命令不会影响其他类，且满足“开闭原则”。 可以实现宏命令。命令模式可以与组合模式结合，将多个命令装配成一个组合命令，即宏命令。 方便实现 Undo 和 Redo 操作。命令模式可以与后面介绍的备忘录模式结合，实现命令的撤销与恢复。 可以在现有命令的基础上，增加额外功能。比如日志记录，结合装饰器模式会更加灵活。 缺点： 可能产生大量具体的命令类。因为每一个具体操作都需要设计一个具体命令类，这会增加系统的复杂性。 命令模式的结果其实就是接收方的执行结果，但是为了以命令的形式进行架构、解耦请求与实现，引入了额外类型结构（引入了请求方与抽象命令接口），增加了理解上的困难。不过这也是设计模式的通病，抽象必然会额外增加类的数量，代码抽离肯定比代码聚合更加难理解 角色： 抽象命令类（Command）角色：声明执行命令的接口，拥有执行命令的抽象方法 execute()。 具体命令类（Concrete Command）角色：是抽象命令类的具体实现类，它拥有接收者对象，并通过调用接收者的功能来完成命令要执行的操作。 实现者/接收者（Receiver）角色：执行命令功能的相关操作，是具体命令对象业务的真正实现者。 调用者/请求者（Invoker）角色：是请求的发送者，它通常拥有很多的命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者。 命令模式的应用场景： 请求调用者需要与请求接收者解耦时，命令模式可以使调用者和接收者不直接交互。 系统随机请求命令或经常增加、删除命令时，命令模式可以方便地实现这些功能。 当系统需要执行一组操作时，命令模式可以定义宏命令来实现该功能。 当系统需要支持命令的撤销（Undo）操作和恢复（Redo）操作时，可以将命令对象存储起来，采用备忘录模式来实现。 JAVA实现： 1234567891011121314151617181920212223242526272829303132333435363738394041public class StrategyPattern { public static void main(String[] args) { Context c = new Context(); Strategy s = new ConcreteStrategyA(); c.setStrategy(s); c.strategyMethod(); System.out.println(&quot;-----------------&quot;); s = new ConcreteStrategyB(); c.setStrategy(s); c.strategyMethod(); }}//抽象策略类interface Strategy { public void strategyMethod(); //策略方法}//具体策略类Aclass ConcreteStrategyA implements Strategy { public void strategyMethod() { System.out.println(&quot;具体策略A的策略方法被访问！&quot;); }}//具体策略类Bclass ConcreteStrategyB implements Strategy { public void strategyMethod() { System.out.println(&quot;具体策略B的策略方法被访问！&quot;); }}//环境类class Context { private Strategy strategy; public Strategy getStrategy() { return strategy; } public void setStrategy(Strategy strategy) { this.strategy = strategy; } public void strategyMethod() { strategy.strategyMethod(); }} 《**责任/职责 链模式 **Chain of Responsibility pattern》 特点： 为了避免请求发送者与多个请求处理者耦合在一起，于是将所有请求的处理者通过前一对象记住其下一个对象的引用而连成一条链；当有请求发生时，可将请求沿着这条链传递，直到有对象处理它为止。 优点： 降低了对象之间的耦合度。该模式使得一个对象无须知道到底是哪一个对象处理其请求以及链的结构，发送者和接收者也无须拥有对方的明确信息。 增强了系统的可扩展性。可以根据需要增加新的请求处理类，满足开闭原则。 增强了给对象指派职责的灵活性。当工作流程发生变化，可以动态地改变链内的成员或者调动它们的次序，也可动态地新增或者删除责任。 责任链简化了对象之间的连接。每个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的 if 或者 if···else 语句。 责任分担。每个类只需要处理自己该处理的工作，不该处理的传递给下一个对象完成，明确各类的责任范围，符合类的单一职责原则。 缺点： 不能保证每个请求一定被处理。由于一个请求没有明确的接收者，所以不能保证它一定会被处理，该请求可能一直传到链的末端都得不到处理。 对比较长的职责链，请求的处理可能涉及多个处理对象，系统性能将受到一定影响。 职责链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于职责链的错误设置而导致系统出错，如可能会造成循环调用。 角色： 抽象处理者（Handler）角色：定义一个处理请求的接口，包含抽象处理方法和一个后继连接。 具体处理者（Concrete Handler）角色：实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者。 客户类（Client）角色：创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。 责任/职责 链模式的应用场景： 多个对象可以处理一个请求，但具体由哪个对象处理该请求在运行时自动确定。 可动态指定一组对象处理请求，或添加新的处理者。 需要在不明确指定请求处理者的情况下，向多个处理者中的一个提交请求。 JAVA实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class ChainOfResponsibilityPattern { public static void main(String[] args) { //组装责任链 Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); handler1.setNext(handler2); //提交请求 handler1.handleRequest(&quot;two&quot;); }}//抽象处理者角色abstract class Handler { private Handler next; public void setNext(Handler next) { this.next = next; } public Handler getNext() { return next; } //处理请求的方法 public abstract void handleRequest(String request);}//具体处理者角色1class ConcreteHandler1 extends Handler { @Override public void handleRequest(String request) { if (request.equals(&quot;one&quot;)) { System.out.println(&quot;具体处理者1负责处理该请求！&quot;); } else { if (getNext() != null) { getNext().handleRequest(request); } else { System.out.println(&quot;没有人处理该请求！&quot;); } } }}//具体处理者角色2class ConcreteHandler2 extends Handler { @Override public void handleRequest(String request) { if (request.equals(&quot;two&quot;)) { System.out.println(&quot;具体处理者2负责处理该请求！&quot;); } else { if (getNext() != null) { getNext().handleRequest(request); } else { System.out.println(&quot;没有人处理该请求！&quot;); } } }} 《**状态模式 **State pattern》 特点： 对有状态的对象，把复杂的“判断逻辑”提取到不同的状态对象中，允许状态对象在其内部状态发生改变时改变其行为。 优点： 结构清晰，状态模式将与特定状态相关的行为局部化到一个状态中，并且将不同状态的行为分割开来，满足“单一职责原则”。 将状态转换显示化，减少对象间的相互依赖。将不同的状态引入独立的对象中会使得状态转换变得更加明确，且减少对象间的相互依赖。 状态类职责明确，有利于程序的扩展。通过定义新的子类很容易地增加新的状态和转换。 缺点： 状态模式的使用必然会增加系统的类与对象的个数。 状态模式的结构与实现都较为复杂，如果使用不当会导致程序结构和代码的混乱。 状态模式对开闭原则的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源码，否则无法切换到新增状态，而且修改某个状态类的行为也需要修改对应类的源码。 角色： 环境类（Context）角色：也称为上下文，它定义了客户端需要的接口，内部维护一个当前状态，并负责具体状态的切换。 抽象状态（State）角色：定义一个接口，用以封装环境对象中的特定状态所对应的行为，可以有一个或多个行为。 具体状态（Concrete State）角色：实现抽象状态所对应的行为，并且在需要的情况下进行状态切换。 状态模式的应用场景： 当一个对象的行为取决于它的状态，并且它必须在运行时根据状态改变它的行为时，就可以考虑使用状态模式。 一个操作中含有庞大的分支结构，并且这些分支决定于对象的状态时。 JAVA实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class StatePatternClient { public static void main(String[] args) { Context context = new Context(); //创建环境 context.Handle(); //处理请求 context.Handle(); context.Handle(); context.Handle(); }}//环境类class Context { private State state; //定义环境类的初始状态 public Context() { this.state = new ConcreteStateA(); } //设置新状态 public void setState(State state) { this.state = state; } //读取状态 public State getState() { return (state); } //对请求做处理 public void Handle() { state.Handle(this); }}//抽象状态类abstract class State { public abstract void Handle(Context context);}//具体状态A类class ConcreteStateA extends State { @Override public void Handle(Context context) { System.out.println(&quot;当前状态是 A.&quot;); context.setState(new ConcreteStateB()); }}//具体状态B类class ConcreteStateB extends State { @Override public void Handle(Context context) { System.out.println(&quot;当前状态是 B.&quot;); context.setState(new ConcreteStateA()); }} 《观察者模式 Observer pattern》 特点： 指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。这种模式有时又称作发布-订阅模式、模型-视图模式。 优点： 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则。 目标与观察者之间建立了一套触发机制。 缺点： 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用。 当观察者对象很多时，通知的发布会花费很多时间，影响程序的效率。 角色： 抽象主题（Subject）角色：也叫抽象目标类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法。 具体主题（Concrete Subject）角色：也叫具体目标类，它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象。 抽象观察者（Observer）角色：它是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用。 具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态。 观察者模式的应用场景： 对象间存在一对多关系，一个对象的状态发生改变会影响其他对象。 当一个抽象模型有两个方面，其中一个方面依赖于另一方面时，可将这二者封装在独立的对象中以使它们可以各自独立地改变和复用。 实现类似广播机制的功能，不需要知道具体收听者，只需分发广播，系统中感兴趣的对象会自动接收该广播。 多层级嵌套使用，形成一种链式触发机制，使得事件具备跨域（跨越两种观察者类型）通知。 JAVA实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class StatePatternClient { public static void main(String[] args) { Context context = new Context(); //创建环境 context.Handle(); //处理请求 context.Handle(); context.Handle(); context.Handle(); }}//环境类class Context { private State state; //定义环境类的初始状态 public Context() { this.state = new ConcreteStateA(); } //设置新状态 public void setState(State state) { this.state = state; } //读取状态 public State getState() { return (state); } //对请求做处理 public void Handle() { state.Handle(this); }}//抽象状态类abstract class State { public abstract void Handle(Context context);}//具体状态A类class ConcreteStateA extends State { @Override public void Handle(Context context) { System.out.println(&quot;当前状态是 A.&quot;); context.setState(new ConcreteStateB()); }}//具体状态B类class ConcreteStateB extends State { @Override public void Handle(Context context) { System.out.println(&quot;当前状态是 B.&quot;); context.setState(new ConcreteStateA()); }} 《中介者模式 Mediator Pattern》 特点： 定义一个中介对象来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。 优点： 类之间各司其职，符合迪米特法则。 降低了对象之间的耦合性，使得对象易于独立地被复用。 将对象间的一对多关联转变为一对一的关联，提高系统的灵活性，使得系统易于维护和扩展。 缺点： 中介者模式将原本多个对象直接的相互依赖变成了中介者和多个同事类的依赖关系。当同事类越多时，中介者就会越臃肿，变得复杂且难以维护。 角色： 抽象中介者（Mediator）角色：它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法。 具体中介者（Concrete Mediator）角色：实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色。 抽象同事类（Colleague）角色：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能。 具体同事类（Concrete Colleague）角色：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互。 中介者模式的应用场景： 当对象之间存在复杂的网状结构关系而导致依赖关系混乱且难以复用时。 当想创建一个运行于多个类之间的对象，又不想生成新的子类时 JAVA实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import java.util.*;public class MediatorPattern { public static void main(String[] args) { Mediator md = new ConcreteMediator(); Colleague c1, c2; c1 = new ConcreteColleague1(); c2 = new ConcreteColleague2(); md.register(c1); md.register(c2); c1.send(); System.out.println(&quot;-------------&quot;); c2.send(); }}//抽象中介者abstract class Mediator { public abstract void register(Colleague colleague); public abstract void relay(Colleague cl); //转发}//具体中介者class ConcreteMediator extends Mediator { private List&lt;Colleague&gt; colleagues = new ArrayList&lt;Colleague&gt;(); public void register(Colleague colleague) { if (!colleagues.contains(colleague)) { colleagues.add(colleague); colleague.setMedium(this); } } public void relay(Colleague cl) { for (Colleague ob : colleagues) { if (!ob.equals(cl)) { ((Colleague) ob).receive(); } } }}//抽象同事类abstract class Colleague { protected Mediator mediator; public void setMedium(Mediator mediator) { this.mediator = mediator; } public abstract void receive(); public abstract void send();}//具体同事类class ConcreteColleague1 extends Colleague { public void receive() { System.out.println(&quot;具体同事类1收到请求。&quot;); } public void send() { System.out.println(&quot;具体同事类1发出请求。&quot;); mediator.relay(this); //请中介者转发 }}//具体同事类class ConcreteColleague2 extends Colleague { public void receive() { System.out.println(&quot;具体同事类2收到请求。&quot;); } public void send() { System.out.println(&quot;具体同事类2发出请求。&quot;); mediator.relay(this); //请中介者转发 }} 《迭代器模式 Iterator Pattern》 特点： 提供一个对象来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。 优点： 访问一个聚合对象的内容而无须暴露它的内部表示。 遍历任务交由迭代器完成，这简化了聚合类。 它支持以不同方式遍历一个聚合，甚至可以自定义迭代器的子类以支持新的遍历。 增加新的聚合类和迭代器类都很方便，无须修改原有代码。 封装性良好，为遍历不同的聚合结构提供一个统一的接口。 缺点： 增加了类的个数，这在一定程度上增加了系统的复杂性。 角色： 抽象聚合（Aggregate）角色：定义存储、添加、删除聚合对象以及创建迭代器对象的接口。 具体聚合（ConcreteAggregate）角色：实现抽象聚合类，返回一个具体迭代器的实例。 抽象迭代器（Iterator）角色：定义访问和遍历聚合元素的接口，通常包含 hasNext()、first()、next() 等方法。 具体迭代器（Concretelterator）角色：实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。 中介者模式的应用场景： 当需要为聚合对象提供多种遍历方式时。 当需要为遍历不同的聚合结构提供一个统一的接口时。 当访问一个聚合对象的内容而无须暴露其内部细节的表示时。 JAVA实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import java.util.*;public class IteratorPattern { public static void main(String[] args) { Aggregate ag = new ConcreteAggregate(); ag.add(&quot;中山大学&quot;); ag.add(&quot;华南理工&quot;); ag.add(&quot;韶关学院&quot;); System.out.print(&quot;聚合的内容有：&quot;); Iterator it = ag.getIterator(); while (it.hasNext()) { Object ob = it.next(); System.out.print(ob.toString() + &quot;\\t&quot;); } Object ob = it.first(); System.out.println(&quot;\\nFirst：&quot; + ob.toString()); }}//抽象聚合 定义存储、添加、删除聚合对象以及创建迭代器对象的接口。interface Aggregate { public void add(Object obj); public void remove(Object obj); public Iterator getIterator();}//具体聚合 实现抽象聚合类，返回一个具体迭代器的实例。class ConcreteAggregate implements Aggregate { private List&lt;Object&gt; list = new ArrayList&lt;Object&gt;(); @Override public void add(Object obj) { list.add(obj); } @Override public void remove(Object obj) { list.remove(obj); } @Override public Iterator getIterator() { return (new ConcreteIterator(list)); }}//抽象迭代器interface Iterator { Object first(); Object next(); boolean hasNext();}//具体迭代器class ConcreteIterator implements Iterator { private List&lt;Object&gt; list = null; private int index = -1; public ConcreteIterator(List&lt;Object&gt; list) { this.list = list; } @Override public boolean hasNext() { if (index &lt; list.size() - 1) { return true; } else { return false; } } @Override public Object first() { index = 0; Object obj = list.get(index); ; return obj; } @Override public Object next() { Object obj = null; if (this.hasNext()) { obj = list.get(++index); } return obj; }} 《访问者模式 Visitor Pattern》 特点： 将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离，是行为类模式中最复杂的一种模式。 优点： 扩展性好。能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。 复用性好。可以通过访问者来定义整个对象结构通用的功能，从而提高系统的复用程度。 灵活性好。访问者模式将数据结构与作用于结构上的操作解耦，使得操作集合可相对自由地演化而不影响系统的数据结构。 符合单一职责原则。访问者模式把相关的行为封装在一起，构成一个访问者，使每一个访问者的功能都比较单一。 缺点： 增加新的元素类很困难。在访问者模式中，每增加一个新的元素类，都要在每一个具体访问者类中增加相应的具体操作，这违背了“开闭原则”。 破坏封装。访问者模式中具体元素对访问者公布细节，这破坏了对象的封装性。 违反了依赖倒置原则。访问者模式依赖了具体类，而没有依赖抽象类。 角色： 抽象访问者（Visitor）角色：定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作 visit() ，该操作中的参数类型标识了被访问的具体元素。 具体访问者（ConcreteVisitor）角色：实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时该做什么。 抽象元素（Element）角色：声明一个包含接受操作 accept() 的接口，被接受的访问者对象作为 accept() 方法的参数。 具体元素（ConcreteElement）角色：实现抽象元素角色提供的 accept() 操作，其方法体通常都是 visitor.visit(this) ，另外具体元素中可能还包含本身业务逻辑的相关操作。 对象结构（Object Structure）角色：是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法，通常由 List、Set、Map 等聚合类实现。 访问者模式的应用场景： 对象结构相对稳定，但其操作算法经常变化的程序。 对象结构中的对象需要提供多种不同且不相关的操作，而且要避免让这些操作的变化影响对象的结构。 对象结构包含很多类型的对象，希望对这些对象实施一些依赖于其具体类型的操作。 JAVA实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import java.util.*;public class VisitorPattern { public static void main(String[] args) { ObjectStructure os = new ObjectStructure(); os.add(new ConcreteElementA()); os.add(new ConcreteElementB()); Visitor visitor = new ConcreteVisitorA(); os.accept(visitor); System.out.println(&quot;------------------------&quot;); visitor = new ConcreteVisitorB(); os.accept(visitor); }}//抽象访问者interface Visitor { void visit(ConcreteElementA element); void visit(ConcreteElementB element);}//具体访问者A类class ConcreteVisitorA implements Visitor { public void visit(ConcreteElementA element) { System.out.println(&quot;具体访问者A访问--&gt;&quot; + element.operationA()); } public void visit(ConcreteElementB element) { System.out.println(&quot;具体访问者A访问--&gt;&quot; + element.operationB()); }}//具体访问者B类class ConcreteVisitorB implements Visitor { public void visit(ConcreteElementA element) { System.out.println(&quot;具体访问者B访问--&gt;&quot; + element.operationA()); } public void visit(ConcreteElementB element) { System.out.println(&quot;具体访问者B访问--&gt;&quot; + element.operationB()); }}//抽象元素类interface Element { void accept(Visitor visitor);}//具体元素A类class ConcreteElementA implements Element { public void accept(Visitor visitor) { visitor.visit(this); } public String operationA() { return &quot;具体元素A的操作。&quot;; }}//具体元素B类class ConcreteElementB implements Element { public void accept(Visitor visitor) { visitor.visit(this); } public String operationB() { return &quot;具体元素B的操作。&quot;; }}//对象结构角色class ObjectStructure { private List&lt;Element&gt; list = new ArrayList&lt;Element&gt;(); public void accept(Visitor visitor) { Iterator&lt;Element&gt; i = list.iterator(); while (i.hasNext()) { ((Element) i.next()).accept(visitor); } } public void add(Element element) { list.add(element); } public void remove(Element element) { list.remove(element); }} 《备忘录/快照 模式 Memento Pattern》 特点： 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫快照模式。 优点： 提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态。 实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息。 简化了发起人类。发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，这符合单一职责原则。 缺点： 资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源。 角色： 发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。 备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。 管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。 备忘录/快照 模式的应用场景： JAVA实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class MementoPattern { public static void main(String[] args) { Originator or = new Originator(); Caretaker cr = new Caretaker(); or.setState(&quot;S0&quot;); System.out.println(&quot;初始状态:&quot; + or.getState()); cr.setMemento(or.createMemento()); //保存状态 or.setState(&quot;S1&quot;); System.out.println(&quot;新的状态:&quot; + or.getState()); or.restoreMemento(cr.getMemento()); //恢复状态 System.out.println(&quot;恢复状态:&quot; + or.getState()); }}//备忘录class Memento { private String state; public Memento(String state) { this.state = state; } public void setState(String state) { this.state = state; } public String getState() { return state; }}//发起人class Originator { private String state; public void setState(String state) { this.state = state; } public String getState() { return state; } public Memento createMemento() { return new Memento(state); } public void restoreMemento(Memento m) { this.setState(m.getState()); }}//管理者class Caretaker { private Memento memento; public void setMemento(Memento m) { memento = m; } public Memento getMemento() { return memento; }} 《解释器模式 Interpreter Pattern》 特点： 给分析对象定义一个语言，并定义该语言的文法表示，再设计一个解析器来解释语言中的句子。也就是说，用编译语言的方式来分析应用中的实例。这种模式实现了文法表达式处理的接口，该接口解释一个特定的上下文。 优点： 扩展性好。由于在解释器模式中使用类来表示语言的文法规则，因此可以通过继承等机制来改变或扩展文法。 容易实现。在语法树中的每个表达式节点类都是相似的，所以实现其文法较为容易。 缺点： 执行效率较低。解释器模式中通常使用大量的循环和递归调用，当要解释的句子较复杂时，其运行速度很慢，且代码的调试过程也比较麻烦。 会引起类膨胀。解释器模式中的每条规则至少需要定义一个类，当包含的文法规则很多时，类的个数将急剧增加，导致系统难以管理与维护。 可应用的场景比较少。在软件开发中，需要定义语言文法的应用实例非常少，所以这种模式很少被使用到。 角色： 文法（主谓宾）、句子、语法树 抽象表达式（Abstract Expression）角色：定义解释器的接口，约定解释器的解释操作，主要包含解释方法 interpret()。 终结符表达式（Terminal Expression）角色：是抽象表达式的子类，用来实现文法中与终结符相关的操作，文法中的每一个终结符都有一个具体终结表达式与之相对应。 非终结符表达式（Nonterminal Expression）角色：也是抽象表达式的子类，用来实现文法中与非终结符相关的操作，文法中的每条规则都对应于一个非终结符表达式。 环境（Context）角色：通常包含各个解释器需要的数据或是公共的功能，一般用来传递被所有解释器共享的数据，后面的解释器可以从这里获取这些值。 客户端（Client）：主要任务是将需要分析的句子或表达式转换成使用解释器对象描述的抽象语法树，然后调用解释器的解释方法，当然也可以通过环境角色间接访问解释器的解释方法。 解释器模式的应用场景： 当语言的文法较为简单，且执行效率不是关键问题时。 当问题重复出现，且可以用一种简单的语言来进行表达时。 当一个语言需要解释执行，并且语言中的句子可以表示为一个抽象语法树的时候，如 XML 文档解释。 JAVA实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.*;/*文法规则 &lt;expression&gt; ::= &lt;city&gt;的&lt;person&gt; &lt;city&gt; ::= 韶关|广州 &lt;person&gt; ::= 老人|妇女|儿童*/public class InterpreterPatternDemo { public static void main(String[] args) { Context bus = new Context(); bus.freeRide(&quot;韶关的老人&quot;); bus.freeRide(&quot;韶关的年轻人&quot;); bus.freeRide(&quot;广州的妇女&quot;); bus.freeRide(&quot;广州的儿童&quot;); bus.freeRide(&quot;山东的儿童&quot;); }}//抽象表达式类interface Expression { public boolean interpret(String info);}//终结符表达式类class TerminalExpression implements Expression { private Set&lt;String&gt; set = new HashSet&lt;String&gt;(); public TerminalExpression(String[] data) { for (int i = 0; i &lt; data.length; i++) set.add(data[i]); } @Override public boolean interpret(String info) { if (set.contains(info)) { return true; } return false; }}//非终结符表达式类class AndExpression implements Expression { private Expression city = null; private Expression person = null; public AndExpression(Expression city, Expression person) { this.city = city; this.person = person; } @Override public boolean interpret(String info) { String s[] = info.split(&quot;的&quot;); return city.interpret(s[0]) &amp;&amp; person.interpret(s[1]); }}//环境类class Context { private String[] citys = {&quot;韶关&quot;, &quot;广州&quot;}; private String[] persons = {&quot;老人&quot;, &quot;妇女&quot;, &quot;儿童&quot;}; private Expression cityPerson; public Context() { Expression city = new TerminalExpression(citys); Expression person = new TerminalExpression(persons); cityPerson = new AndExpression(city, person); } public void freeRide(String info) { boolean ok = cityPerson.interpret(info); if (ok) { System.out.println(&quot;您是&quot; + info + &quot;，您本次乘车免费！&quot;); } else { System.out.println(info + &quot;，您不是免费人员，本次乘车扣费2元！&quot;); } }} 全模式总结 一句话全模式总结 分类 设计模式 简述 一句话归纳 目的 生活案例 创建型设计模式 （简单来说就是用来创建对象的） [工厂模式（Factory Pattern）](#《工厂模式Factory Pattern》) 不同条件下创建不同实例 产品标准化，生产更高效 封装创建细节 实体工厂 单例模式（Singleton Pattern） 保证一个类仅有一个实例，并且提供一个全局访问点 世上只有一个我 保证独一无二 CEO 原型模式（Prototype Pattern） 通过拷贝原型创建新的对象 拔一根猴毛，吹出千万个 高效创建对象 克隆 建造者模式（Builder Pattern） 用来创建复杂的复合对象 高配中配和低配，想选哪配就哪配 开放个性配置步骤 选配 结构型设计模式 （关注类和对象的组合） [代理模式（Proxy Pattern）](#《代理模式 Proxy 》) 为其他对象提供一种代理以控制对这个对象的访问 没有资源没时间，得找别人来帮忙 增强职责 媒婆 [外观模式（Facade Pattern）](#《外观模式 Facade Pattern》) 对外提供一个统一的接口用来访问子系统 打开一扇门，通向全世界 统一访问入口 前台 [装饰器模式（Decorator Pattern）](#《装饰器模式 Decorator Pattern》) 为对象添加新功能 他大舅他二舅都是他舅 灵活扩展、同宗同源 煎饼 [享元模式（Flyweight Pattern）](#《享元模式 Flyweight Pattern》) 使用对象池来减少重复对象的创建 优化资源配置，减少重复浪费 共享资源池 全国社保联网 [组合模式（Composite Pattern）](#《组合模式 Composite Pattern》) 将整体与局部（树形结构）进行递归组合，让客户端能够以一种的方式对其进行处理 人在一起叫团伙，心在一起叫团队 统一整体和个体 组织架构树 [适配器模式（Adapter Pattern）](#《适配器模式 Adapter 》) 将原来不兼容的两个类融合在一起 万能充电器 兼容转换 电源适配 [桥接模式（Bridge Pattern）](#《桥接模式 Bridge》) 将两个能够独立变化的部分分离开来 约定优于配置 不允许用继承 桥 行为型设计模式 （关注对象之间的通信） 模板模式（Template Pattern） 定义一套流程模板，根据需要实现模板中的操作 流程全部标准化，需要微调请覆盖 逻辑复用 把大象装进冰箱 策略模式（Strategy Pattern） 封装不同的算法，算法之间能互相替换 条条大道通罗马，具体哪条你来定 把选择权交给用户 选择支付方式 责任链模式（Chain of Responsibility Pattern） 拦截的类都实现统一接口，每个接收者都包含对下一个接收者的引用。将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 各人自扫门前雪，莫管他们瓦上霜 解耦处理逻辑 踢皮球 迭代器模式（Iterator Pattern） 提供一种方法顺序访问一个聚合对象中的各个元素 流水线上坐一天，每个包裹扫一遍 统一对集合的访问方式 逐个检票进站 命令模式（Command Pattern） 将请求封装成命令，并记录下来，能够撤销与重做 运筹帷幄之中，决胜千里之外 解耦请求和处理 遥控器 状态模式（State Pattern） 根据不同的状态做出不同的行为 状态驱动行为，行为决定状态 绑定状态和行为 订单状态跟踪 备忘录模式（Memento Pattern） 保存对象的状态，在需要时进行恢复 失足不成千古恨，想重来时就重来 备份、后悔机制 草稿箱 中介者模式（Mediator Pattern） 将对象之间的通信关联关系封装到一个中介类中单独处理，从而使其耦合松散 联系方式我给你，怎么搞定我不管 统一管理网状资源 朋友圈 解释器模式（Interpreter Pattern） 给定一个语言，定义它的语法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子 我想说”方言“，一切解释权都归我 实现特定语法解析 摩斯密码 观察者模式（Observer Pattern） 状态发生改变时通知观察者，一对多的关系 到点就通知我 解耦观察者与被观察者 闹钟 访问者模式（Visitor Pattern） 稳定数据结构，定义新的操作行为 横看成岭侧成峰，远近高低各不同 解耦数据结构和数据操作 KPI考核 委派模式（Delegate Pattern） 允许对象组合实现与继承相同的代码重用，负责任务的调用和分配 这个需求很简单，怎么实现我不管 只对结果负责 授权委托书 资料来源 编程帮 Refactoringguru.cn","link":"/2021/03/01/Draft/2021/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"BUG","slug":"BUG","link":"/tags/BUG/"},{"name":"工具教程","slug":"工具教程","link":"/tags/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/"},{"name":"文件上传下载","slug":"文件上传下载","link":"/tags/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD/"},{"name":"编程语言","slug":"编程语言","link":"/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"NO GAME NO LIFE","slug":"NO-GAME-NO-LIFE","link":"/tags/NO-GAME-NO-LIFE/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"Software Engineer","slug":"Software-Engineer","link":"/tags/Software-Engineer/"},{"name":"音乐","slug":"音乐","link":"/tags/%E9%9F%B3%E4%B9%90/"},{"name":"待办","slug":"待办","link":"/tags/%E5%BE%85%E5%8A%9E/"},{"name":"书影音","slug":"书影音","link":"/tags/%E4%B9%A6%E5%BD%B1%E9%9F%B3/"},{"name":"健身外型","slug":"健身外型","link":"/tags/%E5%81%A5%E8%BA%AB%E5%A4%96%E5%9E%8B/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"自媒体计划","slug":"自媒体计划","link":"/tags/%E8%87%AA%E5%AA%92%E4%BD%93%E8%AE%A1%E5%88%92/"},{"name":"学习方法","slug":"学习方法","link":"/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"},{"name":"快查","slug":"快查","link":"/tags/%E5%BF%AB%E6%9F%A5/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"每日算法","slug":"每日算法","link":"/tags/%E6%AF%8F%E6%97%A5%E7%AE%97%E6%B3%95/"},{"name":"English","slug":"English","link":"/tags/English/"},{"name":"每日面题","slug":"每日面题","link":"/tags/%E6%AF%8F%E6%97%A5%E9%9D%A2%E9%A2%98/"},{"name":"Dubbo","slug":"Dubbo","link":"/tags/Dubbo/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/tags/SpringCloud/"},{"name":"计算机网络","slug":"计算机网络","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"信息系统项目管理师","slug":"信息系统项目管理师","link":"/tags/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%B8%88/"},{"name":"微信小程序","slug":"微信小程序","link":"/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/tags/RabbitMQ/"},{"name":"服务器","slug":"服务器","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Python学习","slug":"Python学习","link":"/tags/Python%E5%AD%A6%E4%B9%A0/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"categories":[{"name":"BUG记录","slug":"BUG记录","link":"/categories/BUG%E8%AE%B0%E5%BD%95/"},{"name":"工具教程","slug":"工具教程","link":"/categories/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/"},{"name":"JAVA应用","slug":"JAVA应用","link":"/categories/JAVA%E5%BA%94%E7%94%A8/"},{"name":"编程语言","slug":"编程语言","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"BUG","slug":"BUG记录/BUG","link":"/categories/BUG%E8%AE%B0%E5%BD%95/BUG/"},{"name":"游戏人生","slug":"游戏人生","link":"/categories/%E6%B8%B8%E6%88%8F%E4%BA%BA%E7%94%9F/"},{"name":"主题工具","slug":"工具教程/主题工具","link":"/categories/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/%E4%B8%BB%E9%A2%98%E5%B7%A5%E5%85%B7/"},{"name":"中间件","slug":"中间件","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"程序人生","slug":"程序人生","link":"/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"业务技术","slug":"JAVA应用/业务技术","link":"/categories/JAVA%E5%BA%94%E7%94%A8/%E4%B8%9A%E5%8A%A1%E6%8A%80%E6%9C%AF/"},{"name":"兴趣爱好","slug":"兴趣爱好","link":"/categories/%E5%85%B4%E8%B6%A3%E7%88%B1%E5%A5%BD/"},{"name":"待办","slug":"待办","link":"/categories/%E5%BE%85%E5%8A%9E/"},{"name":"Java","slug":"编程语言/Java","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Java/"},{"name":"博客搭建","slug":"工具教程/博客搭建","link":"/categories/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"书影音","slug":"书影音","link":"/categories/%E4%B9%A6%E5%BD%B1%E9%9F%B3/"},{"name":"健康","slug":"健康","link":"/categories/%E5%81%A5%E5%BA%B7/"},{"name":"程序基础","slug":"程序基础","link":"/categories/%E7%A8%8B%E5%BA%8F%E5%9F%BA%E7%A1%80/"},{"name":"计划","slug":"计划","link":"/categories/%E8%AE%A1%E5%88%92/"},{"name":"NO GAME NO LIFE","slug":"游戏人生/NO-GAME-NO-LIFE","link":"/categories/%E6%B8%B8%E6%88%8F%E4%BA%BA%E7%94%9F/NO-GAME-NO-LIFE/"},{"name":"学习方法","slug":"学习方法","link":"/categories/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"},{"name":"编程工具","slug":"编程工具","link":"/categories/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"每日任务","slug":"每日任务","link":"/categories/%E6%AF%8F%E6%97%A5%E4%BB%BB%E5%8A%A1/"},{"name":"English","slug":"English","link":"/categories/English/"},{"name":"Nginx","slug":"中间件/Nginx","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Nginx/"},{"name":"Software Engineer","slug":"程序人生/Software-Engineer","link":"/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/Software-Engineer/"},{"name":"音乐","slug":"兴趣爱好/音乐","link":"/categories/%E5%85%B4%E8%B6%A3%E7%88%B1%E5%A5%BD/%E9%9F%B3%E4%B9%90/"},{"name":"Everyday-TODO","slug":"待办/Everyday-TODO","link":"/categories/%E5%BE%85%E5%8A%9E/Everyday-TODO/"},{"name":"书影音","slug":"书影音/书影音","link":"/categories/%E4%B9%A6%E5%BD%B1%E9%9F%B3/%E4%B9%A6%E5%BD%B1%E9%9F%B3/"},{"name":"健身外型","slug":"健康/健身外型","link":"/categories/%E5%81%A5%E5%BA%B7/%E5%81%A5%E8%BA%AB%E5%A4%96%E5%9E%8B/"},{"name":"前端","slug":"程序基础/前端","link":"/categories/%E7%A8%8B%E5%BA%8F%E5%9F%BA%E7%A1%80/%E5%89%8D%E7%AB%AF/"},{"name":"自媒体计划","slug":"计划/自媒体计划","link":"/categories/%E8%AE%A1%E5%88%92/%E8%87%AA%E5%AA%92%E4%BD%93%E8%AE%A1%E5%88%92/"},{"name":"如何学习一个新知识","slug":"学习方法/如何学习一个新知识","link":"/categories/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9F%A5%E8%AF%86/"},{"name":"快查","slug":"编程工具/快查","link":"/categories/%E7%BC%96%E7%A8%8B%E5%B7%A5%E5%85%B7/%E5%BF%AB%E6%9F%A5/"},{"name":"数据库设计","slug":"数据库/数据库设计","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/"},{"name":"算法基础","slug":"每日任务/算法基础","link":"/categories/%E6%AF%8F%E6%97%A5%E4%BB%BB%E5%8A%A1/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"name":"程序员英语","slug":"English/程序员英语","link":"/categories/English/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%8B%B1%E8%AF%AD/"},{"name":"每日面题","slug":"每日任务/每日面题","link":"/categories/%E6%AF%8F%E6%97%A5%E4%BB%BB%E5%8A%A1/%E6%AF%8F%E6%97%A5%E9%9D%A2%E9%A2%98/"},{"name":"资源篇","slug":"工具教程/资源篇","link":"/categories/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/%E8%B5%84%E6%BA%90%E7%AF%87/"},{"name":"Dubbo","slug":"中间件/Dubbo","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/Dubbo/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"编程基础","slug":"编程基础","link":"/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"},{"name":"GIS","slug":"前端/GIS","link":"/categories/%E5%89%8D%E7%AB%AF/GIS/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","link":"/categories/Spring/SpringCloud/"},{"name":"计算机网络","slug":"编程基础/计算机网络","link":"/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"考证","slug":"考证","link":"/categories/%E8%80%83%E8%AF%81/"},{"name":"编程","slug":"编程","link":"/categories/%E7%BC%96%E7%A8%8B/"},{"name":"信息系统项目管理师","slug":"考证/信息系统项目管理师","link":"/categories/%E8%80%83%E8%AF%81/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%B8%88/"},{"name":"微信小程序","slug":"编程/微信小程序","link":"/categories/%E7%BC%96%E7%A8%8B/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"RabbitMQ","slug":"中间件/RabbitMQ","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/RabbitMQ/"},{"name":"实施维护","slug":"实施维护","link":"/categories/%E5%AE%9E%E6%96%BD%E7%BB%B4%E6%8A%A4/"},{"name":"MYSQL优化","slug":"数据库/MYSQL优化","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MYSQL%E4%BC%98%E5%8C%96/"},{"name":"Python学习","slug":"编程语言/Python学习","link":"/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python%E5%AD%A6%E4%B9%A0/"},{"name":"服务器","slug":"实施维护/服务器","link":"/categories/%E5%AE%9E%E6%96%BD%E7%BB%B4%E6%8A%A4/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Redis","slug":"程序基础/Redis","link":"/categories/%E7%A8%8B%E5%BA%8F%E5%9F%BA%E7%A1%80/Redis/"},{"name":"设计模式","slug":"程序基础/设计模式","link":"/categories/%E7%A8%8B%E5%BA%8F%E5%9F%BA%E7%A1%80/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}